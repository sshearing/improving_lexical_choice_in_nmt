2017-12-02 19:40:43,822:data_manager.py:103 - parallel_filter_long_sentences(): Filter ./nmt/data/de2en_bp/train.de & ./nmt/data/de2en_bp/train.en by length 50 & 50
2017-12-02 19:40:52,023:data_manager.py:103 - parallel_filter_long_sentences(): Filter ./nmt/data/de2en_bp/train.delex & ./nmt/data/de2en_bp/train.enlex by length 50 & 50
2017-12-02 19:40:52,827:data_manager.py:132 -        create_vocabs(): Create vocabulary for de with size 52000 from ./nmt/data/de2en_bp/train.de.clean-50
2017-12-02 19:40:53,291:data_manager.py:143 -        create_vocabs():    processing line 10000
2017-12-02 19:40:53,757:data_manager.py:143 -        create_vocabs():    processing line 20000
2017-12-02 19:40:54,220:data_manager.py:143 -        create_vocabs():    processing line 30000
2017-12-02 19:40:54,689:data_manager.py:143 -        create_vocabs():    processing line 40000
2017-12-02 19:40:55,149:data_manager.py:143 -        create_vocabs():    processing line 50000
2017-12-02 19:40:55,618:data_manager.py:143 -        create_vocabs():    processing line 60000
2017-12-02 19:40:56,087:data_manager.py:143 -        create_vocabs():    processing line 70000
2017-12-02 19:40:56,540:data_manager.py:143 -        create_vocabs():    processing line 80000
2017-12-02 19:40:57,004:data_manager.py:143 -        create_vocabs():    processing line 90000
2017-12-02 19:40:57,467:data_manager.py:143 -        create_vocabs():    processing line 100000
2017-12-02 19:40:57,931:data_manager.py:143 -        create_vocabs():    processing line 110000
2017-12-02 19:40:58,398:data_manager.py:143 -        create_vocabs():    processing line 120000
2017-12-02 19:40:58,864:data_manager.py:143 -        create_vocabs():    processing line 130000
2017-12-02 19:40:59,346:data_manager.py:143 -        create_vocabs():    processing line 140000
2017-12-02 19:40:59,812:data_manager.py:143 -        create_vocabs():    processing line 150000
2017-12-02 19:41:00,287:data_manager.py:143 -        create_vocabs():    processing line 160000
2017-12-02 19:41:00,470:data_manager.py:152 -        create_vocabs():    processing line 170000
2017-12-02 19:41:00,571:data_manager.py:152 -        create_vocabs():    processing line 180000
2017-12-02 19:41:00,669:data_manager.py:152 -        create_vocabs():    processing line 190000
2017-12-02 19:41:00,769:data_manager.py:152 -        create_vocabs():    processing line 200000
2017-12-02 19:41:01,296:data_manager.py:132 -        create_vocabs(): Create vocabulary for en with size 40000 from ./nmt/data/de2en_bp/train.en.clean-50
2017-12-02 19:41:01,712:data_manager.py:143 -        create_vocabs():    processing line 10000
2017-12-02 19:41:02,151:data_manager.py:143 -        create_vocabs():    processing line 20000
2017-12-02 19:41:02,601:data_manager.py:143 -        create_vocabs():    processing line 30000
2017-12-02 19:41:03,053:data_manager.py:143 -        create_vocabs():    processing line 40000
2017-12-02 19:41:03,502:data_manager.py:143 -        create_vocabs():    processing line 50000
2017-12-02 19:41:03,963:data_manager.py:143 -        create_vocabs():    processing line 60000
2017-12-02 19:41:04,424:data_manager.py:143 -        create_vocabs():    processing line 70000
2017-12-02 19:41:04,872:data_manager.py:143 -        create_vocabs():    processing line 80000
2017-12-02 19:41:05,308:data_manager.py:143 -        create_vocabs():    processing line 90000
2017-12-02 19:41:05,755:data_manager.py:143 -        create_vocabs():    processing line 100000
2017-12-02 19:41:06,185:data_manager.py:143 -        create_vocabs():    processing line 110000
2017-12-02 19:41:06,617:data_manager.py:143 -        create_vocabs():    processing line 120000
2017-12-02 19:41:07,050:data_manager.py:143 -        create_vocabs():    processing line 130000
2017-12-02 19:41:07,478:data_manager.py:143 -        create_vocabs():    processing line 140000
2017-12-02 19:41:07,907:data_manager.py:143 -        create_vocabs():    processing line 150000
2017-12-02 19:41:08,334:data_manager.py:143 -        create_vocabs():    processing line 160000
2017-12-02 19:41:08,505:data_manager.py:152 -        create_vocabs():    processing line 170000
2017-12-02 19:41:08,610:data_manager.py:152 -        create_vocabs():    processing line 180000
2017-12-02 19:41:08,712:data_manager.py:152 -        create_vocabs():    processing line 190000
2017-12-02 19:41:08,816:data_manager.py:152 -        create_vocabs():    processing line 200000
2017-12-02 19:41:09,233:data_manager.py:176 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en_bp/vocab-52000.de
2017-12-02 19:41:09,487:data_manager.py:176 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en_bp/vocab-40000.en
2017-12-02 19:41:09,747:data_manager.py:210 - parallel_data_to_token_ids(): Parallel convert tokens from ./nmt/data/de2en_bp/train.de.clean-50 & ./nmt/data/de2en_bp/train.en.clean-50 to ids and save to ./nmt/data/de2en_bp/train.ids
Also save the total data length to ./nmt/data/de2en_bp/train.length
2017-12-02 19:41:10,842:data_manager.py:230 - parallel_data_to_token_ids():     converting line 10000
2017-12-02 19:41:11,949:data_manager.py:230 - parallel_data_to_token_ids():     converting line 20000
2017-12-02 19:41:13,067:data_manager.py:230 - parallel_data_to_token_ids():     converting line 30000
2017-12-02 19:41:14,183:data_manager.py:230 - parallel_data_to_token_ids():     converting line 40000
2017-12-02 19:41:15,297:data_manager.py:230 - parallel_data_to_token_ids():     converting line 50000
2017-12-02 19:41:16,424:data_manager.py:230 - parallel_data_to_token_ids():     converting line 60000
2017-12-02 19:41:17,555:data_manager.py:230 - parallel_data_to_token_ids():     converting line 70000
2017-12-02 19:41:18,656:data_manager.py:230 - parallel_data_to_token_ids():     converting line 80000
2017-12-02 19:41:19,777:data_manager.py:230 - parallel_data_to_token_ids():     converting line 90000
2017-12-02 19:41:20,903:data_manager.py:230 - parallel_data_to_token_ids():     converting line 100000
2017-12-02 19:41:22,019:data_manager.py:230 - parallel_data_to_token_ids():     converting line 110000
2017-12-02 19:41:23,152:data_manager.py:230 - parallel_data_to_token_ids():     converting line 120000
2017-12-02 19:41:24,277:data_manager.py:230 - parallel_data_to_token_ids():     converting line 130000
2017-12-02 19:41:25,398:data_manager.py:230 - parallel_data_to_token_ids():     converting line 140000
2017-12-02 19:41:26,531:data_manager.py:230 - parallel_data_to_token_ids():     converting line 150000
2017-12-02 19:41:27,664:data_manager.py:230 - parallel_data_to_token_ids():     converting line 160000
2017-12-02 19:41:28,260:data_manager.py:176 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en_bp/vocab-52000.de
2017-12-02 19:41:28,506:data_manager.py:176 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en_bp/vocab-40000.en
2017-12-02 19:41:28,701:data_manager.py:210 - parallel_data_to_token_ids(): Parallel convert tokens from ./nmt/data/de2en_bp/train.delex.clean-50 & ./nmt/data/de2en_bp/train.enlex.clean-50 to ids and save to ./nmt/data/de2en_bp/train.lex.ids
Also save the total data length to ./nmt/data/de2en_bp/train.lex.length
2017-12-02 19:41:28,920:data_manager.py:230 - parallel_data_to_token_ids():     converting line 10000
2017-12-02 19:41:29,147:data_manager.py:230 - parallel_data_to_token_ids():     converting line 20000
2017-12-02 19:41:29,365:data_manager.py:230 - parallel_data_to_token_ids():     converting line 30000
2017-12-02 19:41:29,584:data_manager.py:230 - parallel_data_to_token_ids():     converting line 40000
2017-12-02 19:41:29,767:data_manager.py:176 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en_bp/vocab-52000.de
2017-12-02 19:41:30,015:data_manager.py:176 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en_bp/vocab-40000.en
2017-12-02 19:41:30,261:data_manager.py:210 - parallel_data_to_token_ids(): Parallel convert tokens from ./nmt/data/de2en_bp/dev.de & ./nmt/data/de2en_bp/dev.en to ids and save to ./nmt/data/de2en_bp/dev.ids
Also save the total data length to ./nmt/data/de2en_bp/dev.length
2017-12-02 19:41:30,482:data_manager.py:176 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en_bp/vocab-52000.de
2017-12-02 19:41:30,721:data_manager.py:176 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en_bp/vocab-40000.en
2017-12-02 19:41:30,907:data_manager.py:210 - parallel_data_to_token_ids(): Parallel convert tokens from ./nmt/data/de2en_bp/test.de & ./nmt/data/de2en_bp/test.en to ids and save to ./nmt/data/de2en_bp/test.ids
Also save the total data length to ./nmt/data/de2en_bp/test.length
2017-12-02 19:41:31,205:validator.py:23 -             __init__(): Initializing validator
2017-12-02 19:41:31,205:data_manager.py:176 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en_bp/vocab-40000.en
2017-12-02 19:41:31,446:train.py:43 -             __init__(): Evaluate every 7000 batches
2017-12-02 19:41:31,450:data_manager.py:176 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en_bp/vocab-52000.de
2017-12-02 19:41:31,690:data_manager.py:176 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en_bp/vocab-40000.en
2017-12-02 19:41:34,283:model.py:205 -             __init__(): train model:
2017-12-02 19:41:34,283:model.py:206 -             __init__(): Num trainable variables 15
2017-12-02 19:41:34,283:model.py:207 -             __init__(): Num params: 56,724,400
2017-12-02 19:41:34,283:model.py:208 -             __init__(): List of all trainable parameters:
2017-12-02 19:41:34,284:model.py:210 -             __init__():    de2en_bp/src_embedding:0
2017-12-02 19:41:34,284:model.py:210 -             __init__():    de2en_bp/trg_embedding:0
2017-12-02 19:41:34,284:model.py:210 -             __init__():    de2en_bp/sm_bias:0
2017-12-02 19:41:34,284:model.py:210 -             __init__():    de2en_bp/lex_embedding:0
2017-12-02 19:41:34,284:model.py:210 -             __init__():    de2en_bp/lex_bias:0
2017-12-02 19:41:34,284:model.py:210 -             __init__():    de2en_bp/outputer/W:0
2017-12-02 19:41:34,284:model.py:210 -             __init__():    de2en_bp/outputer/b:0
2017-12-02 19:41:34,284:model.py:210 -             __init__():    de2en_bp/lexical/W:0
2017-12-02 19:41:34,284:model.py:210 -             __init__():    de2en_bp/lexical/b:0
2017-12-02 19:41:34,284:model.py:210 -             __init__():    de2en_bp/encoder/lstm_cell/kernel:0
2017-12-02 19:41:34,284:model.py:210 -             __init__():    de2en_bp/encoder/lstm_cell/bias:0
2017-12-02 19:41:34,284:model.py:210 -             __init__():    de2en_bp/attention/W:0
2017-12-02 19:41:34,284:model.py:210 -             __init__():    de2en_bp/attention/b:0
2017-12-02 19:41:34,284:model.py:210 -             __init__():    de2en_bp/decoder/lstm_cell/kernel:0
2017-12-02 19:41:34,284:model.py:210 -             __init__():    de2en_bp/decoder/lstm_cell/bias:0
2017-12-02 19:41:40,227:train.py:88 -                train(): Set learning rate to 1.0
2017-12-02 19:41:41,661:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.688201904297 seconds
2017-12-02 19:43:03,046:train.py:199 -         run_log_save(): Batch 100, epoch 1/20:
2017-12-02 19:43:03,046:train.py:200 -         run_log_save():    avg word perp:   2429.56
2017-12-02 19:43:03,046:train.py:201 -         run_log_save():    acc trg words/s: 1988
2017-12-02 19:43:03,046:train.py:202 -         run_log_save():    acc sec/batch:   0.81
2017-12-02 19:44:24,515:train.py:199 -         run_log_save(): Batch 200, epoch 1/20:
2017-12-02 19:44:24,515:train.py:200 -         run_log_save():    avg word perp:   740.69
2017-12-02 19:44:24,515:train.py:201 -         run_log_save():    acc trg words/s: 1989
2017-12-02 19:44:24,515:train.py:202 -         run_log_save():    acc sec/batch:   0.81
2017-12-02 19:45:49,567:train.py:199 -         run_log_save(): Batch 300, epoch 1/20:
2017-12-02 19:45:49,567:train.py:200 -         run_log_save():    avg word perp:   509.32
2017-12-02 19:45:49,567:train.py:201 -         run_log_save():    acc trg words/s: 1954
2017-12-02 19:45:49,567:train.py:202 -         run_log_save():    acc sec/batch:   0.82
2017-12-02 19:47:11,243:train.py:199 -         run_log_save(): Batch 400, epoch 1/20:
2017-12-02 19:47:11,243:train.py:200 -         run_log_save():    avg word perp:   393.95
2017-12-02 19:47:11,243:train.py:201 -         run_log_save():    acc trg words/s: 1955
2017-12-02 19:47:11,243:train.py:202 -         run_log_save():    acc sec/batch:   0.82
2017-12-02 19:48:36,319:train.py:199 -         run_log_save(): Batch 500, epoch 1/20:
2017-12-02 19:48:36,319:train.py:200 -         run_log_save():    avg word perp:   324.26
2017-12-02 19:48:36,319:train.py:201 -         run_log_save():    acc trg words/s: 1946
2017-12-02 19:48:36,319:train.py:202 -         run_log_save():    acc sec/batch:   0.82
2017-12-02 19:49:56,880:train.py:199 -         run_log_save(): Batch 600, epoch 1/20:
2017-12-02 19:49:56,880:train.py:200 -         run_log_save():    avg word perp:   271.68
2017-12-02 19:49:56,884:train.py:201 -         run_log_save():    acc trg words/s: 1954
2017-12-02 19:49:56,884:train.py:202 -         run_log_save():    acc sec/batch:   0.82
2017-12-02 19:51:23,387:train.py:199 -         run_log_save(): Batch 700, epoch 1/20:
2017-12-02 19:51:23,387:train.py:200 -         run_log_save():    avg word perp:   239.72
2017-12-02 19:51:23,387:train.py:201 -         run_log_save():    acc trg words/s: 1942
2017-12-02 19:51:23,387:train.py:202 -         run_log_save():    acc sec/batch:   0.83
2017-12-02 19:52:32,009:train.py:199 -         run_log_save(): Batch 800, epoch 1/20:
2017-12-02 19:52:32,009:train.py:200 -         run_log_save():    avg word perp:   210.66
2017-12-02 19:52:32,010:train.py:201 -         run_log_save():    acc trg words/s: 1987
2017-12-02 19:52:32,010:train.py:202 -         run_log_save():    acc sec/batch:   0.81
2017-12-02 19:53:37,830:train.py:199 -         run_log_save(): Batch 900, epoch 1/20:
2017-12-02 19:53:37,830:train.py:200 -         run_log_save():    avg word perp:   188.47
2017-12-02 19:53:37,830:train.py:201 -         run_log_save():    acc trg words/s: 2031
2017-12-02 19:53:37,830:train.py:202 -         run_log_save():    acc sec/batch:   0.79
2017-12-02 19:54:43,158:train.py:151 -         sample_input(): Sample input data:
2017-12-02 19:54:43,158:train.py:152 -         sample_input(): Src: . lösen zu Zeit unserer Sicherheitsfragen wichtigsten der einige um , Allianz der Geschichte der in größten dem , treffen NATO der Gipfel jüngsten dem auf Organisationen internationalen und ländern Partner@@ , Mitgliedstaaten 60 etwa von Repräsentanten die Chicago in sich werden Wochenende diesem an _PAD _PAD _PAD _PAD _PAD
2017-12-02 19:54:43,158:train.py:153 -         sample_input(): Src len: 45
2017-12-02 19:54:43,159:train.py:154 -         sample_input(): Trg: _BOS this weekend in Chicago , representatives of roughly 60 member states , partner countries , and international organizations will assemble for NATO &apos;s latest summit , the largest in the Alliance &apos;s history , to tackle some of the biggest security questions of our time . _PAD _PAD _PAD _PAD
2017-12-02 19:54:43,159:train.py:155 -         sample_input(): Tar: this weekend in Chicago , representatives of roughly 60 member states , partner countries , and international organizations will assemble for NATO &apos;s latest summit , the largest in the Alliance &apos;s history , to tackle some of the biggest security questions of our time . _EOS _PAD _PAD _PAD _PAD
2017-12-02 19:54:43,159:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0
2017-12-02 19:54:43,159:train.py:199 -         run_log_save(): Batch 1000, epoch 1/20:
2017-12-02 19:54:43,159:train.py:200 -         run_log_save():    avg word perp:   164.20
2017-12-02 19:54:43,159:train.py:201 -         run_log_save():    acc trg words/s: 2066
2017-12-02 19:54:43,159:train.py:202 -         run_log_save():    acc sec/batch:   0.78
2017-12-02 19:55:48,399:train.py:199 -         run_log_save(): Batch 1100, epoch 1/20:
2017-12-02 19:55:48,399:train.py:200 -         run_log_save():    avg word perp:   150.31
2017-12-02 19:55:48,399:train.py:201 -         run_log_save():    acc trg words/s: 2099
2017-12-02 19:55:48,400:train.py:202 -         run_log_save():    acc sec/batch:   0.76
2017-12-02 19:56:54,842:train.py:199 -         run_log_save(): Batch 1200, epoch 1/20:
2017-12-02 19:56:54,843:train.py:200 -         run_log_save():    avg word perp:   142.94
2017-12-02 19:56:54,843:train.py:201 -         run_log_save():    acc trg words/s: 2124
2017-12-02 19:56:54,843:train.py:202 -         run_log_save():    acc sec/batch:   0.76
2017-12-02 19:58:00,504:train.py:199 -         run_log_save(): Batch 1300, epoch 1/20:
2017-12-02 19:58:00,505:train.py:200 -         run_log_save():    avg word perp:   125.82
2017-12-02 19:58:00,505:train.py:201 -         run_log_save():    acc trg words/s: 2146
2017-12-02 19:58:00,505:train.py:202 -         run_log_save():    acc sec/batch:   0.75
2017-12-02 19:59:06,337:train.py:199 -         run_log_save(): Batch 1400, epoch 1/20:
2017-12-02 19:59:06,337:train.py:200 -         run_log_save():    avg word perp:   116.26
2017-12-02 19:59:06,337:train.py:201 -         run_log_save():    acc trg words/s: 2166
2017-12-02 19:59:06,337:train.py:202 -         run_log_save():    acc sec/batch:   0.74
2017-12-02 20:00:11,655:train.py:199 -         run_log_save(): Batch 1500, epoch 1/20:
2017-12-02 20:00:11,655:train.py:200 -         run_log_save():    avg word perp:   112.75
2017-12-02 20:00:11,655:train.py:201 -         run_log_save():    acc trg words/s: 2184
2017-12-02 20:00:11,656:train.py:202 -         run_log_save():    acc sec/batch:   0.74
2017-12-02 20:01:17,169:train.py:199 -         run_log_save(): Batch 1600, epoch 1/20:
2017-12-02 20:01:17,169:train.py:200 -         run_log_save():    avg word perp:   107.40
2017-12-02 20:01:17,169:train.py:201 -         run_log_save():    acc trg words/s: 2201
2017-12-02 20:01:17,169:train.py:202 -         run_log_save():    acc sec/batch:   0.73
2017-12-02 20:02:22,561:train.py:199 -         run_log_save(): Batch 1700, epoch 1/20:
2017-12-02 20:02:22,561:train.py:200 -         run_log_save():    avg word perp:   98.27
2017-12-02 20:02:22,561:train.py:201 -         run_log_save():    acc trg words/s: 2216
2017-12-02 20:02:22,561:train.py:202 -         run_log_save():    acc sec/batch:   0.73
2017-12-02 20:03:28,988:train.py:199 -         run_log_save(): Batch 1800, epoch 1/20:
2017-12-02 20:03:28,988:train.py:200 -         run_log_save():    avg word perp:   94.99
2017-12-02 20:03:28,988:train.py:201 -         run_log_save():    acc trg words/s: 2228
2017-12-02 20:03:28,988:train.py:202 -         run_log_save():    acc sec/batch:   0.72
2017-12-02 20:04:34,287:train.py:199 -         run_log_save(): Batch 1900, epoch 1/20:
2017-12-02 20:04:34,288:train.py:200 -         run_log_save():    avg word perp:   89.62
2017-12-02 20:04:34,288:train.py:201 -         run_log_save():    acc trg words/s: 2240
2017-12-02 20:04:34,288:train.py:202 -         run_log_save():    acc sec/batch:   0.72
2017-12-02 20:05:41,993:train.py:151 -         sample_input(): Sample input data:
2017-12-02 20:05:41,994:train.py:152 -         sample_input(): Src: . erreicht Rezession der vor Niveau das wieder Branchen nach Arbeitskräften von Nachfrage und Angebot zwischen verhältnis Miss@@ das hat zufolge Daten jüngsten und istisch charakter@@ Erholung gegenwärtige die für ist Muster dieses . jedoch Ungleichgewichte diese sich verringern , erholt Wirtschaft die sich wenn _PAD _PAD _PAD _PAD _PAD
2017-12-02 20:05:41,994:train.py:153 -         sample_input(): Src len: 45
2017-12-02 20:05:41,994:train.py:154 -         sample_input(): Trg: _BOS this pattern also characterizes the current recovery , and recent data suggest that mis@@ matches between the demand and supply of labor by industry are back to pre @-@ recession levels . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 20:05:41,994:train.py:155 -         sample_input(): Tar: this pattern also characterizes the current recovery , and recent data suggest that mis@@ matches between the demand and supply of labor by industry are back to pre @-@ recession levels . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 20:05:41,994:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-02 20:05:41,994:train.py:199 -         run_log_save(): Batch 2000, epoch 1/20:
2017-12-02 20:05:41,994:train.py:200 -         run_log_save():    avg word perp:   84.96
2017-12-02 20:05:41,994:train.py:201 -         run_log_save():    acc trg words/s: 2247
2017-12-02 20:05:41,994:train.py:202 -         run_log_save():    acc sec/batch:   0.72
2017-12-02 20:06:47,082:train.py:199 -         run_log_save(): Batch 2100, epoch 1/20:
2017-12-02 20:06:47,082:train.py:200 -         run_log_save():    avg word perp:   81.05
2017-12-02 20:06:47,082:train.py:201 -         run_log_save():    acc trg words/s: 2258
2017-12-02 20:06:47,082:train.py:202 -         run_log_save():    acc sec/batch:   0.71
2017-12-02 20:07:52,771:train.py:199 -         run_log_save(): Batch 2200, epoch 1/20:
2017-12-02 20:07:52,771:train.py:200 -         run_log_save():    avg word perp:   77.77
2017-12-02 20:07:52,771:train.py:201 -         run_log_save():    acc trg words/s: 2267
2017-12-02 20:07:52,771:train.py:202 -         run_log_save():    acc sec/batch:   0.71
2017-12-02 20:08:59,529:train.py:199 -         run_log_save(): Batch 2300, epoch 1/20:
2017-12-02 20:08:59,529:train.py:200 -         run_log_save():    avg word perp:   73.72
2017-12-02 20:08:59,530:train.py:201 -         run_log_save():    acc trg words/s: 2273
2017-12-02 20:08:59,530:train.py:202 -         run_log_save():    acc sec/batch:   0.71
2017-12-02 20:10:05,270:train.py:199 -         run_log_save(): Batch 2400, epoch 1/20:
2017-12-02 20:10:05,270:train.py:200 -         run_log_save():    avg word perp:   72.28
2017-12-02 20:10:05,270:train.py:201 -         run_log_save():    acc trg words/s: 2280
2017-12-02 20:10:05,270:train.py:202 -         run_log_save():    acc sec/batch:   0.71
2017-12-02 20:11:10,536:train.py:199 -         run_log_save(): Batch 2500, epoch 1/20:
2017-12-02 20:11:10,536:train.py:200 -         run_log_save():    avg word perp:   68.08
2017-12-02 20:11:10,536:train.py:201 -         run_log_save():    acc trg words/s: 2288
2017-12-02 20:11:10,536:train.py:202 -         run_log_save():    acc sec/batch:   0.70
2017-12-02 20:11:39,449:train.py:199 -         run_log_save(): Batch 2600, epoch 1/20:
2017-12-02 20:11:39,449:train.py:200 -         run_log_save():    avg word perp:   110.57
2017-12-02 20:11:39,449:train.py:201 -         run_log_save():    acc trg words/s: 2288
2017-12-02 20:11:39,449:train.py:202 -         run_log_save():    acc sec/batch:   0.69
2017-12-02 20:11:46,376:train.py:199 -         run_log_save(): Batch 2700, epoch 1/20:
2017-12-02 20:11:46,376:train.py:200 -         run_log_save():    avg word perp:   812.49
2017-12-02 20:11:46,376:train.py:201 -         run_log_save():    acc trg words/s: 2288
2017-12-02 20:11:46,376:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 20:11:53,306:train.py:199 -         run_log_save(): Batch 2800, epoch 1/20:
2017-12-02 20:11:53,306:train.py:200 -         run_log_save():    avg word perp:   726.24
2017-12-02 20:11:53,306:train.py:201 -         run_log_save():    acc trg words/s: 2289
2017-12-02 20:11:53,307:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-02 20:12:00,203:train.py:199 -         run_log_save(): Batch 2900, epoch 1/20:
2017-12-02 20:12:00,204:train.py:200 -         run_log_save():    avg word perp:   648.36
2017-12-02 20:12:00,204:train.py:201 -         run_log_save():    acc trg words/s: 2289
2017-12-02 20:12:00,204:train.py:202 -         run_log_save():    acc sec/batch:   0.62
2017-12-02 20:12:07,098:train.py:151 -         sample_input(): Sample input data:
2017-12-02 20:12:07,098:train.py:152 -         sample_input(): Src: Karbonylgruppe
2017-12-02 20:12:07,098:train.py:153 -         sample_input(): Src len: 1
2017-12-02 20:12:07,098:train.py:154 -         sample_input(): Trg: _BOS carbonyl group
2017-12-02 20:12:07,098:train.py:155 -         sample_input(): Tar: carbonyl group _EOS
2017-12-02 20:12:07,098:train.py:156 -         sample_input(): W: 1.0 1.0 1.0
2017-12-02 20:12:07,099:train.py:199 -         run_log_save(): Batch 3000, epoch 1/20:
2017-12-02 20:12:07,099:train.py:200 -         run_log_save():    avg word perp:   611.23
2017-12-02 20:12:07,099:train.py:201 -         run_log_save():    acc trg words/s: 2290
2017-12-02 20:12:07,099:train.py:202 -         run_log_save():    acc sec/batch:   0.61
2017-12-02 20:12:13,947:train.py:199 -         run_log_save(): Batch 3100, epoch 1/20:
2017-12-02 20:12:13,947:train.py:200 -         run_log_save():    avg word perp:   578.57
2017-12-02 20:12:13,947:train.py:201 -         run_log_save():    acc trg words/s: 2290
2017-12-02 20:12:13,947:train.py:202 -         run_log_save():    acc sec/batch:   0.59
2017-12-02 20:12:20,800:train.py:199 -         run_log_save(): Batch 3200, epoch 1/20:
2017-12-02 20:12:20,800:train.py:200 -         run_log_save():    avg word perp:   569.23
2017-12-02 20:12:20,800:train.py:201 -         run_log_save():    acc trg words/s: 2291
2017-12-02 20:12:20,800:train.py:202 -         run_log_save():    acc sec/batch:   0.57
2017-12-02 20:12:26,084:train.py:119 -         report_epoch(): Finish epoch 1
2017-12-02 20:12:26,085:train.py:120 -         report_epoch():     It takes 0:30:33.943029
2017-12-02 20:12:26,085:train.py:121 -         report_epoch():     Avergage # words/second    2291.41959874
2017-12-02 20:12:26,085:train.py:122 -         report_epoch():     Average seconds/batch    0.559811669464
2017-12-02 20:12:26,085:train.py:133 -         report_epoch():     train perplexity: 170.408071362
2017-12-02 20:12:26,611:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.525829076767 seconds
2017-12-02 20:12:41,639:train.py:199 -         run_log_save(): Batch 24, epoch 2/20:
2017-12-02 20:12:41,640:train.py:200 -         run_log_save():    avg word perp:   149.33
2017-12-02 20:12:41,640:train.py:201 -         run_log_save():    acc trg words/s: 2393
2017-12-02 20:12:41,640:train.py:202 -         run_log_save():    acc sec/batch:   0.62
2017-12-02 20:13:48,048:train.py:199 -         run_log_save(): Batch 124, epoch 2/20:
2017-12-02 20:13:48,048:train.py:200 -         run_log_save():    avg word perp:   66.15
2017-12-02 20:13:48,048:train.py:201 -         run_log_save():    acc trg words/s: 2426
2017-12-02 20:13:48,048:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:14:53,975:train.py:199 -         run_log_save(): Batch 224, epoch 2/20:
2017-12-02 20:14:53,975:train.py:200 -         run_log_save():    avg word perp:   61.25
2017-12-02 20:14:53,975:train.py:201 -         run_log_save():    acc trg words/s: 2437
2017-12-02 20:14:53,975:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:15:58,460:train.py:199 -         run_log_save(): Batch 324, epoch 2/20:
2017-12-02 20:15:58,460:train.py:200 -         run_log_save():    avg word perp:   58.15
2017-12-02 20:15:58,460:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-02 20:15:58,461:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:17:04,043:train.py:199 -         run_log_save(): Batch 424, epoch 2/20:
2017-12-02 20:17:04,043:train.py:200 -         run_log_save():    avg word perp:   57.13
2017-12-02 20:17:04,043:train.py:201 -         run_log_save():    acc trg words/s: 2460
2017-12-02 20:17:04,043:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:18:10,453:train.py:199 -         run_log_save(): Batch 524, epoch 2/20:
2017-12-02 20:18:10,454:train.py:200 -         run_log_save():    avg word perp:   55.38
2017-12-02 20:18:10,454:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-02 20:18:10,454:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:19:16,123:train.py:199 -         run_log_save(): Batch 624, epoch 2/20:
2017-12-02 20:19:16,123:train.py:200 -         run_log_save():    avg word perp:   51.62
2017-12-02 20:19:16,123:train.py:201 -         run_log_save():    acc trg words/s: 2458
2017-12-02 20:19:16,123:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:20:21,438:train.py:151 -         sample_input(): Sample input data:
2017-12-02 20:20:21,438:train.py:152 -         sample_input(): Src: ? heute es gibt Möglichkeit endere verlock@@ welche oder Problem gendere drin@@ welches aber _PAD
2017-12-02 20:20:21,439:train.py:153 -         sample_input(): Src len: 14
2017-12-02 20:20:21,439:train.py:154 -         sample_input(): Trg: _BOS but what more urgent problem or attractive opportunity exists today ? _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 20:20:21,439:train.py:155 -         sample_input(): Tar: but what more urgent problem or attractive opportunity exists today ? _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 20:20:21,439:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-02 20:20:21,439:train.py:199 -         run_log_save(): Batch 724, epoch 2/20:
2017-12-02 20:20:21,439:train.py:200 -         run_log_save():    avg word perp:   50.43
2017-12-02 20:20:21,439:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-02 20:20:21,439:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:21:27,809:train.py:199 -         run_log_save(): Batch 824, epoch 2/20:
2017-12-02 20:21:27,810:train.py:200 -         run_log_save():    avg word perp:   49.13
2017-12-02 20:21:27,810:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-02 20:21:27,810:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:22:33,325:train.py:199 -         run_log_save(): Batch 924, epoch 2/20:
2017-12-02 20:22:33,325:train.py:200 -         run_log_save():    avg word perp:   49.40
2017-12-02 20:22:33,326:train.py:201 -         run_log_save():    acc trg words/s: 2458
2017-12-02 20:22:33,326:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:23:41,250:train.py:199 -         run_log_save(): Batch 1024, epoch 2/20:
2017-12-02 20:23:41,251:train.py:200 -         run_log_save():    avg word perp:   47.92
2017-12-02 20:23:41,251:train.py:201 -         run_log_save():    acc trg words/s: 2452
2017-12-02 20:23:41,251:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 20:24:46,446:train.py:199 -         run_log_save(): Batch 1124, epoch 2/20:
2017-12-02 20:24:46,447:train.py:200 -         run_log_save():    avg word perp:   46.37
2017-12-02 20:24:46,447:train.py:201 -         run_log_save():    acc trg words/s: 2454
2017-12-02 20:24:46,447:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:25:51,225:train.py:199 -         run_log_save(): Batch 1224, epoch 2/20:
2017-12-02 20:25:51,225:train.py:200 -         run_log_save():    avg word perp:   44.52
2017-12-02 20:25:51,225:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-02 20:25:51,225:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:26:58,774:train.py:199 -         run_log_save(): Batch 1324, epoch 2/20:
2017-12-02 20:26:58,774:train.py:200 -         run_log_save():    avg word perp:   44.45
2017-12-02 20:26:58,774:train.py:201 -         run_log_save():    acc trg words/s: 2453
2017-12-02 20:26:58,774:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 20:28:04,818:train.py:199 -         run_log_save(): Batch 1424, epoch 2/20:
2017-12-02 20:28:04,819:train.py:200 -         run_log_save():    avg word perp:   43.37
2017-12-02 20:28:04,819:train.py:201 -         run_log_save():    acc trg words/s: 2452
2017-12-02 20:28:04,819:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 20:29:10,775:train.py:199 -         run_log_save(): Batch 1524, epoch 2/20:
2017-12-02 20:29:10,776:train.py:200 -         run_log_save():    avg word perp:   42.70
2017-12-02 20:29:10,776:train.py:201 -         run_log_save():    acc trg words/s: 2453
2017-12-02 20:29:10,776:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 20:30:16,849:train.py:199 -         run_log_save(): Batch 1624, epoch 2/20:
2017-12-02 20:30:16,849:train.py:200 -         run_log_save():    avg word perp:   41.96
2017-12-02 20:30:16,849:train.py:201 -         run_log_save():    acc trg words/s: 2453
2017-12-02 20:30:16,849:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 20:31:21,432:train.py:151 -         sample_input(): Sample input data:
2017-12-02 20:31:21,432:train.py:152 -         sample_input(): Src: . lag falsch oder richtig damals ich ob , mich ich frage seitdem _PAD _PAD _PAD
2017-12-02 20:31:21,432:train.py:153 -         sample_input(): Src len: 13
2017-12-02 20:31:21,432:train.py:154 -         sample_input(): Trg: _BOS ever since , I have wondered whether I was right or wrong . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 20:31:21,432:train.py:155 -         sample_input(): Tar: ever since , I have wondered whether I was right or wrong . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 20:31:21,433:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-02 20:31:21,433:train.py:199 -         run_log_save(): Batch 1724, epoch 2/20:
2017-12-02 20:31:21,433:train.py:200 -         run_log_save():    avg word perp:   40.73
2017-12-02 20:31:21,433:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-02 20:31:21,433:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 20:31:22,036:train.py:207 -         run_log_save(): Save model to ./nmt/saved_models/de2en_bp/de2en_bp.cpkt, takes 0:00:00.602955
2017-12-02 20:32:28,250:train.py:199 -         run_log_save(): Batch 1824, epoch 2/20:
2017-12-02 20:32:28,250:train.py:200 -         run_log_save():    avg word perp:   40.16
2017-12-02 20:32:28,250:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-02 20:32:28,250:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 20:33:34,117:train.py:199 -         run_log_save(): Batch 1924, epoch 2/20:
2017-12-02 20:33:34,117:train.py:200 -         run_log_save():    avg word perp:   39.82
2017-12-02 20:33:34,118:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-02 20:33:34,118:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 20:34:39,890:train.py:199 -         run_log_save(): Batch 2024, epoch 2/20:
2017-12-02 20:34:39,891:train.py:200 -         run_log_save():    avg word perp:   37.65
2017-12-02 20:34:39,891:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-02 20:34:39,891:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 20:35:45,405:train.py:199 -         run_log_save(): Batch 2124, epoch 2/20:
2017-12-02 20:35:45,405:train.py:200 -         run_log_save():    avg word perp:   37.32
2017-12-02 20:35:45,405:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-02 20:35:45,405:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 20:36:50,684:train.py:199 -         run_log_save(): Batch 2224, epoch 2/20:
2017-12-02 20:36:50,684:train.py:200 -         run_log_save():    avg word perp:   35.87
2017-12-02 20:36:50,684:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-02 20:36:50,684:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:37:56,311:train.py:199 -         run_log_save(): Batch 2324, epoch 2/20:
2017-12-02 20:37:56,311:train.py:200 -         run_log_save():    avg word perp:   35.78
2017-12-02 20:37:56,311:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-02 20:37:56,311:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:39:02,747:train.py:199 -         run_log_save(): Batch 2424, epoch 2/20:
2017-12-02 20:39:02,747:train.py:200 -         run_log_save():    avg word perp:   36.35
2017-12-02 20:39:02,747:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-02 20:39:02,747:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 20:40:07,809:train.py:199 -         run_log_save(): Batch 2524, epoch 2/20:
2017-12-02 20:40:07,810:train.py:200 -         run_log_save():    avg word perp:   34.98
2017-12-02 20:40:07,810:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-02 20:40:07,810:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:40:21,624:train.py:199 -         run_log_save(): Batch 2624, epoch 2/20:
2017-12-02 20:40:21,624:train.py:200 -         run_log_save():    avg word perp:   152.02
2017-12-02 20:40:21,624:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-02 20:40:21,624:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-02 20:40:28,409:train.py:151 -         sample_input(): Sample input data:
2017-12-02 20:40:28,409:train.py:152 -         sample_input(): Src: Terroranschläge
2017-12-02 20:40:28,409:train.py:153 -         sample_input(): Src len: 1
2017-12-02 20:40:28,409:train.py:154 -         sample_input(): Trg: _BOS terrorist attacks
2017-12-02 20:40:28,409:train.py:155 -         sample_input(): Tar: terrorist attacks _EOS
2017-12-02 20:40:28,409:train.py:156 -         sample_input(): W: 1.0 1.0 1.0
2017-12-02 20:40:28,409:train.py:199 -         run_log_save(): Batch 2724, epoch 2/20:
2017-12-02 20:40:28,409:train.py:200 -         run_log_save():    avg word perp:   613.93
2017-12-02 20:40:28,409:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-02 20:40:28,409:train.py:202 -         run_log_save():    acc sec/batch:   0.61
2017-12-02 20:40:35,288:train.py:199 -         run_log_save(): Batch 2824, epoch 2/20:
2017-12-02 20:40:35,288:train.py:200 -         run_log_save():    avg word perp:   564.46
2017-12-02 20:40:35,288:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-02 20:40:35,288:train.py:202 -         run_log_save():    acc sec/batch:   0.59
2017-12-02 20:40:42,080:train.py:199 -         run_log_save(): Batch 2924, epoch 2/20:
2017-12-02 20:40:42,080:train.py:200 -         run_log_save():    avg word perp:   534.10
2017-12-02 20:40:42,080:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-02 20:40:42,080:train.py:202 -         run_log_save():    acc sec/batch:   0.58
2017-12-02 20:40:48,951:train.py:199 -         run_log_save(): Batch 3024, epoch 2/20:
2017-12-02 20:40:48,952:train.py:200 -         run_log_save():    avg word perp:   536.21
2017-12-02 20:40:48,952:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-02 20:40:48,952:train.py:202 -         run_log_save():    acc sec/batch:   0.56
2017-12-02 20:40:55,785:train.py:199 -         run_log_save(): Batch 3124, epoch 2/20:
2017-12-02 20:40:55,785:train.py:200 -         run_log_save():    avg word perp:   524.37
2017-12-02 20:40:55,785:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-02 20:40:55,785:train.py:202 -         run_log_save():    acc sec/batch:   0.54
2017-12-02 20:41:02,630:train.py:199 -         run_log_save(): Batch 3224, epoch 2/20:
2017-12-02 20:41:02,630:train.py:200 -         run_log_save():    avg word perp:   495.45
2017-12-02 20:41:02,630:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-02 20:41:02,630:train.py:202 -         run_log_save():    acc sec/batch:   0.53
2017-12-02 20:41:06,253:train.py:119 -         report_epoch(): Finish epoch 2
2017-12-02 20:41:06,253:train.py:120 -         report_epoch():     It takes 0:28:30.415294
2017-12-02 20:41:06,253:train.py:121 -         report_epoch():     Avergage # words/second    2456.87875658
2017-12-02 20:41:06,253:train.py:122 -         report_epoch():     Average seconds/batch    0.522104790505
2017-12-02 20:41:06,253:train.py:133 -         report_epoch():     train perplexity: 48.946551528
2017-12-02 20:41:06,761:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.508069038391 seconds
2017-12-02 20:41:36,981:train.py:199 -         run_log_save(): Batch 48, epoch 3/20:
2017-12-02 20:41:36,981:train.py:200 -         run_log_save():    avg word perp:   54.25
2017-12-02 20:41:36,981:train.py:201 -         run_log_save():    acc trg words/s: 2427
2017-12-02 20:41:36,981:train.py:202 -         run_log_save():    acc sec/batch:   0.63
2017-12-02 20:42:42,417:train.py:199 -         run_log_save(): Batch 148, epoch 3/20:
2017-12-02 20:42:42,417:train.py:200 -         run_log_save():    avg word perp:   33.17
2017-12-02 20:42:42,417:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-02 20:42:42,417:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-02 20:43:48,358:train.py:199 -         run_log_save(): Batch 248, epoch 3/20:
2017-12-02 20:43:48,359:train.py:200 -         run_log_save():    avg word perp:   33.21
2017-12-02 20:43:48,359:train.py:201 -         run_log_save():    acc trg words/s: 2455
2017-12-02 20:43:48,359:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:44:54,639:train.py:199 -         run_log_save(): Batch 348, epoch 3/20:
2017-12-02 20:44:54,640:train.py:200 -         run_log_save():    avg word perp:   30.97
2017-12-02 20:44:54,640:train.py:201 -         run_log_save():    acc trg words/s: 2450
2017-12-02 20:44:54,640:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:46:00,129:train.py:151 -         sample_input(): Sample input data:
2017-12-02 20:46:00,130:train.py:152 -         sample_input(): Src: . Dollar Billionen 4 fast zu bis Dollar Billion einer unter zwischen schwanken Wertpapieren und Darlehen amerikanischen aus Verluste der Schätzungen _PAD _PAD
2017-12-02 20:46:00,130:train.py:153 -         sample_input(): Src len: 21
2017-12-02 20:46:00,130:train.py:154 -         sample_input(): Trg: _BOS estimates of the losses on US loans and securities range from under $ 1 trillion to almost $ 4 trillion . _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 20:46:00,130:train.py:155 -         sample_input(): Tar: estimates of the losses on US loans and securities range from under $ 1 trillion to almost $ 4 trillion . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 20:46:00,130:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-02 20:46:00,130:train.py:199 -         run_log_save(): Batch 448, epoch 3/20:
2017-12-02 20:46:00,130:train.py:200 -         run_log_save():    avg word perp:   30.66
2017-12-02 20:46:00,130:train.py:201 -         run_log_save():    acc trg words/s: 2448
2017-12-02 20:46:00,130:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 20:46:00,130:validator.py:224 -    validate_and_save(): Start validation
2017-12-02 20:47:10,096:validator.py:143 -             evaluate():   Translating line 100, average 0.699656400681 seconds/sent
2017-12-02 20:48:15,100:validator.py:143 -             evaluate():   Translating line 200, average 0.674845910072 seconds/sent
2017-12-02 20:49:10,215:validator.py:143 -             evaluate():   Translating line 300, average 0.633614176909 seconds/sent
2017-12-02 20:50:05,545:validator.py:143 -             evaluate():   Translating line 400, average 0.613535137177 seconds/sent
2017-12-02 20:51:11,854:validator.py:143 -             evaluate():   Translating line 500, average 0.623445931911 seconds/sent
2017-12-02 20:52:08,501:validator.py:143 -             evaluate():   Translating line 600, average 0.613950775067 seconds/sent
2017-12-02 20:53:13,106:validator.py:143 -             evaluate():   Translating line 700, average 0.618536775793 seconds/sent
2017-12-02 20:54:08,350:validator.py:143 -             evaluate():   Translating line 800, average 0.610274015069 seconds/sent
2017-12-02 20:54:54,182:validator.py:143 -             evaluate():   Translating line 900, average 0.593390061061 seconds/sent
2017-12-02 20:55:51,101:validator.py:143 -             evaluate():   Translating line 1000, average 0.59097052598 seconds/sent
2017-12-02 20:56:48,326:validator.py:143 -             evaluate():   Translating line 1100, average 0.589268464609 seconds/sent
2017-12-02 20:57:42,462:validator.py:143 -             evaluate():   Translating line 1200, average 0.585276609063 seconds/sent
2017-12-02 20:58:54,932:validator.py:143 -             evaluate():   Translating line 1300, average 0.596000760702 seconds/sent
2017-12-02 21:00:02,146:validator.py:143 -             evaluate():   Translating line 1400, average 0.601439593519 seconds/sent
2017-12-02 21:01:02,203:validator.py:143 -             evaluate():   Translating line 1500, average 0.601381640593 seconds/sent
2017-12-02 21:02:08,605:validator.py:143 -             evaluate():   Translating line 1600, average 0.6052966775 seconds/sent
2017-12-02 21:03:08,767:validator.py:143 -             evaluate():   Translating line 1700, average 0.60508048296 seconds/sent
2017-12-02 21:04:18,543:validator.py:143 -             evaluate():   Translating line 1800, average 0.610229158931 seconds/sent
2017-12-02 21:05:27,067:validator.py:143 -             evaluate():   Translating line 1900, average 0.614176854209 seconds/sent
2017-12-02 21:06:02,068:validator.py:152 -             evaluate(): Done translating.
2017-12-02 21:06:02,068:validator.py:153 -             evaluate(): dev perplexity: 171.52
2017-12-02 21:06:02,534:validator.py:159 -             evaluate(): BLEU = 7.31, 36.4/12.3/5.2/2.4 (BP=0.846, ratio=0.857, hyp_len=38806, ref_len=45274)

2017-12-02 21:06:02,535:validator.py:160 -             evaluate(): Validation took: 20.0400666833 minutes
2017-12-02 21:06:02,538:validator.py:212 -           maybe_save(): Save 7.31 to list of best bleu scores
2017-12-02 21:06:03,081:validator.py:216 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en_bp/de2en_bp-7.31.cpkt
2017-12-02 21:06:03,081:validator.py:217 -           maybe_save(): Best bleu scores so far: 7.31
2017-12-02 21:07:09,028:train.py:199 -         run_log_save(): Batch 548, epoch 3/20:
2017-12-02 21:07:09,028:train.py:200 -         run_log_save():    avg word perp:   31.21
2017-12-02 21:07:09,028:train.py:201 -         run_log_save():    acc trg words/s: 2449
2017-12-02 21:07:09,028:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:08:14,321:train.py:199 -         run_log_save(): Batch 648, epoch 3/20:
2017-12-02 21:08:14,321:train.py:200 -         run_log_save():    avg word perp:   29.56
2017-12-02 21:08:14,321:train.py:201 -         run_log_save():    acc trg words/s: 2451
2017-12-02 21:08:14,321:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:09:19,946:train.py:199 -         run_log_save(): Batch 748, epoch 3/20:
2017-12-02 21:09:19,946:train.py:200 -         run_log_save():    avg word perp:   29.51
2017-12-02 21:09:19,946:train.py:201 -         run_log_save():    acc trg words/s: 2455
2017-12-02 21:09:19,946:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:10:25,090:train.py:199 -         run_log_save(): Batch 848, epoch 3/20:
2017-12-02 21:10:25,090:train.py:200 -         run_log_save():    avg word perp:   29.22
2017-12-02 21:10:25,090:train.py:201 -         run_log_save():    acc trg words/s: 2458
2017-12-02 21:10:25,090:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:11:31,272:train.py:199 -         run_log_save(): Batch 948, epoch 3/20:
2017-12-02 21:11:31,272:train.py:200 -         run_log_save():    avg word perp:   28.96
2017-12-02 21:11:31,272:train.py:201 -         run_log_save():    acc trg words/s: 2458
2017-12-02 21:11:31,272:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:12:37,680:train.py:199 -         run_log_save(): Batch 1048, epoch 3/20:
2017-12-02 21:12:37,681:train.py:200 -         run_log_save():    avg word perp:   28.69
2017-12-02 21:12:37,681:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-02 21:12:37,681:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:13:42,741:train.py:199 -         run_log_save(): Batch 1148, epoch 3/20:
2017-12-02 21:13:42,742:train.py:200 -         run_log_save():    avg word perp:   28.55
2017-12-02 21:13:42,742:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-02 21:13:42,742:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:14:49,208:train.py:199 -         run_log_save(): Batch 1248, epoch 3/20:
2017-12-02 21:14:49,208:train.py:200 -         run_log_save():    avg word perp:   27.88
2017-12-02 21:14:49,208:train.py:201 -         run_log_save():    acc trg words/s: 2458
2017-12-02 21:14:49,208:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:15:55,435:train.py:199 -         run_log_save(): Batch 1348, epoch 3/20:
2017-12-02 21:15:55,436:train.py:200 -         run_log_save():    avg word perp:   27.52
2017-12-02 21:15:55,436:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-02 21:15:55,436:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:17:00,311:train.py:151 -         sample_input(): Sample input data:
2017-12-02 21:17:00,311:train.py:152 -         sample_input(): Src: . Verantwortung und Gerechtigkeit der Fragen um sondern , Fragen &quot; ökologische &quot; um nur nicht sich es handelt dabei _PAD _PAD
2017-12-02 21:17:00,312:train.py:153 -         sample_input(): Src len: 20
2017-12-02 21:17:00,312:train.py:154 -         sample_input(): Trg: _BOS these are not just &quot; environmental &quot; questions . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 21:17:00,312:train.py:155 -         sample_input(): Tar: these are not just &quot; environmental &quot; questions . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 21:17:00,312:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-02 21:17:00,312:train.py:199 -         run_log_save(): Batch 1448, epoch 3/20:
2017-12-02 21:17:00,312:train.py:200 -         run_log_save():    avg word perp:   27.59
2017-12-02 21:17:00,312:train.py:201 -         run_log_save():    acc trg words/s: 2458
2017-12-02 21:17:00,312:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:18:05,422:train.py:199 -         run_log_save(): Batch 1548, epoch 3/20:
2017-12-02 21:18:05,422:train.py:200 -         run_log_save():    avg word perp:   27.41
2017-12-02 21:18:05,422:train.py:201 -         run_log_save():    acc trg words/s: 2460
2017-12-02 21:18:05,422:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:19:11,345:train.py:199 -         run_log_save(): Batch 1648, epoch 3/20:
2017-12-02 21:19:11,346:train.py:200 -         run_log_save():    avg word perp:   26.18
2017-12-02 21:19:11,346:train.py:201 -         run_log_save():    acc trg words/s: 2460
2017-12-02 21:19:11,346:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:20:17,862:train.py:199 -         run_log_save(): Batch 1748, epoch 3/20:
2017-12-02 21:20:17,862:train.py:200 -         run_log_save():    avg word perp:   26.18
2017-12-02 21:20:17,862:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-02 21:20:17,862:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:21:22,531:train.py:199 -         run_log_save(): Batch 1848, epoch 3/20:
2017-12-02 21:21:22,532:train.py:200 -         run_log_save():    avg word perp:   26.00
2017-12-02 21:21:22,532:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-02 21:21:22,532:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:22:28,800:train.py:199 -         run_log_save(): Batch 1948, epoch 3/20:
2017-12-02 21:22:28,801:train.py:200 -         run_log_save():    avg word perp:   25.90
2017-12-02 21:22:28,801:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-02 21:22:28,801:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:23:34,290:train.py:199 -         run_log_save(): Batch 2048, epoch 3/20:
2017-12-02 21:23:34,291:train.py:200 -         run_log_save():    avg word perp:   25.43
2017-12-02 21:23:34,291:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-02 21:23:34,291:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:24:39,178:train.py:199 -         run_log_save(): Batch 2148, epoch 3/20:
2017-12-02 21:24:39,179:train.py:200 -         run_log_save():    avg word perp:   25.96
2017-12-02 21:24:39,179:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-02 21:24:39,179:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:25:44,365:train.py:199 -         run_log_save(): Batch 2248, epoch 3/20:
2017-12-02 21:25:44,365:train.py:200 -         run_log_save():    avg word perp:   25.15
2017-12-02 21:25:44,366:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-02 21:25:44,366:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:26:49,671:train.py:199 -         run_log_save(): Batch 2348, epoch 3/20:
2017-12-02 21:26:49,671:train.py:200 -         run_log_save():    avg word perp:   24.63
2017-12-02 21:26:49,672:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-02 21:26:49,672:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:27:54,215:train.py:151 -         sample_input(): Sample input data:
2017-12-02 21:27:54,215:train.py:152 -         sample_input(): Src: . betroffen Finanzierung öffentliche entsprechende ohne zahlen Studenten@@ steigender an@@ weiter immer Elend dem von Großbritannien auch allerdings ist jetzt _PAD
2017-12-02 21:27:54,215:train.py:153 -         sample_input(): Src len: 20
2017-12-02 21:27:54,215:train.py:154 -         sample_input(): Trg: _BOS now , however , the mis@@ eries of expanding the number of university students without adequate public finance have invaded Britain as well . _PAD _PAD _PAD
2017-12-02 21:27:54,215:train.py:155 -         sample_input(): Tar: now , however , the mis@@ eries of expanding the number of university students without adequate public finance have invaded Britain as well . _EOS _PAD _PAD _PAD
2017-12-02 21:27:54,215:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0
2017-12-02 21:27:54,215:train.py:199 -         run_log_save(): Batch 2448, epoch 3/20:
2017-12-02 21:27:54,215:train.py:200 -         run_log_save():    avg word perp:   24.21
2017-12-02 21:27:54,215:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-02 21:27:54,215:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:28:53,335:train.py:199 -         run_log_save(): Batch 2548, epoch 3/20:
2017-12-02 21:28:53,335:train.py:200 -         run_log_save():    avg word perp:   26.06
2017-12-02 21:28:53,335:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 21:28:53,335:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:29:00,202:train.py:199 -         run_log_save(): Batch 2648, epoch 3/20:
2017-12-02 21:29:00,202:train.py:200 -         run_log_save():    avg word perp:   671.17
2017-12-02 21:29:00,202:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 21:29:00,202:train.py:202 -         run_log_save():    acc sec/batch:   0.63
2017-12-02 21:29:07,063:train.py:199 -         run_log_save(): Batch 2748, epoch 3/20:
2017-12-02 21:29:07,063:train.py:200 -         run_log_save():    avg word perp:   519.46
2017-12-02 21:29:07,063:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 21:29:07,063:train.py:202 -         run_log_save():    acc sec/batch:   0.61
2017-12-02 21:29:13,928:train.py:199 -         run_log_save(): Batch 2848, epoch 3/20:
2017-12-02 21:29:13,929:train.py:200 -         run_log_save():    avg word perp:   492.51
2017-12-02 21:29:13,929:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 21:29:13,929:train.py:202 -         run_log_save():    acc sec/batch:   0.59
2017-12-02 21:29:20,770:train.py:199 -         run_log_save(): Batch 2948, epoch 3/20:
2017-12-02 21:29:20,771:train.py:200 -         run_log_save():    avg word perp:   479.62
2017-12-02 21:29:20,771:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 21:29:20,771:train.py:202 -         run_log_save():    acc sec/batch:   0.57
2017-12-02 21:29:27,653:train.py:199 -         run_log_save(): Batch 3048, epoch 3/20:
2017-12-02 21:29:27,653:train.py:200 -         run_log_save():    avg word perp:   468.99
2017-12-02 21:29:27,653:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-02 21:29:27,653:train.py:202 -         run_log_save():    acc sec/batch:   0.55
2017-12-02 21:29:34,479:train.py:199 -         run_log_save(): Batch 3148, epoch 3/20:
2017-12-02 21:29:34,479:train.py:200 -         run_log_save():    avg word perp:   460.19
2017-12-02 21:29:34,480:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-02 21:29:34,480:train.py:202 -         run_log_save():    acc sec/batch:   0.54
2017-12-02 21:29:41,276:train.py:199 -         run_log_save(): Batch 3248, epoch 3/20:
2017-12-02 21:29:41,276:train.py:200 -         run_log_save():    avg word perp:   451.47
2017-12-02 21:29:41,276:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-02 21:29:41,276:train.py:202 -         run_log_save():    acc sec/batch:   0.52
2017-12-02 21:29:43,178:train.py:119 -         report_epoch(): Finish epoch 3
2017-12-02 21:29:43,178:train.py:120 -         report_epoch():     It takes 0:28:25.034415
2017-12-02 21:29:43,178:train.py:121 -         report_epoch():     Avergage # words/second    2464.6417481
2017-12-02 21:29:43,178:train.py:122 -         report_epoch():     Average seconds/batch    0.520462275497
2017-12-02 21:29:43,178:train.py:133 -         report_epoch():     train perplexity: 30.4926977636
2017-12-02 21:29:43,680:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.502017974854 seconds
2017-12-02 21:30:29,601:train.py:199 -         run_log_save(): Batch 72, epoch 4/20:
2017-12-02 21:30:29,602:train.py:200 -         run_log_save():    avg word perp:   30.27
2017-12-02 21:30:29,602:train.py:201 -         run_log_save():    acc trg words/s: 2426
2017-12-02 21:30:29,602:train.py:202 -         run_log_save():    acc sec/batch:   0.63
2017-12-02 21:31:35,556:train.py:151 -         sample_input(): Sample input data:
2017-12-02 21:31:35,556:train.py:152 -         sample_input(): Src: . Kapitalmärkten internationalen den zu mehr Zugang keinen haben Kreditgeber russische viele und , gestiegen Prozentpunkte 3 @-@ 2 um sind Anleihen Russlands für Zinssätze die _PAD _PAD
2017-12-02 21:31:35,556:train.py:153 -         sample_input(): Src len: 26
2017-12-02 21:31:35,556:train.py:154 -         sample_input(): Trg: _BOS interest rates on Russia &apos;s bonds have risen by 2 @-@ 3 percentage points , and many Russian creditors no longer have access to international capital markets . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 21:31:35,556:train.py:155 -         sample_input(): Tar: interest rates on Russia &apos;s bonds have risen by 2 @-@ 3 percentage points , and many Russian creditors no longer have access to international capital markets . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 21:31:35,556:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-02 21:31:35,557:train.py:199 -         run_log_save(): Batch 172, epoch 4/20:
2017-12-02 21:31:35,557:train.py:200 -         run_log_save():    avg word perp:   23.33
2017-12-02 21:31:35,557:train.py:201 -         run_log_save():    acc trg words/s: 2452
2017-12-02 21:31:35,557:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:31:38,835:train.py:207 -         run_log_save(): Save model to ./nmt/saved_models/de2en_bp/de2en_bp.cpkt, takes 0:00:03.278405
2017-12-02 21:32:43,501:train.py:199 -         run_log_save(): Batch 272, epoch 4/20:
2017-12-02 21:32:43,501:train.py:200 -         run_log_save():    avg word perp:   22.70
2017-12-02 21:32:43,501:train.py:201 -         run_log_save():    acc trg words/s: 2473
2017-12-02 21:32:43,502:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:33:49,104:train.py:199 -         run_log_save(): Batch 372, epoch 4/20:
2017-12-02 21:33:49,105:train.py:200 -         run_log_save():    avg word perp:   21.73
2017-12-02 21:33:49,105:train.py:201 -         run_log_save():    acc trg words/s: 2473
2017-12-02 21:33:49,105:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:34:54,095:train.py:199 -         run_log_save(): Batch 472, epoch 4/20:
2017-12-02 21:34:54,095:train.py:200 -         run_log_save():    avg word perp:   21.71
2017-12-02 21:34:54,095:train.py:201 -         run_log_save():    acc trg words/s: 2474
2017-12-02 21:34:54,095:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:35:59,915:train.py:199 -         run_log_save(): Batch 572, epoch 4/20:
2017-12-02 21:35:59,915:train.py:200 -         run_log_save():    avg word perp:   21.59
2017-12-02 21:35:59,915:train.py:201 -         run_log_save():    acc trg words/s: 2474
2017-12-02 21:35:59,915:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:37:05,634:train.py:199 -         run_log_save(): Batch 672, epoch 4/20:
2017-12-02 21:37:05,634:train.py:200 -         run_log_save():    avg word perp:   21.77
2017-12-02 21:37:05,635:train.py:201 -         run_log_save():    acc trg words/s: 2475
2017-12-02 21:37:05,635:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:38:12,040:train.py:199 -         run_log_save(): Batch 772, epoch 4/20:
2017-12-02 21:38:12,040:train.py:200 -         run_log_save():    avg word perp:   21.66
2017-12-02 21:38:12,040:train.py:201 -         run_log_save():    acc trg words/s: 2471
2017-12-02 21:38:12,040:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:39:17,572:train.py:199 -         run_log_save(): Batch 872, epoch 4/20:
2017-12-02 21:39:17,572:train.py:200 -         run_log_save():    avg word perp:   22.12
2017-12-02 21:39:17,572:train.py:201 -         run_log_save():    acc trg words/s: 2471
2017-12-02 21:39:17,572:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:40:22,724:train.py:199 -         run_log_save(): Batch 972, epoch 4/20:
2017-12-02 21:40:22,724:train.py:200 -         run_log_save():    avg word perp:   21.08
2017-12-02 21:40:22,724:train.py:201 -         run_log_save():    acc trg words/s: 2470
2017-12-02 21:40:22,724:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:41:28,317:train.py:199 -         run_log_save(): Batch 1072, epoch 4/20:
2017-12-02 21:41:28,317:train.py:200 -         run_log_save():    avg word perp:   20.93
2017-12-02 21:41:28,317:train.py:201 -         run_log_save():    acc trg words/s: 2470
2017-12-02 21:41:28,317:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:42:34,046:train.py:151 -         sample_input(): Sample input data:
2017-12-02 21:42:34,046:train.py:152 -         sample_input(): Src: . aufzubauen neues ein , hat zerstört Gaddafi das , Landes des inen Ru@@ den auf um , braucht Zeit rat National@@ der dass , verstehen Libyer _PAD
2017-12-02 21:42:34,046:train.py:153 -         sample_input(): Src len: 27
2017-12-02 21:42:34,046:train.py:154 -         sample_input(): Trg: _BOS Libyans understand that the NTC needs time to build a new country on the ruins of the one that Qaddafi destroyed . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 21:42:34,046:train.py:155 -         sample_input(): Tar: Libyans understand that the NTC needs time to build a new country on the ruins of the one that Qaddafi destroyed . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 21:42:34,046:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-02 21:42:34,047:train.py:199 -         run_log_save(): Batch 1172, epoch 4/20:
2017-12-02 21:42:34,047:train.py:200 -         run_log_save():    avg word perp:   20.97
2017-12-02 21:42:34,047:train.py:201 -         run_log_save():    acc trg words/s: 2470
2017-12-02 21:42:34,047:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:43:39,763:train.py:199 -         run_log_save(): Batch 1272, epoch 4/20:
2017-12-02 21:43:39,763:train.py:200 -         run_log_save():    avg word perp:   21.15
2017-12-02 21:43:39,763:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-02 21:43:39,764:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:44:45,181:train.py:199 -         run_log_save(): Batch 1372, epoch 4/20:
2017-12-02 21:44:45,182:train.py:200 -         run_log_save():    avg word perp:   20.53
2017-12-02 21:44:45,182:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-02 21:44:45,182:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:45:50,766:train.py:199 -         run_log_save(): Batch 1472, epoch 4/20:
2017-12-02 21:45:50,766:train.py:200 -         run_log_save():    avg word perp:   20.13
2017-12-02 21:45:50,766:train.py:201 -         run_log_save():    acc trg words/s: 2469
2017-12-02 21:45:50,766:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:46:55,950:train.py:199 -         run_log_save(): Batch 1572, epoch 4/20:
2017-12-02 21:46:55,950:train.py:200 -         run_log_save():    avg word perp:   20.31
2017-12-02 21:46:55,951:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-02 21:46:55,951:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:48:01,799:train.py:199 -         run_log_save(): Batch 1672, epoch 4/20:
2017-12-02 21:48:01,799:train.py:200 -         run_log_save():    avg word perp:   20.29
2017-12-02 21:48:01,799:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-02 21:48:01,799:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:49:07,452:train.py:199 -         run_log_save(): Batch 1772, epoch 4/20:
2017-12-02 21:49:07,452:train.py:200 -         run_log_save():    avg word perp:   20.31
2017-12-02 21:49:07,452:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-02 21:49:07,452:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:50:12,585:train.py:199 -         run_log_save(): Batch 1872, epoch 4/20:
2017-12-02 21:50:12,585:train.py:200 -         run_log_save():    avg word perp:   20.03
2017-12-02 21:50:12,585:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-02 21:50:12,586:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:51:17,857:train.py:199 -         run_log_save(): Batch 1972, epoch 4/20:
2017-12-02 21:51:17,857:train.py:200 -         run_log_save():    avg word perp:   19.85
2017-12-02 21:51:17,857:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-02 21:51:17,857:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:52:24,517:train.py:199 -         run_log_save(): Batch 2072, epoch 4/20:
2017-12-02 21:52:24,517:train.py:200 -         run_log_save():    avg word perp:   20.43
2017-12-02 21:52:24,517:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 21:52:24,517:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:53:31,150:train.py:151 -         sample_input(): Sample input data:
2017-12-02 21:53:31,150:train.py:152 -         sample_input(): Src: . wird ausgeübt USA den von Selbstverteidigung der Aufgabe souveräne Japans dass , darauf sich gründet Osten nen Fer@@ im Amerikas Position militärischen gesamten der Legitimität die _PAD
2017-12-02 21:53:31,150:train.py:153 -         sample_input(): Src len: 27
2017-12-02 21:53:31,150:train.py:154 -         sample_input(): Trg: _BOS the legitimacy of the entire American military position in the Far East is built around the US exercising Japan &apos;s sovereign function of self @-@ defense . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 21:53:31,150:train.py:155 -         sample_input(): Tar: the legitimacy of the entire American military position in the Far East is built around the US exercising Japan &apos;s sovereign function of self @-@ defense . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 21:53:31,150:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-02 21:53:31,150:train.py:199 -         run_log_save(): Batch 2172, epoch 4/20:
2017-12-02 21:53:31,151:train.py:200 -         run_log_save():    avg word perp:   19.99
2017-12-02 21:53:31,151:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-02 21:53:31,151:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:54:36,364:train.py:199 -         run_log_save(): Batch 2272, epoch 4/20:
2017-12-02 21:54:36,364:train.py:200 -         run_log_save():    avg word perp:   19.73
2017-12-02 21:54:36,364:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 21:54:36,364:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:55:42,223:train.py:199 -         run_log_save(): Batch 2372, epoch 4/20:
2017-12-02 21:55:42,223:train.py:200 -         run_log_save():    avg word perp:   19.31
2017-12-02 21:55:42,223:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-02 21:55:42,223:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:56:46,949:train.py:199 -         run_log_save(): Batch 2472, epoch 4/20:
2017-12-02 21:56:46,949:train.py:200 -         run_log_save():    avg word perp:   19.25
2017-12-02 21:56:46,949:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 21:56:46,949:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 21:57:31,891:train.py:199 -         run_log_save(): Batch 2572, epoch 4/20:
2017-12-02 21:57:31,891:train.py:200 -         run_log_save():    avg word perp:   24.18
2017-12-02 21:57:31,891:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-02 21:57:31,891:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-02 21:57:38,689:train.py:199 -         run_log_save(): Batch 2672, epoch 4/20:
2017-12-02 21:57:38,690:train.py:200 -         run_log_save():    avg word perp:   519.56
2017-12-02 21:57:38,690:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-02 21:57:38,690:train.py:202 -         run_log_save():    acc sec/batch:   0.62
2017-12-02 21:57:45,532:train.py:199 -         run_log_save(): Batch 2772, epoch 4/20:
2017-12-02 21:57:45,532:train.py:200 -         run_log_save():    avg word perp:   462.58
2017-12-02 21:57:45,532:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-02 21:57:45,532:train.py:202 -         run_log_save():    acc sec/batch:   0.60
2017-12-02 21:57:52,406:train.py:199 -         run_log_save(): Batch 2872, epoch 4/20:
2017-12-02 21:57:52,406:train.py:200 -         run_log_save():    avg word perp:   442.33
2017-12-02 21:57:52,407:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 21:57:52,407:train.py:202 -         run_log_save():    acc sec/batch:   0.58
2017-12-02 21:57:59,267:train.py:199 -         run_log_save(): Batch 2972, epoch 4/20:
2017-12-02 21:57:59,267:train.py:200 -         run_log_save():    avg word perp:   441.43
2017-12-02 21:57:59,267:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 21:57:59,267:train.py:202 -         run_log_save():    acc sec/batch:   0.57
2017-12-02 21:58:06,136:train.py:199 -         run_log_save(): Batch 3072, epoch 4/20:
2017-12-02 21:58:06,136:train.py:200 -         run_log_save():    avg word perp:   432.40
2017-12-02 21:58:06,137:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 21:58:06,137:train.py:202 -         run_log_save():    acc sec/batch:   0.55
2017-12-02 21:58:12,937:train.py:151 -         sample_input(): Sample input data:
2017-12-02 21:58:12,937:train.py:152 -         sample_input(): Src: darbietend
2017-12-02 21:58:12,937:train.py:153 -         sample_input(): Src len: 1
2017-12-02 21:58:12,937:train.py:154 -         sample_input(): Trg: _BOS presenting _PAD
2017-12-02 21:58:12,937:train.py:155 -         sample_input(): Tar: presenting _EOS _PAD
2017-12-02 21:58:12,937:train.py:156 -         sample_input(): W: 1.0 1.0 0.0
2017-12-02 21:58:12,937:train.py:199 -         run_log_save(): Batch 3172, epoch 4/20:
2017-12-02 21:58:12,937:train.py:200 -         run_log_save():    avg word perp:   411.04
2017-12-02 21:58:12,937:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 21:58:12,937:train.py:202 -         run_log_save():    acc sec/batch:   0.54
2017-12-02 21:58:19,755:train.py:199 -         run_log_save(): Batch 3272, epoch 4/20:
2017-12-02 21:58:19,755:train.py:200 -         run_log_save():    avg word perp:   427.84
2017-12-02 21:58:19,756:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 21:58:19,756:train.py:202 -         run_log_save():    acc sec/batch:   0.52
2017-12-02 21:58:20,075:train.py:119 -         report_epoch(): Finish epoch 4
2017-12-02 21:58:20,075:train.py:120 -         report_epoch():     It takes 0:28:24.703761
2017-12-02 21:58:20,075:train.py:121 -         report_epoch():     Avergage # words/second    2465.14385391
2017-12-02 21:58:20,075:train.py:122 -         report_epoch():     Average seconds/batch    0.52036134351
2017-12-02 21:58:20,075:train.py:133 -         report_epoch():     train perplexity: 22.9261760494
2017-12-02 21:58:20,608:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.531832933426 seconds
2017-12-02 21:59:22,237:train.py:199 -         run_log_save(): Batch 96, epoch 5/20:
2017-12-02 21:59:22,237:train.py:200 -         run_log_save():    avg word perp:   20.29
2017-12-02 21:59:22,237:train.py:201 -         run_log_save():    acc trg words/s: 2460
2017-12-02 21:59:22,237:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-02 22:00:28,029:train.py:199 -         run_log_save(): Batch 196, epoch 5/20:
2017-12-02 22:00:28,029:train.py:200 -         run_log_save():    avg word perp:   17.74
2017-12-02 22:00:28,029:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-02 22:00:28,029:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:01:33,885:train.py:199 -         run_log_save(): Batch 296, epoch 5/20:
2017-12-02 22:01:33,887:train.py:200 -         run_log_save():    avg word perp:   17.97
2017-12-02 22:01:33,887:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-02 22:01:33,887:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:02:40,177:train.py:199 -         run_log_save(): Batch 396, epoch 5/20:
2017-12-02 22:02:40,177:train.py:200 -         run_log_save():    avg word perp:   17.72
2017-12-02 22:02:40,177:train.py:201 -         run_log_save():    acc trg words/s: 2452
2017-12-02 22:02:40,177:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:03:44,422:train.py:199 -         run_log_save(): Batch 496, epoch 5/20:
2017-12-02 22:03:44,422:train.py:200 -         run_log_save():    avg word perp:   17.61
2017-12-02 22:03:44,422:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-02 22:03:44,422:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:04:50,718:train.py:199 -         run_log_save(): Batch 596, epoch 5/20:
2017-12-02 22:04:50,718:train.py:200 -         run_log_save():    avg word perp:   17.20
2017-12-02 22:04:50,718:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-02 22:04:50,718:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:05:57,152:train.py:199 -         run_log_save(): Batch 696, epoch 5/20:
2017-12-02 22:05:57,152:train.py:200 -         run_log_save():    avg word perp:   17.47
2017-12-02 22:05:57,152:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-02 22:05:57,153:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:07:03,292:train.py:199 -         run_log_save(): Batch 796, epoch 5/20:
2017-12-02 22:07:03,293:train.py:200 -         run_log_save():    avg word perp:   17.00
2017-12-02 22:07:03,293:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-02 22:07:03,293:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:08:09,163:train.py:151 -         sample_input(): Sample input data:
2017-12-02 22:08:09,163:train.py:152 -         sample_input(): Src: . folgen letztlich wird , ist anerkannt nicht UNO der von aber , unabhängig zwar momentan der , Kosovo der auch . angeschlossen UNO der sich und verlassen bereits Organisation die haben Mitglieder sechs _PAD _PAD
2017-12-02 22:08:09,163:train.py:153 -         sample_input(): Src len: 34
2017-12-02 22:08:09,163:train.py:154 -         sample_input(): Trg: _BOS political ma@@ ps are never car@@ ved in stone . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 22:08:09,163:train.py:155 -         sample_input(): Tar: political ma@@ ps are never car@@ ved in stone . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 22:08:09,163:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-02 22:08:09,163:train.py:199 -         run_log_save(): Batch 896, epoch 5/20:
2017-12-02 22:08:09,163:train.py:200 -         run_log_save():    avg word perp:   17.03
2017-12-02 22:08:09,163:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-02 22:08:09,163:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:08:09,163:validator.py:224 -    validate_and_save(): Start validation
2017-12-02 22:09:14,349:validator.py:143 -             evaluate():   Translating line 100, average 0.651848618984 seconds/sent
2017-12-02 22:10:19,321:validator.py:143 -             evaluate():   Translating line 200, average 0.650784488916 seconds/sent
2017-12-02 22:11:17,270:validator.py:143 -             evaluate():   Translating line 300, average 0.627021196683 seconds/sent
2017-12-02 22:12:17,391:validator.py:143 -             evaluate():   Translating line 400, average 0.620567719936 seconds/sent
2017-12-02 22:13:24,900:validator.py:143 -             evaluate():   Translating line 500, average 0.63147134161 seconds/sent
2017-12-02 22:14:23,883:validator.py:143 -             evaluate():   Translating line 600, average 0.624532166322 seconds/sent
2017-12-02 22:15:31,624:validator.py:143 -             evaluate():   Translating line 700, average 0.632086119992 seconds/sent
2017-12-02 22:16:27,290:validator.py:143 -             evaluate():   Translating line 800, average 0.622657373548 seconds/sent
2017-12-02 22:17:11,569:validator.py:143 -             evaluate():   Translating line 900, average 0.602671956486 seconds/sent
2017-12-02 22:18:09,103:validator.py:143 -             evaluate():   Translating line 1000, average 0.599938821793 seconds/sent
2017-12-02 22:19:08,597:validator.py:143 -             evaluate():   Translating line 1100, average 0.599484441714 seconds/sent
2017-12-02 22:20:01,603:validator.py:143 -             evaluate():   Translating line 1200, average 0.593699131608 seconds/sent
2017-12-02 22:21:12,517:validator.py:143 -             evaluate():   Translating line 1300, average 0.602578932139 seconds/sent
2017-12-02 22:22:16,731:validator.py:143 -             evaluate():   Translating line 1400, average 0.605405129875 seconds/sent
2017-12-02 22:23:22,177:validator.py:143 -             evaluate():   Translating line 1500, average 0.608675531228 seconds/sent
2017-12-02 22:24:28,649:validator.py:143 -             evaluate():   Translating line 1600, average 0.612177856117 seconds/sent
2017-12-02 22:25:27,540:validator.py:143 -             evaluate():   Translating line 1700, average 0.610809132913 seconds/sent
2017-12-02 22:26:42,963:validator.py:143 -             evaluate():   Translating line 1800, average 0.618777186076 seconds/sent
2017-12-02 22:27:52,603:validator.py:143 -             evaluate():   Translating line 1900, average 0.622862493113 seconds/sent
2017-12-02 22:28:32,439:validator.py:152 -             evaluate(): Done translating.
2017-12-02 22:28:32,439:validator.py:153 -             evaluate(): dev perplexity: 106.503
2017-12-02 22:28:32,936:validator.py:159 -             evaluate(): BLEU = 9.28, 34.5/13.0/5.9/2.8 (BP=1.000, ratio=1.065, hyp_len=48235, ref_len=45274)

2017-12-02 22:28:32,936:validator.py:160 -             evaluate(): Validation took: 20.3961977323 minutes
2017-12-02 22:28:32,939:validator.py:195 -           maybe_save(): Current best bleus: 7.31
2017-12-02 22:28:32,940:validator.py:196 -           maybe_save(): Delete 7.31 & use 9.28 instead
2017-12-02 22:28:32,940:validator.py:206 -           maybe_save(): Delete ./nmt/saved_models/de2en_bp/de2en_bp-7.31.cpkt.data-00000-of-00001 & ./nmt/saved_models/de2en_bp/de2en_bp-7.31.cpkt.meta & ./nmt/saved_models/de2en_bp/de2en_bp-7.31.cpkt.index
2017-12-02 22:28:32,962:validator.py:212 -           maybe_save(): Save 9.28 to list of best bleu scores
2017-12-02 22:28:33,541:validator.py:216 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en_bp/de2en_bp-9.28.cpkt
2017-12-02 22:28:33,541:validator.py:217 -           maybe_save(): Best bleu scores so far: 9.28
2017-12-02 22:29:39,375:train.py:199 -         run_log_save(): Batch 996, epoch 5/20:
2017-12-02 22:29:39,375:train.py:200 -         run_log_save():    avg word perp:   17.22
2017-12-02 22:29:39,375:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-02 22:29:39,375:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:30:45,185:train.py:199 -         run_log_save(): Batch 1096, epoch 5/20:
2017-12-02 22:30:45,185:train.py:200 -         run_log_save():    avg word perp:   17.14
2017-12-02 22:30:45,185:train.py:201 -         run_log_save():    acc trg words/s: 2455
2017-12-02 22:30:45,185:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:31:50,259:train.py:199 -         run_log_save(): Batch 1196, epoch 5/20:
2017-12-02 22:31:50,259:train.py:200 -         run_log_save():    avg word perp:   17.13
2017-12-02 22:31:50,259:train.py:201 -         run_log_save():    acc trg words/s: 2458
2017-12-02 22:31:50,260:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:32:55,302:train.py:199 -         run_log_save(): Batch 1296, epoch 5/20:
2017-12-02 22:32:55,303:train.py:200 -         run_log_save():    avg word perp:   17.23
2017-12-02 22:32:55,303:train.py:201 -         run_log_save():    acc trg words/s: 2460
2017-12-02 22:32:55,303:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:34:00,087:train.py:199 -         run_log_save(): Batch 1396, epoch 5/20:
2017-12-02 22:34:00,087:train.py:200 -         run_log_save():    avg word perp:   16.68
2017-12-02 22:34:00,087:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-02 22:34:00,087:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:35:05,517:train.py:199 -         run_log_save(): Batch 1496, epoch 5/20:
2017-12-02 22:35:05,517:train.py:200 -         run_log_save():    avg word perp:   17.13
2017-12-02 22:35:05,517:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-02 22:35:05,518:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:36:10,231:train.py:199 -         run_log_save(): Batch 1596, epoch 5/20:
2017-12-02 22:36:10,231:train.py:200 -         run_log_save():    avg word perp:   17.13
2017-12-02 22:36:10,231:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-02 22:36:10,231:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:37:16,170:train.py:199 -         run_log_save(): Batch 1696, epoch 5/20:
2017-12-02 22:37:16,170:train.py:200 -         run_log_save():    avg word perp:   17.01
2017-12-02 22:37:16,170:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-02 22:37:16,171:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:38:22,150:train.py:199 -         run_log_save(): Batch 1796, epoch 5/20:
2017-12-02 22:38:22,151:train.py:200 -         run_log_save():    avg word perp:   16.67
2017-12-02 22:38:22,151:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-02 22:38:22,151:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:39:27,087:train.py:151 -         sample_input(): Sample input data:
2017-12-02 22:39:27,087:train.py:152 -         sample_input(): Src: . Staat der tut bezahlen . versicherung Lebens@@ und - täts@@ di@@ ali@@ Inv@@ der Berücksichtigung ohne - kosten Tag pro Dollar 1.000 als mehr kann Security water Black@@ von mann Wach@@ ein _PAD _PAD _PAD
2017-12-02 22:39:27,087:train.py:153 -         sample_input(): Src len: 33
2017-12-02 22:39:27,087:train.py:154 -         sample_input(): Trg: _BOS a Black@@ water Security guard can cost more than $ 1,000 per day , not including disability and life insurance , which is paid for by the government . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 22:39:27,087:train.py:155 -         sample_input(): Tar: a Black@@ water Security guard can cost more than $ 1,000 per day , not including disability and life insurance , which is paid for by the government . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 22:39:27,087:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-02 22:39:27,087:train.py:199 -         run_log_save(): Batch 1896, epoch 5/20:
2017-12-02 22:39:27,087:train.py:200 -         run_log_save():    avg word perp:   16.34
2017-12-02 22:39:27,087:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-02 22:39:27,087:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:39:30,371:train.py:207 -         run_log_save(): Save model to ./nmt/saved_models/de2en_bp/de2en_bp.cpkt, takes 0:00:03.283912
2017-12-02 22:40:36,482:train.py:199 -         run_log_save(): Batch 1996, epoch 5/20:
2017-12-02 22:40:36,482:train.py:200 -         run_log_save():    avg word perp:   16.74
2017-12-02 22:40:36,482:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-02 22:40:36,482:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:41:41,842:train.py:199 -         run_log_save(): Batch 2096, epoch 5/20:
2017-12-02 22:41:41,843:train.py:200 -         run_log_save():    avg word perp:   16.36
2017-12-02 22:41:41,843:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-02 22:41:41,843:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:42:47,134:train.py:199 -         run_log_save(): Batch 2196, epoch 5/20:
2017-12-02 22:42:47,134:train.py:200 -         run_log_save():    avg word perp:   16.67
2017-12-02 22:42:47,134:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 22:42:47,134:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:43:52,454:train.py:199 -         run_log_save(): Batch 2296, epoch 5/20:
2017-12-02 22:43:52,454:train.py:200 -         run_log_save():    avg word perp:   16.30
2017-12-02 22:43:52,454:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 22:43:52,454:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:44:58,193:train.py:199 -         run_log_save(): Batch 2396, epoch 5/20:
2017-12-02 22:44:58,193:train.py:200 -         run_log_save():    avg word perp:   16.62
2017-12-02 22:44:58,193:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-02 22:44:58,193:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:46:04,308:train.py:199 -         run_log_save(): Batch 2496, epoch 5/20:
2017-12-02 22:46:04,308:train.py:200 -         run_log_save():    avg word perp:   16.72
2017-12-02 22:46:04,308:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-02 22:46:04,309:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:46:34,864:train.py:199 -         run_log_save(): Batch 2596, epoch 5/20:
2017-12-02 22:46:34,864:train.py:200 -         run_log_save():    avg word perp:   27.35
2017-12-02 22:46:34,864:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-02 22:46:34,864:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-02 22:46:41,718:train.py:199 -         run_log_save(): Batch 2696, epoch 5/20:
2017-12-02 22:46:41,718:train.py:200 -         run_log_save():    avg word perp:   482.65
2017-12-02 22:46:41,718:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-02 22:46:41,718:train.py:202 -         run_log_save():    acc sec/batch:   0.62
2017-12-02 22:46:48,571:train.py:199 -         run_log_save(): Batch 2796, epoch 5/20:
2017-12-02 22:46:48,571:train.py:200 -         run_log_save():    avg word perp:   443.00
2017-12-02 22:46:48,571:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 22:46:48,571:train.py:202 -         run_log_save():    acc sec/batch:   0.60
2017-12-02 22:46:55,431:train.py:151 -         sample_input(): Sample input data:
2017-12-02 22:46:55,431:train.py:152 -         sample_input(): Src: _UNK
2017-12-02 22:46:55,431:train.py:153 -         sample_input(): Src len: 1
2017-12-02 22:46:55,431:train.py:154 -         sample_input(): Trg: _BOS tremendous success
2017-12-02 22:46:55,431:train.py:155 -         sample_input(): Tar: tremendous success _EOS
2017-12-02 22:46:55,431:train.py:156 -         sample_input(): W: 1.0 1.0 1.0
2017-12-02 22:46:55,431:train.py:199 -         run_log_save(): Batch 2896, epoch 5/20:
2017-12-02 22:46:55,432:train.py:200 -         run_log_save():    avg word perp:   439.44
2017-12-02 22:46:55,432:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 22:46:55,432:train.py:202 -         run_log_save():    acc sec/batch:   0.58
2017-12-02 22:47:02,304:train.py:199 -         run_log_save(): Batch 2996, epoch 5/20:
2017-12-02 22:47:02,305:train.py:200 -         run_log_save():    avg word perp:   420.31
2017-12-02 22:47:02,305:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 22:47:02,305:train.py:202 -         run_log_save():    acc sec/batch:   0.56
2017-12-02 22:47:09,160:train.py:199 -         run_log_save(): Batch 3096, epoch 5/20:
2017-12-02 22:47:09,160:train.py:200 -         run_log_save():    avg word perp:   406.59
2017-12-02 22:47:09,160:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 22:47:09,160:train.py:202 -         run_log_save():    acc sec/batch:   0.55
2017-12-02 22:47:16,015:train.py:199 -         run_log_save(): Batch 3196, epoch 5/20:
2017-12-02 22:47:16,015:train.py:200 -         run_log_save():    avg word perp:   426.40
2017-12-02 22:47:16,015:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 22:47:16,015:train.py:202 -         run_log_save():    acc sec/batch:   0.53
2017-12-02 22:47:21,489:train.py:119 -         report_epoch(): Finish epoch 5
2017-12-02 22:47:21,491:train.py:120 -         report_epoch():     It takes 0:28:24.775580
2017-12-02 22:47:21,491:train.py:121 -         report_epoch():     Avergage # words/second    2465.03765626
2017-12-02 22:47:21,491:train.py:122 -         report_epoch():     Average seconds/batch    0.520383266157
2017-12-02 22:47:21,491:train.py:133 -         report_epoch():     train perplexity: 18.8271321047
2017-12-02 22:47:21,970:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.479290962219 seconds
2017-12-02 22:47:34,873:train.py:199 -         run_log_save(): Batch 20, epoch 6/20:
2017-12-02 22:47:34,874:train.py:200 -         run_log_save():    avg word perp:   56.04
2017-12-02 22:47:34,874:train.py:201 -         run_log_save():    acc trg words/s: 2505
2017-12-02 22:47:34,874:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-02 22:48:41,642:train.py:199 -         run_log_save(): Batch 120, epoch 6/20:
2017-12-02 22:48:41,642:train.py:200 -         run_log_save():    avg word perp:   15.85
2017-12-02 22:48:41,642:train.py:201 -         run_log_save():    acc trg words/s: 2444
2017-12-02 22:48:41,642:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 22:49:47,095:train.py:199 -         run_log_save(): Batch 220, epoch 6/20:
2017-12-02 22:49:47,095:train.py:200 -         run_log_save():    avg word perp:   15.08
2017-12-02 22:49:47,096:train.py:201 -         run_log_save():    acc trg words/s: 2452
2017-12-02 22:49:47,096:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 22:50:52,650:train.py:199 -         run_log_save(): Batch 320, epoch 6/20:
2017-12-02 22:50:52,650:train.py:200 -         run_log_save():    avg word perp:   15.09
2017-12-02 22:50:52,650:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-02 22:50:52,650:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 22:51:58,653:train.py:199 -         run_log_save(): Batch 420, epoch 6/20:
2017-12-02 22:51:58,653:train.py:200 -         run_log_save():    avg word perp:   15.07
2017-12-02 22:51:58,653:train.py:201 -         run_log_save():    acc trg words/s: 2452
2017-12-02 22:51:58,653:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 22:53:04,228:train.py:199 -         run_log_save(): Batch 520, epoch 6/20:
2017-12-02 22:53:04,228:train.py:200 -         run_log_save():    avg word perp:   14.62
2017-12-02 22:53:04,228:train.py:201 -         run_log_save():    acc trg words/s: 2455
2017-12-02 22:53:04,228:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-02 22:54:09,942:train.py:151 -         sample_input(): Sample input data:
2017-12-02 22:54:09,942:train.py:152 -         sample_input(): Src: . fiziert klassi@@ &quot; ose Psych@@ auf drom syn@@ Risiko@@ &quot; als , entwickeln zu Störung tische psycho@@ eine hindeutet Risiko erhöhtes ein auf aber , gilt Störung als nicht gegenwärtig das , Denken benes ro@@ versch@@ oder loses ziel@@ , netes ord@@ unge@@ würde ebenso _PAD _PAD _PAD _PAD
2017-12-02 22:54:09,942:train.py:153 -         sample_input(): Src len: 46
2017-12-02 22:54:09,942:train.py:154 -         sample_input(): Trg: _BOS likewise , loose or qu@@ ir@@ ky thinking that is not now a disorder but indicates an increased risk of developing a psycho@@ tic disorder would be classified as a &quot; psycho@@ tic risk disorder . &quot; _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 22:54:09,943:train.py:155 -         sample_input(): Tar: likewise , loose or qu@@ ir@@ ky thinking that is not now a disorder but indicates an increased risk of developing a psycho@@ tic disorder would be classified as a &quot; psycho@@ tic risk disorder . &quot; _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 22:54:09,943:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-02 22:54:09,943:train.py:199 -         run_log_save(): Batch 620, epoch 6/20:
2017-12-02 22:54:09,943:train.py:200 -         run_log_save():    avg word perp:   14.76
2017-12-02 22:54:09,943:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-02 22:54:09,943:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:55:15,509:train.py:199 -         run_log_save(): Batch 720, epoch 6/20:
2017-12-02 22:55:15,509:train.py:200 -         run_log_save():    avg word perp:   14.80
2017-12-02 22:55:15,509:train.py:201 -         run_log_save():    acc trg words/s: 2455
2017-12-02 22:55:15,509:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:56:20,818:train.py:199 -         run_log_save(): Batch 820, epoch 6/20:
2017-12-02 22:56:20,818:train.py:200 -         run_log_save():    avg word perp:   15.06
2017-12-02 22:56:20,818:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-02 22:56:20,818:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:57:26,673:train.py:199 -         run_log_save(): Batch 920, epoch 6/20:
2017-12-02 22:57:26,674:train.py:200 -         run_log_save():    avg word perp:   15.11
2017-12-02 22:57:26,674:train.py:201 -         run_log_save():    acc trg words/s: 2458
2017-12-02 22:57:26,674:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:58:32,798:train.py:199 -         run_log_save(): Batch 1020, epoch 6/20:
2017-12-02 22:58:32,798:train.py:200 -         run_log_save():    avg word perp:   14.79
2017-12-02 22:58:32,798:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-02 22:58:32,798:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 22:59:38,327:train.py:199 -         run_log_save(): Batch 1120, epoch 6/20:
2017-12-02 22:59:38,327:train.py:200 -         run_log_save():    avg word perp:   14.72
2017-12-02 22:59:38,327:train.py:201 -         run_log_save():    acc trg words/s: 2458
2017-12-02 22:59:38,327:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:00:43,827:train.py:199 -         run_log_save(): Batch 1220, epoch 6/20:
2017-12-02 23:00:43,827:train.py:200 -         run_log_save():    avg word perp:   14.64
2017-12-02 23:00:43,827:train.py:201 -         run_log_save():    acc trg words/s: 2460
2017-12-02 23:00:43,827:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:01:48,381:train.py:199 -         run_log_save(): Batch 1320, epoch 6/20:
2017-12-02 23:01:48,382:train.py:200 -         run_log_save():    avg word perp:   14.74
2017-12-02 23:01:48,382:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-02 23:01:48,382:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:02:53,314:train.py:199 -         run_log_save(): Batch 1420, epoch 6/20:
2017-12-02 23:02:53,314:train.py:200 -         run_log_save():    avg word perp:   14.90
2017-12-02 23:02:53,314:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-02 23:02:53,314:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:03:58,556:train.py:199 -         run_log_save(): Batch 1520, epoch 6/20:
2017-12-02 23:03:58,556:train.py:200 -         run_log_save():    avg word perp:   14.72
2017-12-02 23:03:58,556:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-02 23:03:58,556:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:05:03,075:train.py:151 -         sample_input(): Sample input data:
2017-12-02 23:05:03,075:train.py:152 -         sample_input(): Src: . angehen Probleme die und werden aktiv wir dass , führt dazu reaktionen Abwehr@@ und k än@@ z@@ Ge@@ lichem klein@@ zu statt die , Weise einer in und entschieden , klar , müssen aussprechen es wir werden Gipfel @-@ 20 + Rio dem auf _PAD _PAD _PAD _PAD _PAD
2017-12-02 23:05:03,075:train.py:153 -         sample_input(): Src len: 45
2017-12-02 23:05:03,076:train.py:154 -         sample_input(): Trg: _BOS at Rio + 20 we will have to say so , clearly , decisively , and in a way that leads to problem @-@ solving and action , not to bickering and defen@@ siveness . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 23:05:03,076:train.py:155 -         sample_input(): Tar: at Rio + 20 we will have to say so , clearly , decisively , and in a way that leads to problem @-@ solving and action , not to bickering and defen@@ siveness . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 23:05:03,076:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-02 23:05:03,076:train.py:199 -         run_log_save(): Batch 1620, epoch 6/20:
2017-12-02 23:05:03,076:train.py:200 -         run_log_save():    avg word perp:   14.40
2017-12-02 23:05:03,076:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-02 23:05:03,076:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:06:07,403:train.py:199 -         run_log_save(): Batch 1720, epoch 6/20:
2017-12-02 23:06:07,403:train.py:200 -         run_log_save():    avg word perp:   14.21
2017-12-02 23:06:07,403:train.py:201 -         run_log_save():    acc trg words/s: 2470
2017-12-02 23:06:07,403:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:07:14,075:train.py:199 -         run_log_save(): Batch 1820, epoch 6/20:
2017-12-02 23:07:14,075:train.py:200 -         run_log_save():    avg word perp:   14.50
2017-12-02 23:07:14,075:train.py:201 -         run_log_save():    acc trg words/s: 2469
2017-12-02 23:07:14,075:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:08:20,182:train.py:199 -         run_log_save(): Batch 1920, epoch 6/20:
2017-12-02 23:08:20,183:train.py:200 -         run_log_save():    avg word perp:   14.57
2017-12-02 23:08:20,183:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-02 23:08:20,183:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:09:26,550:train.py:199 -         run_log_save(): Batch 2020, epoch 6/20:
2017-12-02 23:09:26,550:train.py:200 -         run_log_save():    avg word perp:   14.39
2017-12-02 23:09:26,550:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-02 23:09:26,550:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:10:32,531:train.py:199 -         run_log_save(): Batch 2120, epoch 6/20:
2017-12-02 23:10:32,531:train.py:200 -         run_log_save():    avg word perp:   14.40
2017-12-02 23:10:32,531:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-02 23:10:32,531:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:11:36,783:train.py:199 -         run_log_save(): Batch 2220, epoch 6/20:
2017-12-02 23:11:36,783:train.py:200 -         run_log_save():    avg word perp:   14.24
2017-12-02 23:11:36,783:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-02 23:11:36,783:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:12:42,079:train.py:199 -         run_log_save(): Batch 2320, epoch 6/20:
2017-12-02 23:12:42,079:train.py:200 -         run_log_save():    avg word perp:   14.38
2017-12-02 23:12:42,079:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-02 23:12:42,079:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:13:47,481:train.py:199 -         run_log_save(): Batch 2420, epoch 6/20:
2017-12-02 23:13:47,481:train.py:200 -         run_log_save():    avg word perp:   14.02
2017-12-02 23:13:47,481:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-02 23:13:47,481:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:14:53,120:train.py:199 -         run_log_save(): Batch 2520, epoch 6/20:
2017-12-02 23:14:53,120:train.py:200 -         run_log_save():    avg word perp:   14.30
2017-12-02 23:14:53,120:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-02 23:14:53,120:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:15:08,756:train.py:151 -         sample_input(): Sample input data:
2017-12-02 23:15:08,756:train.py:152 -         sample_input(): Src: _UNK
2017-12-02 23:15:08,756:train.py:153 -         sample_input(): Src len: 1
2017-12-02 23:15:08,756:train.py:154 -         sample_input(): Trg: _BOS wage component
2017-12-02 23:15:08,756:train.py:155 -         sample_input(): Tar: wage component _EOS
2017-12-02 23:15:08,756:train.py:156 -         sample_input(): W: 1.0 1.0 1.0
2017-12-02 23:15:08,756:train.py:199 -         run_log_save(): Batch 2620, epoch 6/20:
2017-12-02 23:15:08,756:train.py:200 -         run_log_save():    avg word perp:   59.47
2017-12-02 23:15:08,756:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-02 23:15:08,756:train.py:202 -         run_log_save():    acc sec/batch:   0.63
2017-12-02 23:15:15,618:train.py:199 -         run_log_save(): Batch 2720, epoch 6/20:
2017-12-02 23:15:15,618:train.py:200 -         run_log_save():    avg word perp:   457.75
2017-12-02 23:15:15,618:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-02 23:15:15,618:train.py:202 -         run_log_save():    acc sec/batch:   0.61
2017-12-02 23:15:22,451:train.py:199 -         run_log_save(): Batch 2820, epoch 6/20:
2017-12-02 23:15:22,451:train.py:200 -         run_log_save():    avg word perp:   431.78
2017-12-02 23:15:22,451:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-02 23:15:22,451:train.py:202 -         run_log_save():    acc sec/batch:   0.59
2017-12-02 23:15:29,294:train.py:199 -         run_log_save(): Batch 2920, epoch 6/20:
2017-12-02 23:15:29,294:train.py:200 -         run_log_save():    avg word perp:   425.55
2017-12-02 23:15:29,294:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-02 23:15:29,294:train.py:202 -         run_log_save():    acc sec/batch:   0.58
2017-12-02 23:15:36,140:train.py:199 -         run_log_save(): Batch 3020, epoch 6/20:
2017-12-02 23:15:36,140:train.py:200 -         run_log_save():    avg word perp:   404.45
2017-12-02 23:15:36,140:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-02 23:15:36,140:train.py:202 -         run_log_save():    acc sec/batch:   0.56
2017-12-02 23:15:42,984:train.py:199 -         run_log_save(): Batch 3120, epoch 6/20:
2017-12-02 23:15:42,984:train.py:200 -         run_log_save():    avg word perp:   411.17
2017-12-02 23:15:42,984:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-02 23:15:42,984:train.py:202 -         run_log_save():    acc sec/batch:   0.54
2017-12-02 23:15:49,813:train.py:199 -         run_log_save(): Batch 3220, epoch 6/20:
2017-12-02 23:15:49,813:train.py:200 -         run_log_save():    avg word perp:   406.31
2017-12-02 23:15:49,813:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-02 23:15:49,813:train.py:202 -         run_log_save():    acc sec/batch:   0.53
2017-12-02 23:15:53,666:train.py:119 -         report_epoch(): Finish epoch 6
2017-12-02 23:15:53,667:train.py:120 -         report_epoch():     It takes 0:28:23.298253
2017-12-02 23:15:53,667:train.py:121 -         report_epoch():     Avergage # words/second    2467.13926562
2017-12-02 23:15:53,667:train.py:122 -         report_epoch():     Average seconds/batch    0.519932311533
2017-12-02 23:15:53,667:train.py:133 -         report_epoch():     train perplexity: 16.2675811444
2017-12-02 23:15:54,193:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.526027917862 seconds
2017-12-02 23:16:21,757:train.py:199 -         run_log_save(): Batch 44, epoch 7/20:
2017-12-02 23:16:21,757:train.py:200 -         run_log_save():    avg word perp:   23.41
2017-12-02 23:16:21,757:train.py:201 -         run_log_save():    acc trg words/s: 2431
2017-12-02 23:16:21,757:train.py:202 -         run_log_save():    acc sec/batch:   0.62
2017-12-02 23:17:27,381:train.py:199 -         run_log_save(): Batch 144, epoch 7/20:
2017-12-02 23:17:27,381:train.py:200 -         run_log_save():    avg word perp:   13.90
2017-12-02 23:17:27,381:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-02 23:17:27,381:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-02 23:18:32,053:train.py:199 -         run_log_save(): Batch 244, epoch 7/20:
2017-12-02 23:18:32,053:train.py:200 -         run_log_save():    avg word perp:   13.37
2017-12-02 23:18:32,053:train.py:201 -         run_log_save():    acc trg words/s: 2480
2017-12-02 23:18:32,053:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-02 23:19:37,772:train.py:151 -         sample_input(): Sample input data:
2017-12-02 23:19:37,772:train.py:152 -         sample_input(): Src: . USA der orge Haupts@@ eine Tage dieser ist , beschwichtigen zu Ängste diese _PAD
2017-12-02 23:19:37,772:train.py:153 -         sample_input(): Src len: 14
2017-12-02 23:19:37,772:train.py:154 -         sample_input(): Trg: _BOS easing those fears is big concern in the US these days . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 23:19:37,772:train.py:155 -         sample_input(): Tar: easing those fears is big concern in the US these days . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 23:19:37,772:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-02 23:19:37,772:train.py:199 -         run_log_save(): Batch 344, epoch 7/20:
2017-12-02 23:19:37,773:train.py:200 -         run_log_save():    avg word perp:   13.02
2017-12-02 23:19:37,773:train.py:201 -         run_log_save():    acc trg words/s: 2475
2017-12-02 23:19:37,773:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:19:41,124:train.py:207 -         run_log_save(): Save model to ./nmt/saved_models/de2en_bp/de2en_bp.cpkt, takes 0:00:03.351062
2017-12-02 23:20:46,921:train.py:199 -         run_log_save(): Batch 444, epoch 7/20:
2017-12-02 23:20:46,923:train.py:200 -         run_log_save():    avg word perp:   13.15
2017-12-02 23:20:46,923:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-02 23:20:46,923:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:21:52,768:train.py:199 -         run_log_save(): Batch 544, epoch 7/20:
2017-12-02 23:21:52,769:train.py:200 -         run_log_save():    avg word perp:   13.26
2017-12-02 23:21:52,769:train.py:201 -         run_log_save():    acc trg words/s: 2469
2017-12-02 23:21:52,769:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:22:57,858:train.py:199 -         run_log_save(): Batch 644, epoch 7/20:
2017-12-02 23:22:57,859:train.py:200 -         run_log_save():    avg word perp:   13.16
2017-12-02 23:22:57,859:train.py:201 -         run_log_save():    acc trg words/s: 2474
2017-12-02 23:22:57,859:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:24:04,920:train.py:199 -         run_log_save(): Batch 744, epoch 7/20:
2017-12-02 23:24:04,920:train.py:200 -         run_log_save():    avg word perp:   13.21
2017-12-02 23:24:04,920:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-02 23:24:04,920:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:25:10,784:train.py:199 -         run_log_save(): Batch 844, epoch 7/20:
2017-12-02 23:25:10,784:train.py:200 -         run_log_save():    avg word perp:   13.07
2017-12-02 23:25:10,784:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-02 23:25:10,784:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:26:15,991:train.py:199 -         run_log_save(): Batch 944, epoch 7/20:
2017-12-02 23:26:15,991:train.py:200 -         run_log_save():    avg word perp:   12.92
2017-12-02 23:26:15,991:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-02 23:26:15,991:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:27:21,747:train.py:199 -         run_log_save(): Batch 1044, epoch 7/20:
2017-12-02 23:27:21,747:train.py:200 -         run_log_save():    avg word perp:   12.84
2017-12-02 23:27:21,747:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-02 23:27:21,747:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:28:27,147:train.py:199 -         run_log_save(): Batch 1144, epoch 7/20:
2017-12-02 23:28:27,147:train.py:200 -         run_log_save():    avg word perp:   13.10
2017-12-02 23:28:27,147:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-02 23:28:27,147:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:29:32,549:train.py:199 -         run_log_save(): Batch 1244, epoch 7/20:
2017-12-02 23:29:32,550:train.py:200 -         run_log_save():    avg word perp:   13.06
2017-12-02 23:29:32,550:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-02 23:29:32,550:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:30:38,551:train.py:151 -         sample_input(): Sample input data:
2017-12-02 23:30:38,552:train.py:152 -         sample_input(): Src: . statt Rahmen erem klein@@ viel in fanden Aktionen politische as Ji@@ Hu _PAD _PAD
2017-12-02 23:30:38,552:train.py:153 -         sample_input(): Src len: 13
2017-12-02 23:30:38,552:train.py:154 -         sample_input(): Trg: _BOS Hu Jia &apos;s political actions are much more modest than that . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 23:30:38,552:train.py:155 -         sample_input(): Tar: Hu Jia &apos;s political actions are much more modest than that . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 23:30:38,552:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-02 23:30:38,552:train.py:199 -         run_log_save(): Batch 1344, epoch 7/20:
2017-12-02 23:30:38,552:train.py:200 -         run_log_save():    avg word perp:   13.12
2017-12-02 23:30:38,552:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-02 23:30:38,552:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:30:38,552:validator.py:224 -    validate_and_save(): Start validation
2017-12-02 23:31:36,657:validator.py:143 -             evaluate():   Translating line 100, average 0.581037621498 seconds/sent
2017-12-02 23:32:33,535:validator.py:143 -             evaluate():   Translating line 200, average 0.574910609722 seconds/sent
2017-12-02 23:33:23,798:validator.py:143 -             evaluate():   Translating line 300, average 0.550817170143 seconds/sent
2017-12-02 23:34:11,783:validator.py:143 -             evaluate():   Translating line 400, average 0.53307443738 seconds/sent
2017-12-02 23:35:12,007:validator.py:143 -             evaluate():   Translating line 500, average 0.546907403946 seconds/sent
2017-12-02 23:36:04,882:validator.py:143 -             evaluate():   Translating line 600, average 0.543881931702 seconds/sent
2017-12-02 23:36:57,449:validator.py:143 -             evaluate():   Translating line 700, average 0.541280129978 seconds/sent
2017-12-02 23:37:45,693:validator.py:143 -             evaluate():   Translating line 800, average 0.53392452389 seconds/sent
2017-12-02 23:38:26,177:validator.py:143 -             evaluate():   Translating line 900, average 0.51958227449 seconds/sent
2017-12-02 23:39:18,106:validator.py:143 -             evaluate():   Translating line 1000, average 0.519553254128 seconds/sent
2017-12-02 23:40:11,598:validator.py:143 -             evaluate():   Translating line 1100, average 0.520950261029 seconds/sent
2017-12-02 23:40:55,654:validator.py:143 -             evaluate():   Translating line 1200, average 0.514250671665 seconds/sent
2017-12-02 23:42:03,271:validator.py:143 -             evaluate():   Translating line 1300, average 0.526705971498 seconds/sent
2017-12-02 23:43:01,163:validator.py:143 -             evaluate():   Translating line 1400, average 0.530435442243 seconds/sent
2017-12-02 23:43:58,236:validator.py:143 -             evaluate():   Translating line 1500, average 0.533122205416 seconds/sent
2017-12-02 23:44:58,291:validator.py:143 -             evaluate():   Translating line 1600, average 0.537335951924 seconds/sent
2017-12-02 23:45:52,545:validator.py:143 -             evaluate():   Translating line 1700, average 0.537642605866 seconds/sent
2017-12-02 23:46:57,523:validator.py:143 -             evaluate():   Translating line 1800, average 0.543872052828 seconds/sent
2017-12-02 23:47:54,106:validator.py:143 -             evaluate():   Translating line 1900, average 0.545027877908 seconds/sent
2017-12-02 23:48:28,818:validator.py:152 -             evaluate(): Done translating.
2017-12-02 23:48:28,819:validator.py:153 -             evaluate(): dev perplexity: 90.003
2017-12-02 23:48:29,287:validator.py:159 -             evaluate(): BLEU = 11.17, 41.0/16.7/8.0/4.0 (BP=0.916, ratio=0.920, hyp_len=41636, ref_len=45274)

2017-12-02 23:48:29,288:validator.py:160 -             evaluate(): Validation took: 17.8455769022 minutes
2017-12-02 23:48:29,291:validator.py:195 -           maybe_save(): Current best bleus: 9.28
2017-12-02 23:48:29,291:validator.py:196 -           maybe_save(): Delete 9.28 & use 11.17 instead
2017-12-02 23:48:29,291:validator.py:206 -           maybe_save(): Delete ./nmt/saved_models/de2en_bp/de2en_bp-9.28.cpkt.data-00000-of-00001 & ./nmt/saved_models/de2en_bp/de2en_bp-9.28.cpkt.meta & ./nmt/saved_models/de2en_bp/de2en_bp-9.28.cpkt.index
2017-12-02 23:48:29,316:validator.py:212 -           maybe_save(): Save 11.17 to list of best bleu scores
2017-12-02 23:48:29,879:validator.py:216 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en_bp/de2en_bp-11.17.cpkt
2017-12-02 23:48:29,879:validator.py:217 -           maybe_save(): Best bleu scores so far: 11.17
2017-12-02 23:49:35,712:train.py:199 -         run_log_save(): Batch 1444, epoch 7/20:
2017-12-02 23:49:35,713:train.py:200 -         run_log_save():    avg word perp:   13.20
2017-12-02 23:49:35,713:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-02 23:49:35,713:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:50:41,492:train.py:199 -         run_log_save(): Batch 1544, epoch 7/20:
2017-12-02 23:50:41,492:train.py:200 -         run_log_save():    avg word perp:   13.10
2017-12-02 23:50:41,492:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-02 23:50:41,492:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:51:48,367:train.py:199 -         run_log_save(): Batch 1644, epoch 7/20:
2017-12-02 23:51:48,368:train.py:200 -         run_log_save():    avg word perp:   12.85
2017-12-02 23:51:48,368:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-02 23:51:48,368:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:52:53,567:train.py:199 -         run_log_save(): Batch 1744, epoch 7/20:
2017-12-02 23:52:53,567:train.py:200 -         run_log_save():    avg word perp:   12.83
2017-12-02 23:52:53,567:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-02 23:52:53,567:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:53:58,573:train.py:199 -         run_log_save(): Batch 1844, epoch 7/20:
2017-12-02 23:53:58,573:train.py:200 -         run_log_save():    avg word perp:   12.89
2017-12-02 23:53:58,573:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-02 23:53:58,573:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:55:04,422:train.py:199 -         run_log_save(): Batch 1944, epoch 7/20:
2017-12-02 23:55:04,422:train.py:200 -         run_log_save():    avg word perp:   12.81
2017-12-02 23:55:04,423:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-02 23:55:04,423:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:56:10,053:train.py:199 -         run_log_save(): Batch 2044, epoch 7/20:
2017-12-02 23:56:10,053:train.py:200 -         run_log_save():    avg word perp:   12.81
2017-12-02 23:56:10,053:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-02 23:56:10,053:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:57:16,919:train.py:199 -         run_log_save(): Batch 2144, epoch 7/20:
2017-12-02 23:57:16,919:train.py:200 -         run_log_save():    avg word perp:   12.83
2017-12-02 23:57:16,919:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-02 23:57:16,919:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:58:22,129:train.py:199 -         run_log_save(): Batch 2244, epoch 7/20:
2017-12-02 23:58:22,129:train.py:200 -         run_log_save():    avg word perp:   12.77
2017-12-02 23:58:22,130:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-02 23:58:22,130:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-02 23:59:27,414:train.py:151 -         sample_input(): Sample input data:
2017-12-02 23:59:27,414:train.py:152 -         sample_input(): Src: . ern trau@@ be@@ zu modells Nachrichten@@ älteren des Verschwinden am viel gibt es _PAD _PAD
2017-12-02 23:59:27,415:train.py:153 -         sample_input(): Src len: 14
2017-12-02 23:59:27,415:train.py:154 -         sample_input(): Trg: _BOS there is a great deal to mour@@ n about the passing of the older news model . _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 23:59:27,415:train.py:155 -         sample_input(): Tar: there is a great deal to mour@@ n about the passing of the older news model . _EOS _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-02 23:59:27,415:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-02 23:59:27,415:train.py:199 -         run_log_save(): Batch 2344, epoch 7/20:
2017-12-02 23:59:27,415:train.py:200 -         run_log_save():    avg word perp:   12.84
2017-12-02 23:59:27,415:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-02 23:59:27,415:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:00:32,123:train.py:199 -         run_log_save(): Batch 2444, epoch 7/20:
2017-12-03 00:00:32,123:train.py:200 -         run_log_save():    avg word perp:   12.72
2017-12-03 00:00:32,123:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-03 00:00:32,123:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:01:33,310:train.py:199 -         run_log_save(): Batch 2544, epoch 7/20:
2017-12-03 00:01:33,311:train.py:200 -         run_log_save():    avg word perp:   13.30
2017-12-03 00:01:33,311:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-03 00:01:33,311:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:01:40,308:train.py:199 -         run_log_save(): Batch 2644, epoch 7/20:
2017-12-03 00:01:40,308:train.py:200 -         run_log_save():    avg word perp:   495.10
2017-12-03 00:01:40,308:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-03 00:01:40,308:train.py:202 -         run_log_save():    acc sec/batch:   0.63
2017-12-03 00:01:47,160:train.py:199 -         run_log_save(): Batch 2744, epoch 7/20:
2017-12-03 00:01:47,160:train.py:200 -         run_log_save():    avg word perp:   420.91
2017-12-03 00:01:47,160:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-03 00:01:47,160:train.py:202 -         run_log_save():    acc sec/batch:   0.61
2017-12-03 00:01:54,012:train.py:199 -         run_log_save(): Batch 2844, epoch 7/20:
2017-12-03 00:01:54,012:train.py:200 -         run_log_save():    avg word perp:   408.68
2017-12-03 00:01:54,012:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 00:01:54,012:train.py:202 -         run_log_save():    acc sec/batch:   0.59
2017-12-03 00:02:00,830:train.py:199 -         run_log_save(): Batch 2944, epoch 7/20:
2017-12-03 00:02:00,830:train.py:200 -         run_log_save():    avg word perp:   380.15
2017-12-03 00:02:00,830:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 00:02:00,830:train.py:202 -         run_log_save():    acc sec/batch:   0.57
2017-12-03 00:02:07,684:train.py:199 -         run_log_save(): Batch 3044, epoch 7/20:
2017-12-03 00:02:07,685:train.py:200 -         run_log_save():    avg word perp:   401.37
2017-12-03 00:02:07,685:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 00:02:07,685:train.py:202 -         run_log_save():    acc sec/batch:   0.56
2017-12-03 00:02:14,472:train.py:199 -         run_log_save(): Batch 3144, epoch 7/20:
2017-12-03 00:02:14,472:train.py:200 -         run_log_save():    avg word perp:   382.90
2017-12-03 00:02:14,472:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 00:02:14,472:train.py:202 -         run_log_save():    acc sec/batch:   0.54
2017-12-03 00:02:21,276:train.py:199 -         run_log_save(): Batch 3244, epoch 7/20:
2017-12-03 00:02:21,276:train.py:200 -         run_log_save():    avg word perp:   388.47
2017-12-03 00:02:21,276:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 00:02:21,276:train.py:202 -         run_log_save():    acc sec/batch:   0.53
2017-12-03 00:02:23,495:train.py:119 -         report_epoch(): Finish epoch 7
2017-12-03 00:02:23,495:train.py:120 -         report_epoch():     It takes 0:28:25.967431
2017-12-03 00:02:23,495:train.py:121 -         report_epoch():     Avergage # words/second    2463.32135238
2017-12-03 00:02:23,495:train.py:122 -         report_epoch():     Average seconds/batch    0.520747079153
2017-12-03 00:02:23,495:train.py:133 -         report_epoch():     train perplexity: 14.4353549231
2017-12-03 00:02:23,985:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.489238977432 seconds
2017-12-03 00:03:07,595:train.py:151 -         sample_input(): Sample input data:
2017-12-03 00:03:07,595:train.py:152 -         sample_input(): Src: . Kriminalität die für ebenso und Bereich öffentlichen im Heuchelei die für Nährboden der ist aten Priv@@ im Heuchelei diese _PAD _PAD
2017-12-03 00:03:07,595:train.py:153 -         sample_input(): Src len: 20
2017-12-03 00:03:07,595:train.py:154 -         sample_input(): Trg: _BOS private hypocrisy breeds public hypocrisy and crime . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 00:03:07,595:train.py:155 -         sample_input(): Tar: private hypocrisy breeds public hypocrisy and crime . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 00:03:07,595:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 00:03:07,595:train.py:199 -         run_log_save(): Batch 68, epoch 8/20:
2017-12-03 00:03:07,595:train.py:200 -         run_log_save():    avg word perp:   16.70
2017-12-03 00:03:07,596:train.py:201 -         run_log_save():    acc trg words/s: 2418
2017-12-03 00:03:07,596:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-03 00:04:12,693:train.py:199 -         run_log_save(): Batch 168, epoch 8/20:
2017-12-03 00:04:12,693:train.py:200 -         run_log_save():    avg word perp:   11.95
2017-12-03 00:04:12,693:train.py:201 -         run_log_save():    acc trg words/s: 2452
2017-12-03 00:04:12,693:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-03 00:05:18,816:train.py:199 -         run_log_save(): Batch 268, epoch 8/20:
2017-12-03 00:05:18,816:train.py:200 -         run_log_save():    avg word perp:   12.04
2017-12-03 00:05:18,816:train.py:201 -         run_log_save():    acc trg words/s: 2451
2017-12-03 00:05:18,816:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:06:23,891:train.py:199 -         run_log_save(): Batch 368, epoch 8/20:
2017-12-03 00:06:23,891:train.py:200 -         run_log_save():    avg word perp:   11.88
2017-12-03 00:06:23,891:train.py:201 -         run_log_save():    acc trg words/s: 2452
2017-12-03 00:06:23,891:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:07:29,591:train.py:199 -         run_log_save(): Batch 468, epoch 8/20:
2017-12-03 00:07:29,591:train.py:200 -         run_log_save():    avg word perp:   12.00
2017-12-03 00:07:29,591:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-03 00:07:29,591:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:08:34,755:train.py:199 -         run_log_save(): Batch 568, epoch 8/20:
2017-12-03 00:08:34,755:train.py:200 -         run_log_save():    avg word perp:   11.61
2017-12-03 00:08:34,755:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 00:08:34,755:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:09:40,402:train.py:199 -         run_log_save(): Batch 668, epoch 8/20:
2017-12-03 00:09:40,403:train.py:200 -         run_log_save():    avg word perp:   11.77
2017-12-03 00:09:40,403:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 00:09:40,403:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:10:45,775:train.py:199 -         run_log_save(): Batch 768, epoch 8/20:
2017-12-03 00:10:45,775:train.py:200 -         run_log_save():    avg word perp:   11.83
2017-12-03 00:10:45,775:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-03 00:10:45,775:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:11:51,437:train.py:199 -         run_log_save(): Batch 868, epoch 8/20:
2017-12-03 00:11:51,437:train.py:200 -         run_log_save():    avg word perp:   11.90
2017-12-03 00:11:51,437:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 00:11:51,437:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:12:57,698:train.py:199 -         run_log_save(): Batch 968, epoch 8/20:
2017-12-03 00:12:57,698:train.py:200 -         run_log_save():    avg word perp:   11.91
2017-12-03 00:12:57,698:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 00:12:57,698:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:14:02,960:train.py:151 -         sample_input(): Sample input data:
2017-12-03 00:14:02,960:train.py:152 -         sample_input(): Src: . anzuerkennen Niedergang relativen seinen , ren mur@@ Europas Weigerung ure st@@ die über nur Welt restliche die konnte bislang _PAD
2017-12-03 00:14:02,960:train.py:153 -         sample_input(): Src len: 20
2017-12-03 00:14:02,960:train.py:154 -         sample_input(): Trg: _BOS until now , the rest of world could only g@@ rum@@ ble at Europe &apos;s ob@@ stin@@ ate refusal to recognize its relative decline . _PAD _PAD _PAD _PAD
2017-12-03 00:14:02,960:train.py:155 -         sample_input(): Tar: until now , the rest of world could only g@@ rum@@ ble at Europe &apos;s ob@@ stin@@ ate refusal to recognize its relative decline . _EOS _PAD _PAD _PAD _PAD
2017-12-03 00:14:02,960:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0
2017-12-03 00:14:02,960:train.py:199 -         run_log_save(): Batch 1068, epoch 8/20:
2017-12-03 00:14:02,960:train.py:200 -         run_log_save():    avg word perp:   11.58
2017-12-03 00:14:02,961:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-03 00:14:02,961:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:15:07,628:train.py:199 -         run_log_save(): Batch 1168, epoch 8/20:
2017-12-03 00:15:07,628:train.py:200 -         run_log_save():    avg word perp:   11.58
2017-12-03 00:15:07,628:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-03 00:15:07,629:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:16:14,700:train.py:199 -         run_log_save(): Batch 1268, epoch 8/20:
2017-12-03 00:16:14,700:train.py:200 -         run_log_save():    avg word perp:   12.02
2017-12-03 00:16:14,700:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 00:16:14,700:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:17:20,638:train.py:199 -         run_log_save(): Batch 1368, epoch 8/20:
2017-12-03 00:17:20,639:train.py:200 -         run_log_save():    avg word perp:   11.71
2017-12-03 00:17:20,639:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 00:17:20,639:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:18:26,174:train.py:199 -         run_log_save(): Batch 1468, epoch 8/20:
2017-12-03 00:18:26,174:train.py:200 -         run_log_save():    avg word perp:   11.87
2017-12-03 00:18:26,174:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 00:18:26,174:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:19:30,777:train.py:199 -         run_log_save(): Batch 1568, epoch 8/20:
2017-12-03 00:19:30,777:train.py:200 -         run_log_save():    avg word perp:   11.88
2017-12-03 00:19:30,777:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 00:19:30,777:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:20:35,949:train.py:199 -         run_log_save(): Batch 1668, epoch 8/20:
2017-12-03 00:20:35,949:train.py:200 -         run_log_save():    avg word perp:   11.77
2017-12-03 00:20:35,950:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-03 00:20:35,950:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:21:42,335:train.py:199 -         run_log_save(): Batch 1768, epoch 8/20:
2017-12-03 00:21:42,335:train.py:200 -         run_log_save():    avg word perp:   11.64
2017-12-03 00:21:42,335:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 00:21:42,335:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:22:48,433:train.py:199 -         run_log_save(): Batch 1868, epoch 8/20:
2017-12-03 00:22:48,433:train.py:200 -         run_log_save():    avg word perp:   11.79
2017-12-03 00:22:48,434:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 00:22:48,434:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:23:54,173:train.py:199 -         run_log_save(): Batch 1968, epoch 8/20:
2017-12-03 00:23:54,173:train.py:200 -         run_log_save():    avg word perp:   11.90
2017-12-03 00:23:54,173:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 00:23:54,173:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:25:00,245:train.py:151 -         sample_input(): Sample input data:
2017-12-03 00:25:00,245:train.py:152 -         sample_input(): Src: . senkte Wandel demokratischen dem vor Angst die das , Sicherheit der Gefühl ein auch Kommunisten den gab Tisch Runde der _PAD
2017-12-03 00:25:00,246:train.py:153 -         sample_input(): Src len: 21
2017-12-03 00:25:00,246:train.py:154 -         sample_input(): Trg: _BOS the Roundtable also provided the Communists with a sense of safety that diminished their fear of democratic change . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 00:25:00,246:train.py:155 -         sample_input(): Tar: the Roundtable also provided the Communists with a sense of safety that diminished their fear of democratic change . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 00:25:00,246:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 00:25:00,246:train.py:199 -         run_log_save(): Batch 2068, epoch 8/20:
2017-12-03 00:25:00,246:train.py:200 -         run_log_save():    avg word perp:   11.49
2017-12-03 00:25:00,246:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 00:25:00,246:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:25:03,599:train.py:207 -         run_log_save(): Save model to ./nmt/saved_models/de2en_bp/de2en_bp.cpkt, takes 0:00:03.353090
2017-12-03 00:26:10,497:train.py:199 -         run_log_save(): Batch 2168, epoch 8/20:
2017-12-03 00:26:10,497:train.py:200 -         run_log_save():    avg word perp:   11.79
2017-12-03 00:26:10,497:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-03 00:26:10,497:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:27:16,838:train.py:199 -         run_log_save(): Batch 2268, epoch 8/20:
2017-12-03 00:27:16,838:train.py:200 -         run_log_save():    avg word perp:   11.83
2017-12-03 00:27:16,838:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-03 00:27:16,838:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:28:22,208:train.py:199 -         run_log_save(): Batch 2368, epoch 8/20:
2017-12-03 00:28:22,209:train.py:200 -         run_log_save():    avg word perp:   11.81
2017-12-03 00:28:22,209:train.py:201 -         run_log_save():    acc trg words/s: 2460
2017-12-03 00:28:22,209:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:29:27,352:train.py:199 -         run_log_save(): Batch 2468, epoch 8/20:
2017-12-03 00:29:27,352:train.py:200 -         run_log_save():    avg word perp:   11.49
2017-12-03 00:29:27,352:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 00:29:27,352:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:30:14,545:train.py:199 -         run_log_save(): Batch 2568, epoch 8/20:
2017-12-03 00:30:14,546:train.py:200 -         run_log_save():    avg word perp:   14.49
2017-12-03 00:30:14,546:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 00:30:14,546:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:30:21,389:train.py:199 -         run_log_save(): Batch 2668, epoch 8/20:
2017-12-03 00:30:21,389:train.py:200 -         run_log_save():    avg word perp:   430.21
2017-12-03 00:30:21,389:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 00:30:21,389:train.py:202 -         run_log_save():    acc sec/batch:   0.62
2017-12-03 00:30:28,179:train.py:199 -         run_log_save(): Batch 2768, epoch 8/20:
2017-12-03 00:30:28,179:train.py:200 -         run_log_save():    avg word perp:   376.26
2017-12-03 00:30:28,179:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 00:30:28,179:train.py:202 -         run_log_save():    acc sec/batch:   0.60
2017-12-03 00:30:35,027:train.py:199 -         run_log_save(): Batch 2868, epoch 8/20:
2017-12-03 00:30:35,028:train.py:200 -         run_log_save():    avg word perp:   354.90
2017-12-03 00:30:35,028:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 00:30:35,028:train.py:202 -         run_log_save():    acc sec/batch:   0.59
2017-12-03 00:30:42,003:train.py:199 -         run_log_save(): Batch 2968, epoch 8/20:
2017-12-03 00:30:42,003:train.py:200 -         run_log_save():    avg word perp:   346.16
2017-12-03 00:30:42,003:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 00:30:42,003:train.py:202 -         run_log_save():    acc sec/batch:   0.57
2017-12-03 00:30:48,832:train.py:151 -         sample_input(): Sample input data:
2017-12-03 00:30:48,832:train.py:152 -         sample_input(): Src: Hohlzirkel
2017-12-03 00:30:48,832:train.py:153 -         sample_input(): Src len: 1
2017-12-03 00:30:48,832:train.py:154 -         sample_input(): Trg: _BOS inside caliper
2017-12-03 00:30:48,832:train.py:155 -         sample_input(): Tar: inside caliper _EOS
2017-12-03 00:30:48,832:train.py:156 -         sample_input(): W: 1.0 1.0 1.0
2017-12-03 00:30:48,832:train.py:199 -         run_log_save(): Batch 3068, epoch 8/20:
2017-12-03 00:30:48,832:train.py:200 -         run_log_save():    avg word perp:   362.70
2017-12-03 00:30:48,832:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 00:30:48,832:train.py:202 -         run_log_save():    acc sec/batch:   0.55
2017-12-03 00:30:55,652:train.py:199 -         run_log_save(): Batch 3168, epoch 8/20:
2017-12-03 00:30:55,652:train.py:200 -         run_log_save():    avg word perp:   349.98
2017-12-03 00:30:55,652:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 00:30:55,652:train.py:202 -         run_log_save():    acc sec/batch:   0.54
2017-12-03 00:31:02,509:train.py:199 -         run_log_save(): Batch 3268, epoch 8/20:
2017-12-03 00:31:02,510:train.py:200 -         run_log_save():    avg word perp:   340.55
2017-12-03 00:31:02,510:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 00:31:02,510:train.py:202 -         run_log_save():    acc sec/batch:   0.52
2017-12-03 00:31:03,080:train.py:119 -         report_epoch(): Finish epoch 8
2017-12-03 00:31:03,080:train.py:120 -         report_epoch():     It takes 0:28:27.267170
2017-12-03 00:31:03,080:train.py:121 -         report_epoch():     Avergage # words/second    2461.41498762
2017-12-03 00:31:03,080:train.py:122 -         report_epoch():     Average seconds/batch    0.521143824772
2017-12-03 00:31:03,080:train.py:133 -         report_epoch():     train perplexity: 13.1018846286
2017-12-03 00:31:03,608:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.528259038925 seconds
2017-12-03 00:32:02,406:train.py:199 -         run_log_save(): Batch 92, epoch 9/20:
2017-12-03 00:32:02,407:train.py:200 -         run_log_save():    avg word perp:   12.50
2017-12-03 00:32:02,407:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-03 00:32:02,407:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-03 00:33:08,596:train.py:199 -         run_log_save(): Batch 192, epoch 9/20:
2017-12-03 00:33:08,597:train.py:200 -         run_log_save():    avg word perp:   10.85
2017-12-03 00:33:08,597:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 00:33:08,597:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:34:13,324:train.py:199 -         run_log_save(): Batch 292, epoch 9/20:
2017-12-03 00:34:13,324:train.py:200 -         run_log_save():    avg word perp:   10.94
2017-12-03 00:34:13,324:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-03 00:34:13,324:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:35:18,437:train.py:199 -         run_log_save(): Batch 392, epoch 9/20:
2017-12-03 00:35:18,437:train.py:200 -         run_log_save():    avg word perp:   10.89
2017-12-03 00:35:18,437:train.py:201 -         run_log_save():    acc trg words/s: 2469
2017-12-03 00:35:18,437:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:36:24,790:train.py:199 -         run_log_save(): Batch 492, epoch 9/20:
2017-12-03 00:36:24,791:train.py:200 -         run_log_save():    avg word perp:   10.70
2017-12-03 00:36:24,791:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-03 00:36:24,791:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:37:30,541:train.py:199 -         run_log_save(): Batch 592, epoch 9/20:
2017-12-03 00:37:30,541:train.py:200 -         run_log_save():    avg word perp:   10.78
2017-12-03 00:37:30,541:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 00:37:30,541:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:38:35,302:train.py:199 -         run_log_save(): Batch 692, epoch 9/20:
2017-12-03 00:38:35,302:train.py:200 -         run_log_save():    avg word perp:   10.75
2017-12-03 00:38:35,302:train.py:201 -         run_log_save():    acc trg words/s: 2472
2017-12-03 00:38:35,302:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:39:40,818:train.py:151 -         sample_input(): Sample input data:
2017-12-03 00:39:40,819:train.py:152 -         sample_input(): Src: . erreichen zu Kirche orthodoxe die an Annäherung eine und besuchen zu Moskau , war II. Paul Johannes Papst verstorbenen des Träume erfüllten un@@ der einer _PAD _PAD
2017-12-03 00:39:40,819:train.py:153 -         sample_input(): Src len: 26
2017-12-03 00:39:40,819:train.py:154 -         sample_input(): Trg: _BOS one of the late Pope John Paul II &apos;s unfulfilled dreams was to visit Moscow and forge a rapprochement with the Orthodox Church . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 00:39:40,819:train.py:155 -         sample_input(): Tar: one of the late Pope John Paul II &apos;s unfulfilled dreams was to visit Moscow and forge a rapprochement with the Orthodox Church . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 00:39:40,819:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 00:39:40,819:train.py:199 -         run_log_save(): Batch 792, epoch 9/20:
2017-12-03 00:39:40,819:train.py:200 -         run_log_save():    avg word perp:   10.81
2017-12-03 00:39:40,819:train.py:201 -         run_log_save():    acc trg words/s: 2470
2017-12-03 00:39:40,819:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:40:46,682:train.py:199 -         run_log_save(): Batch 892, epoch 9/20:
2017-12-03 00:40:46,682:train.py:200 -         run_log_save():    avg word perp:   11.05
2017-12-03 00:40:46,682:train.py:201 -         run_log_save():    acc trg words/s: 2470
2017-12-03 00:40:46,682:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:41:52,668:train.py:199 -         run_log_save(): Batch 992, epoch 9/20:
2017-12-03 00:41:52,668:train.py:200 -         run_log_save():    avg word perp:   10.92
2017-12-03 00:41:52,668:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-03 00:41:52,668:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:42:57,496:train.py:199 -         run_log_save(): Batch 1092, epoch 9/20:
2017-12-03 00:42:57,496:train.py:200 -         run_log_save():    avg word perp:   10.92
2017-12-03 00:42:57,496:train.py:201 -         run_log_save():    acc trg words/s: 2470
2017-12-03 00:42:57,496:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:44:03,088:train.py:199 -         run_log_save(): Batch 1192, epoch 9/20:
2017-12-03 00:44:03,089:train.py:200 -         run_log_save():    avg word perp:   10.89
2017-12-03 00:44:03,089:train.py:201 -         run_log_save():    acc trg words/s: 2470
2017-12-03 00:44:03,089:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:45:08,087:train.py:199 -         run_log_save(): Batch 1292, epoch 9/20:
2017-12-03 00:45:08,087:train.py:200 -         run_log_save():    avg word perp:   10.74
2017-12-03 00:45:08,087:train.py:201 -         run_log_save():    acc trg words/s: 2470
2017-12-03 00:45:08,087:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:46:14,201:train.py:199 -         run_log_save(): Batch 1392, epoch 9/20:
2017-12-03 00:46:14,201:train.py:200 -         run_log_save():    avg word perp:   10.83
2017-12-03 00:46:14,201:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-03 00:46:14,201:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:47:19,286:train.py:199 -         run_log_save(): Batch 1492, epoch 9/20:
2017-12-03 00:47:19,286:train.py:200 -         run_log_save():    avg word perp:   10.90
2017-12-03 00:47:19,286:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-03 00:47:19,286:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:48:25,003:train.py:199 -         run_log_save(): Batch 1592, epoch 9/20:
2017-12-03 00:48:25,003:train.py:200 -         run_log_save():    avg word perp:   10.91
2017-12-03 00:48:25,003:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 00:48:25,003:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:49:31,110:train.py:199 -         run_log_save(): Batch 1692, epoch 9/20:
2017-12-03 00:49:31,110:train.py:200 -         run_log_save():    avg word perp:   11.09
2017-12-03 00:49:31,110:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-03 00:49:31,110:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:50:36,617:train.py:151 -         sample_input(): Sample input data:
2017-12-03 00:50:36,617:train.py:152 -         sample_input(): Src: . nieder völlig Hauptstadt die nten bran@@ und Geiseln die ten befrei@@ , dala Mag@@ Briten die erreichten Berge die durch Marsch gem monati@@ drei@@ nach _PAD _PAD
2017-12-03 00:50:36,617:train.py:153 -         sample_input(): Src len: 26
2017-12-03 00:50:36,617:train.py:154 -         sample_input(): Trg: _BOS after a three @-@ month journey through the mountains , the British reached Mag@@ dala , released the hostages , and burned the capital to the ground . _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 00:50:36,617:train.py:155 -         sample_input(): Tar: after a three @-@ month journey through the mountains , the British reached Mag@@ dala , released the hostages , and burned the capital to the ground . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 00:50:36,617:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 00:50:36,617:train.py:199 -         run_log_save(): Batch 1792, epoch 9/20:
2017-12-03 00:50:36,618:train.py:200 -         run_log_save():    avg word perp:   10.88
2017-12-03 00:50:36,618:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 00:50:36,618:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 00:50:36,618:validator.py:224 -    validate_and_save(): Start validation
2017-12-03 00:51:38,765:validator.py:143 -             evaluate():   Translating line 100, average 0.621467559338 seconds/sent
2017-12-03 00:52:39,917:validator.py:143 -             evaluate():   Translating line 200, average 0.61649415493 seconds/sent
2017-12-03 00:53:33,529:validator.py:143 -             evaluate():   Translating line 300, average 0.589701240063 seconds/sent
2017-12-03 00:54:27,305:validator.py:143 -             evaluate():   Translating line 400, average 0.576717165112 seconds/sent
2017-12-03 00:55:29,557:validator.py:143 -             evaluate():   Translating line 500, average 0.58587776804 seconds/sent
2017-12-03 00:56:24,303:validator.py:143 -             evaluate():   Translating line 600, average 0.579474250078 seconds/sent
2017-12-03 00:57:24,169:validator.py:143 -             evaluate():   Translating line 700, average 0.582215527126 seconds/sent
2017-12-03 00:58:14,891:validator.py:143 -             evaluate():   Translating line 800, average 0.572841158807 seconds/sent
2017-12-03 00:58:55,918:validator.py:143 -             evaluate():   Translating line 900, average 0.554776856634 seconds/sent
2017-12-03 00:59:49,030:validator.py:143 -             evaluate():   Translating line 1000, average 0.552411859035 seconds/sent
2017-12-03 01:00:41,693:validator.py:143 -             evaluate():   Translating line 1100, average 0.550068071755 seconds/sent
2017-12-03 01:01:29,584:validator.py:143 -             evaluate():   Translating line 1200, average 0.544137736559 seconds/sent
2017-12-03 01:02:39,054:validator.py:143 -             evaluate():   Translating line 1300, average 0.555719904533 seconds/sent
2017-12-03 01:03:40,624:validator.py:143 -             evaluate():   Translating line 1400, average 0.560004007135 seconds/sent
2017-12-03 01:04:44,312:validator.py:143 -             evaluate():   Translating line 1500, average 0.565129048665 seconds/sent
2017-12-03 01:05:43,900:validator.py:143 -             evaluate():   Translating line 1600, average 0.567050901204 seconds/sent
2017-12-03 01:06:44,415:validator.py:143 -             evaluate():   Translating line 1700, average 0.569292080543 seconds/sent
2017-12-03 01:07:55,436:validator.py:143 -             evaluate():   Translating line 1800, average 0.577120913267 seconds/sent
2017-12-03 01:08:57,413:validator.py:143 -             evaluate():   Translating line 1900, average 0.57936549789 seconds/sent
2017-12-03 01:09:35,561:validator.py:152 -             evaluate(): Done translating.
2017-12-03 01:09:35,562:validator.py:153 -             evaluate(): dev perplexity: 72.62
2017-12-03 01:09:36,058:validator.py:159 -             evaluate(): BLEU = 11.13, 36.5/15.1/7.4/3.8 (BP=1.000, ratio=1.064, hyp_len=48188, ref_len=45274)

2017-12-03 01:09:36,058:validator.py:160 -             evaluate(): Validation took: 18.9906613151 minutes
2017-12-03 01:10:41,694:train.py:199 -         run_log_save(): Batch 1892, epoch 9/20:
2017-12-03 01:10:41,694:train.py:200 -         run_log_save():    avg word perp:   11.00
2017-12-03 01:10:41,694:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-03 01:10:41,694:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:11:47,272:train.py:199 -         run_log_save(): Batch 1992, epoch 9/20:
2017-12-03 01:11:47,272:train.py:200 -         run_log_save():    avg word perp:   10.97
2017-12-03 01:11:47,272:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-03 01:11:47,272:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:12:53,356:train.py:199 -         run_log_save(): Batch 2092, epoch 9/20:
2017-12-03 01:12:53,356:train.py:200 -         run_log_save():    avg word perp:   11.06
2017-12-03 01:12:53,356:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 01:12:53,356:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:13:59,612:train.py:199 -         run_log_save(): Batch 2192, epoch 9/20:
2017-12-03 01:13:59,612:train.py:200 -         run_log_save():    avg word perp:   10.75
2017-12-03 01:13:59,613:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 01:13:59,613:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:15:04,141:train.py:199 -         run_log_save(): Batch 2292, epoch 9/20:
2017-12-03 01:15:04,141:train.py:200 -         run_log_save():    avg word perp:   10.67
2017-12-03 01:15:04,141:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 01:15:04,141:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:16:10,142:train.py:199 -         run_log_save(): Batch 2392, epoch 9/20:
2017-12-03 01:16:10,143:train.py:200 -         run_log_save():    avg word perp:   10.85
2017-12-03 01:16:10,143:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-03 01:16:10,143:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:17:15,420:train.py:199 -         run_log_save(): Batch 2492, epoch 9/20:
2017-12-03 01:17:15,420:train.py:200 -         run_log_save():    avg word perp:   10.85
2017-12-03 01:17:15,420:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 01:17:15,420:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:17:48,927:train.py:199 -         run_log_save(): Batch 2592, epoch 9/20:
2017-12-03 01:17:48,927:train.py:200 -         run_log_save():    avg word perp:   17.67
2017-12-03 01:17:48,927:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 01:17:48,927:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-03 01:17:55,775:train.py:199 -         run_log_save(): Batch 2692, epoch 9/20:
2017-12-03 01:17:55,775:train.py:200 -         run_log_save():    avg word perp:   408.43
2017-12-03 01:17:55,775:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 01:17:55,775:train.py:202 -         run_log_save():    acc sec/batch:   0.62
2017-12-03 01:18:02,606:train.py:151 -         sample_input(): Sample input data:
2017-12-03 01:18:02,606:train.py:152 -         sample_input(): Src: Verbreitung
2017-12-03 01:18:02,607:train.py:153 -         sample_input(): Src len: 1
2017-12-03 01:18:02,607:train.py:154 -         sample_input(): Trg: _BOS diffusion _PAD
2017-12-03 01:18:02,607:train.py:155 -         sample_input(): Tar: diffusion _EOS _PAD
2017-12-03 01:18:02,607:train.py:156 -         sample_input(): W: 1.0 1.0 0.0
2017-12-03 01:18:02,607:train.py:199 -         run_log_save(): Batch 2792, epoch 9/20:
2017-12-03 01:18:02,607:train.py:200 -         run_log_save():    avg word perp:   352.94
2017-12-03 01:18:02,607:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 01:18:02,607:train.py:202 -         run_log_save():    acc sec/batch:   0.60
2017-12-03 01:18:09,429:train.py:199 -         run_log_save(): Batch 2892, epoch 9/20:
2017-12-03 01:18:09,429:train.py:200 -         run_log_save():    avg word perp:   366.64
2017-12-03 01:18:09,429:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 01:18:09,429:train.py:202 -         run_log_save():    acc sec/batch:   0.58
2017-12-03 01:18:16,236:train.py:199 -         run_log_save(): Batch 2992, epoch 9/20:
2017-12-03 01:18:16,236:train.py:200 -         run_log_save():    avg word perp:   345.54
2017-12-03 01:18:16,236:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 01:18:16,236:train.py:202 -         run_log_save():    acc sec/batch:   0.56
2017-12-03 01:18:23,055:train.py:199 -         run_log_save(): Batch 3092, epoch 9/20:
2017-12-03 01:18:23,055:train.py:200 -         run_log_save():    avg word perp:   342.30
2017-12-03 01:18:23,055:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 01:18:23,055:train.py:202 -         run_log_save():    acc sec/batch:   0.55
2017-12-03 01:18:29,890:train.py:199 -         run_log_save(): Batch 3192, epoch 9/20:
2017-12-03 01:18:29,890:train.py:200 -         run_log_save():    avg word perp:   347.02
2017-12-03 01:18:29,890:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 01:18:29,890:train.py:202 -         run_log_save():    acc sec/batch:   0.53
2017-12-03 01:18:35,696:train.py:119 -         report_epoch(): Finish epoch 9
2017-12-03 01:18:35,696:train.py:120 -         report_epoch():     It takes 0:28:24.223747
2017-12-03 01:18:35,696:train.py:121 -         report_epoch():     Avergage # words/second    2465.81823906
2017-12-03 01:18:35,696:train.py:122 -         report_epoch():     Average seconds/batch    0.520214819137
2017-12-03 01:18:35,696:train.py:133 -         report_epoch():     train perplexity: 12.096572879
2017-12-03 01:18:36,217:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.521124839783 seconds
2017-12-03 01:18:46,179:train.py:199 -         run_log_save(): Batch 16, epoch 10/20:
2017-12-03 01:18:46,179:train.py:200 -         run_log_save():    avg word perp:   46.22
2017-12-03 01:18:46,179:train.py:201 -         run_log_save():    acc trg words/s: 2251
2017-12-03 01:18:46,179:train.py:202 -         run_log_save():    acc sec/batch:   0.62
2017-12-03 01:19:51,153:train.py:199 -         run_log_save(): Batch 116, epoch 10/20:
2017-12-03 01:19:51,154:train.py:200 -         run_log_save():    avg word perp:   10.56
2017-12-03 01:19:51,154:train.py:201 -         run_log_save():    acc trg words/s: 2444
2017-12-03 01:19:51,154:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-03 01:20:56,536:train.py:199 -         run_log_save(): Batch 216, epoch 10/20:
2017-12-03 01:20:56,536:train.py:200 -         run_log_save():    avg word perp:   10.20
2017-12-03 01:20:56,536:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-03 01:20:56,537:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:22:02,471:train.py:199 -         run_log_save(): Batch 316, epoch 10/20:
2017-12-03 01:22:02,471:train.py:200 -         run_log_save():    avg word perp:   10.06
2017-12-03 01:22:02,471:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 01:22:02,471:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:23:08,446:train.py:199 -         run_log_save(): Batch 416, epoch 10/20:
2017-12-03 01:23:08,446:train.py:200 -         run_log_save():    avg word perp:   10.24
2017-12-03 01:23:08,447:train.py:201 -         run_log_save():    acc trg words/s: 2460
2017-12-03 01:23:08,447:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:24:14,680:train.py:151 -         sample_input(): Sample input data:
2017-12-03 01:24:14,680:train.py:152 -         sample_input(): Src: . werden bestimmt Tests scher prognosti@@ oder tiver dik@@ prä@@ verschiedener aufgrund einzelnen jedes Behandlung die würde , leiden en Symptom@@ denselben unter und Krankheit derselben an offenkundig die , also Patienten unter selbst _PAD _PAD
2017-12-03 01:24:14,680:train.py:153 -         sample_input(): Src len: 34
2017-12-03 01:24:14,680:train.py:154 -         sample_input(): Trg: _BOS in other words , even among patients who apparently have the same disease and symptoms , the treatment for each one would be determined by various predic@@ tive or progno@@ stic tests . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 01:24:14,680:train.py:155 -         sample_input(): Tar: in other words , even among patients who apparently have the same disease and symptoms , the treatment for each one would be determined by various predic@@ tive or progno@@ stic tests . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 01:24:14,680:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 01:24:14,680:train.py:199 -         run_log_save(): Batch 516, epoch 10/20:
2017-12-03 01:24:14,680:train.py:200 -         run_log_save():    avg word perp:   10.28
2017-12-03 01:24:14,680:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-03 01:24:14,680:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:24:17,989:train.py:207 -         run_log_save(): Save model to ./nmt/saved_models/de2en_bp/de2en_bp.cpkt, takes 0:00:03.308719
2017-12-03 01:25:23,890:train.py:199 -         run_log_save(): Batch 616, epoch 10/20:
2017-12-03 01:25:23,890:train.py:200 -         run_log_save():    avg word perp:   10.11
2017-12-03 01:25:23,890:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-03 01:25:23,890:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:26:29,504:train.py:199 -         run_log_save(): Batch 716, epoch 10/20:
2017-12-03 01:26:29,504:train.py:200 -         run_log_save():    avg word perp:   10.20
2017-12-03 01:26:29,504:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-03 01:26:29,505:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:27:35,093:train.py:199 -         run_log_save(): Batch 816, epoch 10/20:
2017-12-03 01:27:35,093:train.py:200 -         run_log_save():    avg word perp:   10.21
2017-12-03 01:27:35,093:train.py:201 -         run_log_save():    acc trg words/s: 2460
2017-12-03 01:27:35,093:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:28:39,912:train.py:199 -         run_log_save(): Batch 916, epoch 10/20:
2017-12-03 01:28:39,913:train.py:200 -         run_log_save():    avg word perp:   10.08
2017-12-03 01:28:39,913:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 01:28:39,913:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:29:46,621:train.py:199 -         run_log_save(): Batch 1016, epoch 10/20:
2017-12-03 01:29:46,621:train.py:200 -         run_log_save():    avg word perp:   9.87
2017-12-03 01:29:46,621:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-03 01:29:46,622:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:30:51,514:train.py:199 -         run_log_save(): Batch 1116, epoch 10/20:
2017-12-03 01:30:51,514:train.py:200 -         run_log_save():    avg word perp:   10.16
2017-12-03 01:30:51,514:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 01:30:51,514:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:31:57,516:train.py:199 -         run_log_save(): Batch 1216, epoch 10/20:
2017-12-03 01:31:57,517:train.py:200 -         run_log_save():    avg word perp:   10.29
2017-12-03 01:31:57,517:train.py:201 -         run_log_save():    acc trg words/s: 2460
2017-12-03 01:31:57,517:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:33:02,855:train.py:199 -         run_log_save(): Batch 1316, epoch 10/20:
2017-12-03 01:33:02,855:train.py:200 -         run_log_save():    avg word perp:   10.27
2017-12-03 01:33:02,855:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 01:33:02,856:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:34:08,056:train.py:199 -         run_log_save(): Batch 1416, epoch 10/20:
2017-12-03 01:34:08,056:train.py:200 -         run_log_save():    avg word perp:   10.10
2017-12-03 01:34:08,056:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-03 01:34:08,056:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:35:13,135:train.py:151 -         sample_input(): Sample input data:
2017-12-03 01:35:13,135:train.py:152 -         sample_input(): Src: . verpflichten Vorgehensweise dieser zu hinein Vor@@ im auch sich sollten sondern , werden ausgehandelt Rettungsaktion einer Einzelheiten die wenn , verzichten gern gläubi@@ Anleihe@@ von Schutz den auf nur nicht sollten Regierungen _PAD _PAD _PAD
2017-12-03 01:35:13,135:train.py:153 -         sample_input(): Src len: 33
2017-12-03 01:35:13,135:train.py:154 -         sample_input(): Trg: _BOS governments should not only avoid protecting bondholders after the fact , when the details of a bailout are worked out ; but should also make their commitment to this approach clear in advance . _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 01:35:13,135:train.py:155 -         sample_input(): Tar: governments should not only avoid protecting bondholders after the fact , when the details of a bailout are worked out ; but should also make their commitment to this approach clear in advance . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 01:35:13,135:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 01:35:13,136:train.py:199 -         run_log_save(): Batch 1516, epoch 10/20:
2017-12-03 01:35:13,136:train.py:200 -         run_log_save():    avg word perp:   10.23
2017-12-03 01:35:13,136:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 01:35:13,136:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:36:18,805:train.py:199 -         run_log_save(): Batch 1616, epoch 10/20:
2017-12-03 01:36:18,805:train.py:200 -         run_log_save():    avg word perp:   10.11
2017-12-03 01:36:18,805:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 01:36:18,805:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:37:23,505:train.py:199 -         run_log_save(): Batch 1716, epoch 10/20:
2017-12-03 01:37:23,505:train.py:200 -         run_log_save():    avg word perp:   10.25
2017-12-03 01:37:23,505:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-03 01:37:23,505:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:38:29,553:train.py:199 -         run_log_save(): Batch 1816, epoch 10/20:
2017-12-03 01:38:29,553:train.py:200 -         run_log_save():    avg word perp:   10.17
2017-12-03 01:38:29,553:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 01:38:29,554:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:39:33,922:train.py:199 -         run_log_save(): Batch 1916, epoch 10/20:
2017-12-03 01:39:33,922:train.py:200 -         run_log_save():    avg word perp:   10.04
2017-12-03 01:39:33,922:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-03 01:39:33,922:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:40:38,843:train.py:199 -         run_log_save(): Batch 2016, epoch 10/20:
2017-12-03 01:40:38,843:train.py:200 -         run_log_save():    avg word perp:   10.11
2017-12-03 01:40:38,843:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-03 01:40:38,843:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:41:43,616:train.py:199 -         run_log_save(): Batch 2116, epoch 10/20:
2017-12-03 01:41:43,616:train.py:200 -         run_log_save():    avg word perp:   10.23
2017-12-03 01:41:43,616:train.py:201 -         run_log_save():    acc trg words/s: 2470
2017-12-03 01:41:43,616:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:42:50,615:train.py:199 -         run_log_save(): Batch 2216, epoch 10/20:
2017-12-03 01:42:50,615:train.py:200 -         run_log_save():    avg word perp:   10.11
2017-12-03 01:42:50,615:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-03 01:42:50,615:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:43:55,408:train.py:199 -         run_log_save(): Batch 2316, epoch 10/20:
2017-12-03 01:43:55,408:train.py:200 -         run_log_save():    avg word perp:   10.22
2017-12-03 01:43:55,408:train.py:201 -         run_log_save():    acc trg words/s: 2469
2017-12-03 01:43:55,409:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:45:00,835:train.py:199 -         run_log_save(): Batch 2416, epoch 10/20:
2017-12-03 01:45:00,835:train.py:200 -         run_log_save():    avg word perp:   10.18
2017-12-03 01:45:00,835:train.py:201 -         run_log_save():    acc trg words/s: 2469
2017-12-03 01:45:00,835:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:46:06,471:train.py:151 -         sample_input(): Sample input data:
2017-12-03 01:46:06,472:train.py:152 -         sample_input(): Src: . festlegt preis Kohle@@ einen Industrie europäischen der Teil großen einen für das , konnte einführen Handel -@@ und Begrenzung @-@ sions Emis@@ für System ein Europa dass , nicht es überrascht daher _PAD _PAD _PAD
2017-12-03 01:46:06,472:train.py:153 -         sample_input(): Src len: 33
2017-12-03 01:46:06,472:train.py:154 -         sample_input(): Trg: _BOS it is thus not surprising that Europe could enact a cap @-@ and @-@ trade system that imposes a carbon price on a large part of its industry . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 01:46:06,472:train.py:155 -         sample_input(): Tar: it is thus not surprising that Europe could enact a cap @-@ and @-@ trade system that imposes a carbon price on a large part of its industry . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 01:46:06,472:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 01:46:06,472:train.py:199 -         run_log_save(): Batch 2516, epoch 10/20:
2017-12-03 01:46:06,472:train.py:200 -         run_log_save():    avg word perp:   10.07
2017-12-03 01:46:06,472:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-03 01:46:06,472:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:46:25,365:train.py:199 -         run_log_save(): Batch 2616, epoch 10/20:
2017-12-03 01:46:25,366:train.py:200 -         run_log_save():    avg word perp:   32.36
2017-12-03 01:46:25,366:train.py:201 -         run_log_save():    acc trg words/s: 2469
2017-12-03 01:46:25,366:train.py:202 -         run_log_save():    acc sec/batch:   0.63
2017-12-03 01:46:32,185:train.py:199 -         run_log_save(): Batch 2716, epoch 10/20:
2017-12-03 01:46:32,185:train.py:200 -         run_log_save():    avg word perp:   396.62
2017-12-03 01:46:32,186:train.py:201 -         run_log_save():    acc trg words/s: 2469
2017-12-03 01:46:32,186:train.py:202 -         run_log_save():    acc sec/batch:   0.61
2017-12-03 01:46:39,030:train.py:199 -         run_log_save(): Batch 2816, epoch 10/20:
2017-12-03 01:46:39,030:train.py:200 -         run_log_save():    avg word perp:   343.95
2017-12-03 01:46:39,030:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-03 01:46:39,031:train.py:202 -         run_log_save():    acc sec/batch:   0.59
2017-12-03 01:46:45,893:train.py:199 -         run_log_save(): Batch 2916, epoch 10/20:
2017-12-03 01:46:45,894:train.py:200 -         run_log_save():    avg word perp:   342.51
2017-12-03 01:46:45,894:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-03 01:46:45,894:train.py:202 -         run_log_save():    acc sec/batch:   0.58
2017-12-03 01:46:52,891:train.py:199 -         run_log_save(): Batch 3016, epoch 10/20:
2017-12-03 01:46:52,892:train.py:200 -         run_log_save():    avg word perp:   332.67
2017-12-03 01:46:52,892:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-03 01:46:52,892:train.py:202 -         run_log_save():    acc sec/batch:   0.56
2017-12-03 01:46:59,743:train.py:199 -         run_log_save(): Batch 3116, epoch 10/20:
2017-12-03 01:46:59,743:train.py:200 -         run_log_save():    avg word perp:   345.70
2017-12-03 01:46:59,743:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-03 01:46:59,743:train.py:202 -         run_log_save():    acc sec/batch:   0.54
2017-12-03 01:47:06,605:train.py:199 -         run_log_save(): Batch 3216, epoch 10/20:
2017-12-03 01:47:06,605:train.py:200 -         run_log_save():    avg word perp:   329.58
2017-12-03 01:47:06,605:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-03 01:47:06,605:train.py:202 -         run_log_save():    acc sec/batch:   0.53
2017-12-03 01:47:10,693:train.py:119 -         report_epoch(): Finish epoch 10
2017-12-03 01:47:10,693:train.py:120 -         report_epoch():     It takes 0:28:22.761773
2017-12-03 01:47:10,693:train.py:121 -         report_epoch():     Avergage # words/second    2467.95827082
2017-12-03 01:47:10,694:train.py:122 -         report_epoch():     Average seconds/batch    0.519768550865
2017-12-03 01:47:10,694:train.py:133 -         report_epoch():     train perplexity: 11.3017257256
2017-12-03 01:47:11,238:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.543840885162 seconds
2017-12-03 01:47:37,645:train.py:199 -         run_log_save(): Batch 40, epoch 11/20:
2017-12-03 01:47:37,646:train.py:200 -         run_log_save():    avg word perp:   18.25
2017-12-03 01:47:37,646:train.py:201 -         run_log_save():    acc trg words/s: 2454
2017-12-03 01:47:37,646:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 01:48:42,883:train.py:199 -         run_log_save(): Batch 140, epoch 11/20:
2017-12-03 01:48:42,883:train.py:200 -         run_log_save():    avg word perp:   9.73
2017-12-03 01:48:42,883:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-03 01:48:42,883:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:49:48,948:train.py:151 -         sample_input(): Sample input data:
2017-12-03 01:49:48,948:train.py:152 -         sample_input(): Src: . hat ausgebildet Sprache die für später erst und Gesten durch teilungen Mit@@ für zuerst Region Broca die sich dass , daraufhin weiteren des deutet das . ausgeprägt stärker Menschenaffen der fte häl@@ Gehirn@@ linken der in auch ist region Gehirn@@ entsprechende die doch _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 01:49:48,948:train.py:153 -         sample_input(): Src len: 44
2017-12-03 01:49:48,948:train.py:154 -         sample_input(): Trg: _BOS but the corresponding area is larger also in the left brain of great apes , further indicating that the Broca &apos;s region evolved first for gest@@ ural communication and only later for speech . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 01:49:48,948:train.py:155 -         sample_input(): Tar: but the corresponding area is larger also in the left brain of great apes , further indicating that the Broca &apos;s region evolved first for gest@@ ural communication and only later for speech . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 01:49:48,948:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 01:49:48,948:train.py:199 -         run_log_save(): Batch 240, epoch 11/20:
2017-12-03 01:49:48,948:train.py:200 -         run_log_save():    avg word perp:   9.67
2017-12-03 01:49:48,948:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-03 01:49:48,948:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:50:53,838:train.py:199 -         run_log_save(): Batch 340, epoch 11/20:
2017-12-03 01:50:53,838:train.py:200 -         run_log_save():    avg word perp:   9.65
2017-12-03 01:50:53,838:train.py:201 -         run_log_save():    acc trg words/s: 2477
2017-12-03 01:50:53,839:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:51:58,454:train.py:199 -         run_log_save(): Batch 440, epoch 11/20:
2017-12-03 01:51:58,455:train.py:200 -         run_log_save():    avg word perp:   9.58
2017-12-03 01:51:58,455:train.py:201 -         run_log_save():    acc trg words/s: 2478
2017-12-03 01:51:58,455:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:53:03,804:train.py:199 -         run_log_save(): Batch 540, epoch 11/20:
2017-12-03 01:53:03,804:train.py:200 -         run_log_save():    avg word perp:   9.54
2017-12-03 01:53:03,804:train.py:201 -         run_log_save():    acc trg words/s: 2478
2017-12-03 01:53:03,804:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:54:10,184:train.py:199 -         run_log_save(): Batch 640, epoch 11/20:
2017-12-03 01:54:10,185:train.py:200 -         run_log_save():    avg word perp:   9.63
2017-12-03 01:54:10,185:train.py:201 -         run_log_save():    acc trg words/s: 2472
2017-12-03 01:54:10,185:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:55:15,297:train.py:199 -         run_log_save(): Batch 740, epoch 11/20:
2017-12-03 01:55:15,297:train.py:200 -         run_log_save():    avg word perp:   9.48
2017-12-03 01:55:15,297:train.py:201 -         run_log_save():    acc trg words/s: 2473
2017-12-03 01:55:15,297:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:56:20,552:train.py:199 -         run_log_save(): Batch 840, epoch 11/20:
2017-12-03 01:56:20,552:train.py:200 -         run_log_save():    avg word perp:   9.55
2017-12-03 01:56:20,552:train.py:201 -         run_log_save():    acc trg words/s: 2476
2017-12-03 01:56:20,552:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:57:25,467:train.py:199 -         run_log_save(): Batch 940, epoch 11/20:
2017-12-03 01:57:25,468:train.py:200 -         run_log_save():    avg word perp:   9.52
2017-12-03 01:57:25,468:train.py:201 -         run_log_save():    acc trg words/s: 2476
2017-12-03 01:57:25,468:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:58:31,280:train.py:199 -         run_log_save(): Batch 1040, epoch 11/20:
2017-12-03 01:58:31,280:train.py:200 -         run_log_save():    avg word perp:   9.49
2017-12-03 01:58:31,280:train.py:201 -         run_log_save():    acc trg words/s: 2475
2017-12-03 01:58:31,280:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 01:59:36,601:train.py:199 -         run_log_save(): Batch 1140, epoch 11/20:
2017-12-03 01:59:36,601:train.py:200 -         run_log_save():    avg word perp:   9.46
2017-12-03 01:59:36,601:train.py:201 -         run_log_save():    acc trg words/s: 2476
2017-12-03 01:59:36,601:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:00:41,693:train.py:151 -         sample_input(): Sample input data:
2017-12-03 02:00:41,693:train.py:152 -         sample_input(): Src: . errichten zu Anlagen entsprechende selbst , gestatten zu Ländern es statt , einrichtungen tungs@@ berei@@ Wiederauf@@ und - reicherungs@@ an@@ Atom@@ auf Zugriff garantierten international den über Vereinbarungen von handlung Aus@@ die und Inspektionen strengere durch regimes Nichtverbreitungs@@ des Stärkung die auf drängen sie _PAD _PAD _PAD _PAD _PAD
2017-12-03 02:00:41,693:train.py:153 -         sample_input(): Src len: 45
2017-12-03 02:00:41,693:train.py:154 -         sample_input(): Trg: _BOS they urge strengthening the non @-@ proliferation regime through more intrusive inspections , and negotiation of arrangements for internationally guaranteed access to nuclear enrichment and re@@ processing services , rather than allowing countries to construct them for themselves . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 02:00:41,693:train.py:155 -         sample_input(): Tar: they urge strengthening the non @-@ proliferation regime through more intrusive inspections , and negotiation of arrangements for internationally guaranteed access to nuclear enrichment and re@@ processing services , rather than allowing countries to construct them for themselves . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 02:00:41,693:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 02:00:41,693:train.py:199 -         run_log_save(): Batch 1240, epoch 11/20:
2017-12-03 02:00:41,694:train.py:200 -         run_log_save():    avg word perp:   9.31
2017-12-03 02:00:41,694:train.py:201 -         run_log_save():    acc trg words/s: 2476
2017-12-03 02:00:41,694:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:01:47,093:train.py:199 -         run_log_save(): Batch 1340, epoch 11/20:
2017-12-03 02:01:47,093:train.py:200 -         run_log_save():    avg word perp:   9.51
2017-12-03 02:01:47,093:train.py:201 -         run_log_save():    acc trg words/s: 2475
2017-12-03 02:01:47,093:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:02:52,369:train.py:199 -         run_log_save(): Batch 1440, epoch 11/20:
2017-12-03 02:02:52,370:train.py:200 -         run_log_save():    avg word perp:   9.72
2017-12-03 02:02:52,370:train.py:201 -         run_log_save():    acc trg words/s: 2475
2017-12-03 02:02:52,370:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:03:57,990:train.py:199 -         run_log_save(): Batch 1540, epoch 11/20:
2017-12-03 02:03:57,990:train.py:200 -         run_log_save():    avg word perp:   9.50
2017-12-03 02:03:57,990:train.py:201 -         run_log_save():    acc trg words/s: 2474
2017-12-03 02:03:57,990:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:05:03,493:train.py:199 -         run_log_save(): Batch 1640, epoch 11/20:
2017-12-03 02:05:03,494:train.py:200 -         run_log_save():    avg word perp:   9.61
2017-12-03 02:05:03,494:train.py:201 -         run_log_save():    acc trg words/s: 2473
2017-12-03 02:05:03,494:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:06:09,886:train.py:199 -         run_log_save(): Batch 1740, epoch 11/20:
2017-12-03 02:06:09,886:train.py:200 -         run_log_save():    avg word perp:   9.62
2017-12-03 02:06:09,886:train.py:201 -         run_log_save():    acc trg words/s: 2471
2017-12-03 02:06:09,886:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:07:15,700:train.py:199 -         run_log_save(): Batch 1840, epoch 11/20:
2017-12-03 02:07:15,700:train.py:200 -         run_log_save():    avg word perp:   9.75
2017-12-03 02:07:15,700:train.py:201 -         run_log_save():    acc trg words/s: 2470
2017-12-03 02:07:15,700:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:08:21,705:train.py:199 -         run_log_save(): Batch 1940, epoch 11/20:
2017-12-03 02:08:21,705:train.py:200 -         run_log_save():    avg word perp:   9.68
2017-12-03 02:08:21,706:train.py:201 -         run_log_save():    acc trg words/s: 2470
2017-12-03 02:08:21,706:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:09:26,769:train.py:199 -         run_log_save(): Batch 2040, epoch 11/20:
2017-12-03 02:09:26,769:train.py:200 -         run_log_save():    avg word perp:   9.70
2017-12-03 02:09:26,769:train.py:201 -         run_log_save():    acc trg words/s: 2471
2017-12-03 02:09:26,769:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:10:32,205:train.py:199 -         run_log_save(): Batch 2140, epoch 11/20:
2017-12-03 02:10:32,205:train.py:200 -         run_log_save():    avg word perp:   9.44
2017-12-03 02:10:32,205:train.py:201 -         run_log_save():    acc trg words/s: 2471
2017-12-03 02:10:32,205:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:11:38,663:train.py:151 -         sample_input(): Sample input data:
2017-12-03 02:11:38,663:train.py:152 -         sample_input(): Src: . ab d ei@@ Amts@@ seinen Platz @-@ Tahrir dem auf ) 2012 Juni 29. ( &quot; Machtübergabe der tag Frei@@ &quot; am legte , wurde verhaftet ) 2011 Januar 28. ( &quot; ns Zor@@ des tag Frei@@ &quot; dem nach der , Mann ein _PAD _PAD _PAD _PAD _PAD
2017-12-03 02:11:38,663:train.py:153 -         sample_input(): Src len: 45
2017-12-03 02:11:38,663:train.py:154 -         sample_input(): Trg: _BOS a man imprisoned following the &quot; Fri@@ day of R@@ age &quot; ( January 28 , 2011 ) took the presidential oath in Tahrir on a &quot; Fri@@ day of Power Transfer &quot; ( June 29 , 2012 ) . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 02:11:38,663:train.py:155 -         sample_input(): Tar: a man imprisoned following the &quot; Fri@@ day of R@@ age &quot; ( January 28 , 2011 ) took the presidential oath in Tahrir on a &quot; Fri@@ day of Power Transfer &quot; ( June 29 , 2012 ) . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 02:11:38,663:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 02:11:38,663:train.py:199 -         run_log_save(): Batch 2240, epoch 11/20:
2017-12-03 02:11:38,663:train.py:200 -         run_log_save():    avg word perp:   9.56
2017-12-03 02:11:38,663:train.py:201 -         run_log_save():    acc trg words/s: 2469
2017-12-03 02:11:38,663:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:11:42,156:train.py:207 -         run_log_save(): Save model to ./nmt/saved_models/de2en_bp/de2en_bp.cpkt, takes 0:00:03.492070
2017-12-03 02:11:42,156:validator.py:224 -    validate_and_save(): Start validation
2017-12-03 02:12:42,866:validator.py:143 -             evaluate():   Translating line 100, average 0.607090051174 seconds/sent
2017-12-03 02:13:40,013:validator.py:143 -             evaluate():   Translating line 200, average 0.589279534817 seconds/sent
2017-12-03 02:14:32,257:validator.py:143 -             evaluate():   Translating line 300, average 0.567001193364 seconds/sent
2017-12-03 02:15:26,123:validator.py:143 -             evaluate():   Translating line 400, average 0.559915015101 seconds/sent
2017-12-03 02:16:26,922:validator.py:143 -             evaluate():   Translating line 500, average 0.569531244278 seconds/sent
2017-12-03 02:17:20,324:validator.py:143 -             evaluate():   Translating line 600, average 0.563612661759 seconds/sent
2017-12-03 02:18:19,158:validator.py:143 -             evaluate():   Translating line 700, average 0.567144745759 seconds/sent
2017-12-03 02:19:04,445:validator.py:143 -             evaluate():   Translating line 800, average 0.552860851288 seconds/sent
2017-12-03 02:19:45,552:validator.py:143 -             evaluate():   Translating line 900, average 0.537105518977 seconds/sent
2017-12-03 02:20:36,897:validator.py:143 -             evaluate():   Translating line 1000, average 0.534740439177 seconds/sent
2017-12-03 02:21:28,453:validator.py:143 -             evaluate():   Translating line 1100, average 0.532996759198 seconds/sent
2017-12-03 02:22:15,810:validator.py:143 -             evaluate():   Translating line 1200, average 0.528044600884 seconds/sent
2017-12-03 02:23:23,795:validator.py:143 -             evaluate():   Translating line 1300, average 0.53972207693 seconds/sent
2017-12-03 02:24:22,474:validator.py:143 -             evaluate():   Translating line 1400, average 0.54308381285 seconds/sent
2017-12-03 02:25:19,630:validator.py:143 -             evaluate():   Translating line 1500, average 0.544982162635 seconds/sent
2017-12-03 02:26:17,414:validator.py:143 -             evaluate():   Translating line 1600, average 0.547035521865 seconds/sent
2017-12-03 02:27:14,400:validator.py:143 -             evaluate():   Translating line 1700, average 0.548378594202 seconds/sent
2017-12-03 02:28:20,580:validator.py:143 -             evaluate():   Translating line 1800, average 0.554679703977 seconds/sent
2017-12-03 02:29:21,861:validator.py:143 -             evaluate():   Translating line 1900, average 0.557738860532 seconds/sent
2017-12-03 02:29:59,470:validator.py:152 -             evaluate(): Done translating.
2017-12-03 02:29:59,470:validator.py:153 -             evaluate(): dev perplexity: 64.351
2017-12-03 02:29:59,945:validator.py:159 -             evaluate(): BLEU = 12.71, 43.0/18.2/9.1/4.8 (BP=0.937, ratio=0.939, hyp_len=42513, ref_len=45274)

2017-12-03 02:29:59,945:validator.py:160 -             evaluate(): Validation took: 18.2964683175 minutes
2017-12-03 02:29:59,948:validator.py:195 -           maybe_save(): Current best bleus: 11.17
2017-12-03 02:29:59,948:validator.py:196 -           maybe_save(): Delete 11.17 & use 12.71 instead
2017-12-03 02:29:59,948:validator.py:206 -           maybe_save(): Delete ./nmt/saved_models/de2en_bp/de2en_bp-11.17.cpkt.data-00000-of-00001 & ./nmt/saved_models/de2en_bp/de2en_bp-11.17.cpkt.meta & ./nmt/saved_models/de2en_bp/de2en_bp-11.17.cpkt.index
2017-12-03 02:29:59,973:validator.py:212 -           maybe_save(): Save 12.71 to list of best bleu scores
2017-12-03 02:30:00,533:validator.py:216 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en_bp/de2en_bp-12.71.cpkt
2017-12-03 02:30:00,533:validator.py:217 -           maybe_save(): Best bleu scores so far: 12.71
2017-12-03 02:31:05,946:train.py:199 -         run_log_save(): Batch 2340, epoch 11/20:
2017-12-03 02:31:05,947:train.py:200 -         run_log_save():    avg word perp:   9.84
2017-12-03 02:31:05,947:train.py:201 -         run_log_save():    acc trg words/s: 2469
2017-12-03 02:31:05,947:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:32:12,364:train.py:199 -         run_log_save(): Batch 2440, epoch 11/20:
2017-12-03 02:32:12,364:train.py:200 -         run_log_save():    avg word perp:   9.60
2017-12-03 02:32:12,364:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-03 02:32:12,364:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:33:14,496:train.py:199 -         run_log_save(): Batch 2540, epoch 11/20:
2017-12-03 02:33:14,496:train.py:200 -         run_log_save():    avg word perp:   9.65
2017-12-03 02:33:14,496:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-03 02:33:14,496:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:33:21,301:train.py:199 -         run_log_save(): Batch 2640, epoch 11/20:
2017-12-03 02:33:21,301:train.py:200 -         run_log_save():    avg word perp:   448.08
2017-12-03 02:33:21,301:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-03 02:33:21,301:train.py:202 -         run_log_save():    acc sec/batch:   0.63
2017-12-03 02:33:28,164:train.py:199 -         run_log_save(): Batch 2740, epoch 11/20:
2017-12-03 02:33:28,164:train.py:200 -         run_log_save():    avg word perp:   352.55
2017-12-03 02:33:28,164:train.py:201 -         run_log_save():    acc trg words/s: 2468
2017-12-03 02:33:28,164:train.py:202 -         run_log_save():    acc sec/batch:   0.61
2017-12-03 02:33:35,144:train.py:199 -         run_log_save(): Batch 2840, epoch 11/20:
2017-12-03 02:33:35,144:train.py:200 -         run_log_save():    avg word perp:   334.81
2017-12-03 02:33:35,144:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-03 02:33:35,144:train.py:202 -         run_log_save():    acc sec/batch:   0.59
2017-12-03 02:33:42,043:train.py:199 -         run_log_save(): Batch 2940, epoch 11/20:
2017-12-03 02:33:42,043:train.py:200 -         run_log_save():    avg word perp:   319.03
2017-12-03 02:33:42,043:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-03 02:33:42,043:train.py:202 -         run_log_save():    acc sec/batch:   0.57
2017-12-03 02:33:48,924:train.py:199 -         run_log_save(): Batch 3040, epoch 11/20:
2017-12-03 02:33:48,925:train.py:200 -         run_log_save():    avg word perp:   316.17
2017-12-03 02:33:48,925:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-03 02:33:48,925:train.py:202 -         run_log_save():    acc sec/batch:   0.56
2017-12-03 02:33:55,823:train.py:199 -         run_log_save(): Batch 3140, epoch 11/20:
2017-12-03 02:33:55,823:train.py:200 -         run_log_save():    avg word perp:   310.01
2017-12-03 02:33:55,823:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-03 02:33:55,823:train.py:202 -         run_log_save():    acc sec/batch:   0.54
2017-12-03 02:34:02,683:train.py:151 -         sample_input(): Sample input data:
2017-12-03 02:34:02,684:train.py:152 -         sample_input(): Src: _UNK
2017-12-03 02:34:02,684:train.py:153 -         sample_input(): Src len: 1
2017-12-03 02:34:02,684:train.py:154 -         sample_input(): Trg: _BOS cartridge slide
2017-12-03 02:34:02,684:train.py:155 -         sample_input(): Tar: cartridge slide _EOS
2017-12-03 02:34:02,684:train.py:156 -         sample_input(): W: 1.0 1.0 1.0
2017-12-03 02:34:02,684:train.py:199 -         run_log_save(): Batch 3240, epoch 11/20:
2017-12-03 02:34:02,684:train.py:200 -         run_log_save():    avg word perp:   316.13
2017-12-03 02:34:02,684:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 02:34:02,684:train.py:202 -         run_log_save():    acc sec/batch:   0.53
2017-12-03 02:34:05,165:train.py:119 -         report_epoch(): Finish epoch 11
2017-12-03 02:34:05,166:train.py:120 -         report_epoch():     It takes 0:28:23.513482
2017-12-03 02:34:05,166:train.py:121 -         report_epoch():     Avergage # words/second    2466.86923477
2017-12-03 02:34:05,166:train.py:122 -         report_epoch():     Average seconds/batch    0.519998010407
2017-12-03 02:34:05,166:train.py:133 -         report_epoch():     train perplexity: 10.659552814
2017-12-03 02:34:05,671:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.50551700592 seconds
2017-12-03 02:34:46,945:train.py:199 -         run_log_save(): Batch 64, epoch 12/20:
2017-12-03 02:34:46,945:train.py:200 -         run_log_save():    avg word perp:   12.47
2017-12-03 02:34:46,945:train.py:201 -         run_log_save():    acc trg words/s: 2396
2017-12-03 02:34:46,945:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-03 02:35:52,321:train.py:199 -         run_log_save(): Batch 164, epoch 12/20:
2017-12-03 02:35:52,321:train.py:200 -         run_log_save():    avg word perp:   9.21
2017-12-03 02:35:52,321:train.py:201 -         run_log_save():    acc trg words/s: 2445
2017-12-03 02:35:52,321:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:36:58,065:train.py:199 -         run_log_save(): Batch 264, epoch 12/20:
2017-12-03 02:36:58,065:train.py:200 -         run_log_save():    avg word perp:   8.83
2017-12-03 02:36:58,066:train.py:201 -         run_log_save():    acc trg words/s: 2453
2017-12-03 02:36:58,066:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:38:02,988:train.py:199 -         run_log_save(): Batch 364, epoch 12/20:
2017-12-03 02:38:02,988:train.py:200 -         run_log_save():    avg word perp:   8.80
2017-12-03 02:38:02,988:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 02:38:02,988:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:39:08,883:train.py:199 -         run_log_save(): Batch 464, epoch 12/20:
2017-12-03 02:39:08,883:train.py:200 -         run_log_save():    avg word perp:   8.87
2017-12-03 02:39:08,883:train.py:201 -         run_log_save():    acc trg words/s: 2455
2017-12-03 02:39:08,883:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:40:14,619:train.py:199 -         run_log_save(): Batch 564, epoch 12/20:
2017-12-03 02:40:14,619:train.py:200 -         run_log_save():    avg word perp:   8.98
2017-12-03 02:40:14,619:train.py:201 -         run_log_save():    acc trg words/s: 2455
2017-12-03 02:40:14,619:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:41:20,328:train.py:199 -         run_log_save(): Batch 664, epoch 12/20:
2017-12-03 02:41:20,329:train.py:200 -         run_log_save():    avg word perp:   9.06
2017-12-03 02:41:20,329:train.py:201 -         run_log_save():    acc trg words/s: 2454
2017-12-03 02:41:20,329:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:42:25,351:train.py:199 -         run_log_save(): Batch 764, epoch 12/20:
2017-12-03 02:42:25,351:train.py:200 -         run_log_save():    avg word perp:   8.98
2017-12-03 02:42:25,351:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-03 02:42:25,351:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:43:30,476:train.py:199 -         run_log_save(): Batch 864, epoch 12/20:
2017-12-03 02:43:30,476:train.py:200 -         run_log_save():    avg word perp:   8.92
2017-12-03 02:43:30,476:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-03 02:43:30,476:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:44:36,572:train.py:151 -         sample_input(): Sample input data:
2017-12-03 02:44:36,572:train.py:152 -         sample_input(): Src: . tun Gutes meisten am Geld unser um wir können Bereichen diesen in _PAD _PAD
2017-12-03 02:44:36,572:train.py:153 -         sample_input(): Src len: 13
2017-12-03 02:44:36,572:train.py:154 -         sample_input(): Trg: _BOS this was where we could do the most good for our money . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 02:44:36,572:train.py:155 -         sample_input(): Tar: this was where we could do the most good for our money . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 02:44:36,572:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 02:44:36,572:train.py:199 -         run_log_save(): Batch 964, epoch 12/20:
2017-12-03 02:44:36,572:train.py:200 -         run_log_save():    avg word perp:   8.94
2017-12-03 02:44:36,573:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-03 02:44:36,573:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:45:42,162:train.py:199 -         run_log_save(): Batch 1064, epoch 12/20:
2017-12-03 02:45:42,162:train.py:200 -         run_log_save():    avg word perp:   8.89
2017-12-03 02:45:42,162:train.py:201 -         run_log_save():    acc trg words/s: 2458
2017-12-03 02:45:42,162:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:46:48,667:train.py:199 -         run_log_save(): Batch 1164, epoch 12/20:
2017-12-03 02:46:48,667:train.py:200 -         run_log_save():    avg word perp:   9.18
2017-12-03 02:46:48,667:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-03 02:46:48,667:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:47:53,410:train.py:199 -         run_log_save(): Batch 1264, epoch 12/20:
2017-12-03 02:47:53,410:train.py:200 -         run_log_save():    avg word perp:   9.04
2017-12-03 02:47:53,410:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-03 02:47:53,410:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:48:58,671:train.py:199 -         run_log_save(): Batch 1364, epoch 12/20:
2017-12-03 02:48:58,671:train.py:200 -         run_log_save():    avg word perp:   9.23
2017-12-03 02:48:58,671:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 02:48:58,671:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:50:05,990:train.py:199 -         run_log_save(): Batch 1464, epoch 12/20:
2017-12-03 02:50:05,990:train.py:200 -         run_log_save():    avg word perp:   9.06
2017-12-03 02:50:05,990:train.py:201 -         run_log_save():    acc trg words/s: 2458
2017-12-03 02:50:05,990:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:51:12,596:train.py:199 -         run_log_save(): Batch 1564, epoch 12/20:
2017-12-03 02:51:12,596:train.py:200 -         run_log_save():    avg word perp:   9.07
2017-12-03 02:51:12,596:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-03 02:51:12,596:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:52:18,225:train.py:199 -         run_log_save(): Batch 1664, epoch 12/20:
2017-12-03 02:52:18,225:train.py:200 -         run_log_save():    avg word perp:   9.16
2017-12-03 02:52:18,225:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-03 02:52:18,225:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:53:24,878:train.py:199 -         run_log_save(): Batch 1764, epoch 12/20:
2017-12-03 02:53:24,878:train.py:200 -         run_log_save():    avg word perp:   9.16
2017-12-03 02:53:24,878:train.py:201 -         run_log_save():    acc trg words/s: 2455
2017-12-03 02:53:24,878:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:54:30,874:train.py:199 -         run_log_save(): Batch 1864, epoch 12/20:
2017-12-03 02:54:30,874:train.py:200 -         run_log_save():    avg word perp:   9.11
2017-12-03 02:54:30,874:train.py:201 -         run_log_save():    acc trg words/s: 2454
2017-12-03 02:54:30,874:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:55:36,929:train.py:151 -         sample_input(): Sample input data:
2017-12-03 02:55:36,931:train.py:152 -         sample_input(): Src: . Erneuerung wirtschaftlichen zur Chancen historische bietet Welt der Marktes zweitgrößten des Erweiterung die _PAD _PAD
2017-12-03 02:55:36,931:train.py:153 -         sample_input(): Src len: 14
2017-12-03 02:55:36,931:train.py:154 -         sample_input(): Trg: _BOS expansion of the world &apos;s second @-@ largest market offers historic opportunities for economic renewal . _PAD _PAD _PAD _PAD
2017-12-03 02:55:36,931:train.py:155 -         sample_input(): Tar: expansion of the world &apos;s second @-@ largest market offers historic opportunities for economic renewal . _EOS _PAD _PAD _PAD _PAD
2017-12-03 02:55:36,931:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0
2017-12-03 02:55:36,931:train.py:199 -         run_log_save(): Batch 1964, epoch 12/20:
2017-12-03 02:55:36,931:train.py:200 -         run_log_save():    avg word perp:   9.21
2017-12-03 02:55:36,931:train.py:201 -         run_log_save():    acc trg words/s: 2454
2017-12-03 02:55:36,931:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:56:42,132:train.py:199 -         run_log_save(): Batch 2064, epoch 12/20:
2017-12-03 02:56:42,132:train.py:200 -         run_log_save():    avg word perp:   9.21
2017-12-03 02:56:42,132:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-03 02:56:42,132:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:57:48,132:train.py:199 -         run_log_save(): Batch 2164, epoch 12/20:
2017-12-03 02:57:48,133:train.py:200 -         run_log_save():    avg word perp:   9.30
2017-12-03 02:57:48,133:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-03 02:57:48,133:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 02:58:53,707:train.py:199 -         run_log_save(): Batch 2264, epoch 12/20:
2017-12-03 02:58:53,707:train.py:200 -         run_log_save():    avg word perp:   9.13
2017-12-03 02:58:53,707:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-03 02:58:53,707:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 03:00:00,573:train.py:199 -         run_log_save(): Batch 2364, epoch 12/20:
2017-12-03 03:00:00,573:train.py:200 -         run_log_save():    avg word perp:   9.29
2017-12-03 03:00:00,573:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-03 03:00:00,573:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 03:01:06,946:train.py:199 -         run_log_save(): Batch 2464, epoch 12/20:
2017-12-03 03:01:06,947:train.py:200 -         run_log_save():    avg word perp:   9.25
2017-12-03 03:01:06,947:train.py:201 -         run_log_save():    acc trg words/s: 2456
2017-12-03 03:01:06,947:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 03:01:57,222:train.py:199 -         run_log_save(): Batch 2564, epoch 12/20:
2017-12-03 03:01:57,222:train.py:200 -         run_log_save():    avg word perp:   10.81
2017-12-03 03:01:57,222:train.py:201 -         run_log_save():    acc trg words/s: 2455
2017-12-03 03:01:57,222:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 03:02:04,113:train.py:199 -         run_log_save(): Batch 2664, epoch 12/20:
2017-12-03 03:02:04,113:train.py:200 -         run_log_save():    avg word perp:   399.46
2017-12-03 03:02:04,113:train.py:201 -         run_log_save():    acc trg words/s: 2455
2017-12-03 03:02:04,113:train.py:202 -         run_log_save():    acc sec/batch:   0.63
2017-12-03 03:02:10,972:train.py:199 -         run_log_save(): Batch 2764, epoch 12/20:
2017-12-03 03:02:10,972:train.py:200 -         run_log_save():    avg word perp:   347.65
2017-12-03 03:02:10,972:train.py:201 -         run_log_save():    acc trg words/s: 2455
2017-12-03 03:02:10,972:train.py:202 -         run_log_save():    acc sec/batch:   0.61
2017-12-03 03:02:17,783:train.py:199 -         run_log_save(): Batch 2864, epoch 12/20:
2017-12-03 03:02:17,784:train.py:200 -         run_log_save():    avg word perp:   345.64
2017-12-03 03:02:17,784:train.py:201 -         run_log_save():    acc trg words/s: 2455
2017-12-03 03:02:17,784:train.py:202 -         run_log_save():    acc sec/batch:   0.59
2017-12-03 03:02:24,606:train.py:151 -         sample_input(): Sample input data:
2017-12-03 03:02:24,606:train.py:152 -         sample_input(): Src: gröblich
2017-12-03 03:02:24,606:train.py:153 -         sample_input(): Src len: 1
2017-12-03 03:02:24,606:train.py:154 -         sample_input(): Trg: _BOS coarsely _PAD
2017-12-03 03:02:24,606:train.py:155 -         sample_input(): Tar: coarsely _EOS _PAD
2017-12-03 03:02:24,606:train.py:156 -         sample_input(): W: 1.0 1.0 0.0
2017-12-03 03:02:24,606:train.py:199 -         run_log_save(): Batch 2964, epoch 12/20:
2017-12-03 03:02:24,606:train.py:200 -         run_log_save():    avg word perp:   334.59
2017-12-03 03:02:24,606:train.py:201 -         run_log_save():    acc trg words/s: 2455
2017-12-03 03:02:24,607:train.py:202 -         run_log_save():    acc sec/batch:   0.57
2017-12-03 03:02:31,396:train.py:199 -         run_log_save(): Batch 3064, epoch 12/20:
2017-12-03 03:02:31,396:train.py:200 -         run_log_save():    avg word perp:   323.42
2017-12-03 03:02:31,396:train.py:201 -         run_log_save():    acc trg words/s: 2455
2017-12-03 03:02:31,396:train.py:202 -         run_log_save():    acc sec/batch:   0.55
2017-12-03 03:02:38,294:train.py:199 -         run_log_save(): Batch 3164, epoch 12/20:
2017-12-03 03:02:38,294:train.py:200 -         run_log_save():    avg word perp:   333.82
2017-12-03 03:02:38,294:train.py:201 -         run_log_save():    acc trg words/s: 2454
2017-12-03 03:02:38,294:train.py:202 -         run_log_save():    acc sec/batch:   0.54
2017-12-03 03:02:45,150:train.py:199 -         run_log_save(): Batch 3264, epoch 12/20:
2017-12-03 03:02:45,151:train.py:200 -         run_log_save():    avg word perp:   328.81
2017-12-03 03:02:45,151:train.py:201 -         run_log_save():    acc trg words/s: 2454
2017-12-03 03:02:45,151:train.py:202 -         run_log_save():    acc sec/batch:   0.52
2017-12-03 03:02:46,021:train.py:119 -         report_epoch(): Finish epoch 12
2017-12-03 03:02:46,021:train.py:120 -         report_epoch():     It takes 0:28:31.898168
2017-12-03 03:02:46,021:train.py:121 -         report_epoch():     Avergage # words/second    2454.73421127
2017-12-03 03:02:46,021:train.py:122 -         report_epoch():     Average seconds/batch    0.522557438439
2017-12-03 03:02:46,021:train.py:133 -         report_epoch():     train perplexity: 10.1229238387
2017-12-03 03:02:46,525:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.503021001816 seconds
2017-12-03 03:03:42,595:train.py:199 -         run_log_save(): Batch 88, epoch 13/20:
2017-12-03 03:03:42,595:train.py:200 -         run_log_save():    avg word perp:   9.93
2017-12-03 03:03:42,595:train.py:201 -         run_log_save():    acc trg words/s: 2444
2017-12-03 03:03:42,595:train.py:202 -         run_log_save():    acc sec/batch:   0.63
2017-12-03 03:04:49,171:train.py:199 -         run_log_save(): Batch 188, epoch 13/20:
2017-12-03 03:04:49,172:train.py:200 -         run_log_save():    avg word perp:   8.64
2017-12-03 03:04:49,172:train.py:201 -         run_log_save():    acc trg words/s: 2446
2017-12-03 03:04:49,172:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 03:05:56,501:train.py:199 -         run_log_save(): Batch 288, epoch 13/20:
2017-12-03 03:05:56,501:train.py:200 -         run_log_save():    avg word perp:   8.43
2017-12-03 03:05:56,501:train.py:201 -         run_log_save():    acc trg words/s: 2425
2017-12-03 03:05:56,501:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:07:03,510:train.py:199 -         run_log_save(): Batch 388, epoch 13/20:
2017-12-03 03:07:03,510:train.py:200 -         run_log_save():    avg word perp:   8.73
2017-12-03 03:07:03,510:train.py:201 -         run_log_save():    acc trg words/s: 2425
2017-12-03 03:07:03,510:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:08:09,130:train.py:199 -         run_log_save(): Batch 488, epoch 13/20:
2017-12-03 03:08:09,130:train.py:200 -         run_log_save():    avg word perp:   8.53
2017-12-03 03:08:09,130:train.py:201 -         run_log_save():    acc trg words/s: 2433
2017-12-03 03:08:09,130:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:09:15,268:train.py:199 -         run_log_save(): Batch 588, epoch 13/20:
2017-12-03 03:09:15,269:train.py:200 -         run_log_save():    avg word perp:   8.41
2017-12-03 03:09:15,269:train.py:201 -         run_log_save():    acc trg words/s: 2437
2017-12-03 03:09:15,269:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:10:20,712:train.py:151 -         sample_input(): Sample input data:
2017-12-03 03:10:20,712:train.py:152 -         sample_input(): Src: . verbunden Schmerzen ökonomischen erheblichen mit ist Euro dem aus Griechenlands Ausstieg geordneter ein : vor nichts uns wir machen _PAD _PAD
2017-12-03 03:10:20,713:train.py:153 -         sample_input(): Src len: 20
2017-12-03 03:10:20,713:train.py:154 -         sample_input(): Trg: _BOS make no mistake : an orderly euro exit by Greece implies significant economic pain . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 03:10:20,713:train.py:155 -         sample_input(): Tar: make no mistake : an orderly euro exit by Greece implies significant economic pain . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 03:10:20,713:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 03:10:20,713:train.py:199 -         run_log_save(): Batch 688, epoch 13/20:
2017-12-03 03:10:20,713:train.py:200 -         run_log_save():    avg word perp:   8.71
2017-12-03 03:10:20,713:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 03:10:20,713:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:10:24,358:train.py:207 -         run_log_save(): Save model to ./nmt/saved_models/de2en_bp/de2en_bp.cpkt, takes 0:00:03.644562
2017-12-03 03:11:30,900:train.py:199 -         run_log_save(): Batch 788, epoch 13/20:
2017-12-03 03:11:30,900:train.py:200 -         run_log_save():    avg word perp:   8.57
2017-12-03 03:11:30,900:train.py:201 -         run_log_save():    acc trg words/s: 2439
2017-12-03 03:11:30,900:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:12:36,853:train.py:199 -         run_log_save(): Batch 888, epoch 13/20:
2017-12-03 03:12:36,853:train.py:200 -         run_log_save():    avg word perp:   8.63
2017-12-03 03:12:36,853:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 03:12:36,853:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:13:43,028:train.py:199 -         run_log_save(): Batch 988, epoch 13/20:
2017-12-03 03:13:43,028:train.py:200 -         run_log_save():    avg word perp:   8.52
2017-12-03 03:13:43,028:train.py:201 -         run_log_save():    acc trg words/s: 2439
2017-12-03 03:13:43,028:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:14:49,771:train.py:199 -         run_log_save(): Batch 1088, epoch 13/20:
2017-12-03 03:14:49,773:train.py:200 -         run_log_save():    avg word perp:   8.78
2017-12-03 03:14:49,773:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 03:14:49,773:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:15:56,856:train.py:199 -         run_log_save(): Batch 1188, epoch 13/20:
2017-12-03 03:15:56,856:train.py:200 -         run_log_save():    avg word perp:   8.80
2017-12-03 03:15:56,856:train.py:201 -         run_log_save():    acc trg words/s: 2436
2017-12-03 03:15:56,857:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:17:02,655:train.py:199 -         run_log_save(): Batch 1288, epoch 13/20:
2017-12-03 03:17:02,655:train.py:200 -         run_log_save():    avg word perp:   8.43
2017-12-03 03:17:02,655:train.py:201 -         run_log_save():    acc trg words/s: 2437
2017-12-03 03:17:02,655:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:18:09,424:train.py:199 -         run_log_save(): Batch 1388, epoch 13/20:
2017-12-03 03:18:09,424:train.py:200 -         run_log_save():    avg word perp:   8.59
2017-12-03 03:18:09,425:train.py:201 -         run_log_save():    acc trg words/s: 2436
2017-12-03 03:18:09,425:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:19:15,970:train.py:199 -         run_log_save(): Batch 1488, epoch 13/20:
2017-12-03 03:19:15,970:train.py:200 -         run_log_save():    avg word perp:   8.83
2017-12-03 03:19:15,970:train.py:201 -         run_log_save():    acc trg words/s: 2435
2017-12-03 03:19:15,970:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:20:21,712:train.py:199 -         run_log_save(): Batch 1588, epoch 13/20:
2017-12-03 03:20:21,712:train.py:200 -         run_log_save():    avg word perp:   8.54
2017-12-03 03:20:21,712:train.py:201 -         run_log_save():    acc trg words/s: 2437
2017-12-03 03:20:21,712:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:21:28,182:train.py:151 -         sample_input(): Sample input data:
2017-12-03 03:21:28,182:train.py:152 -         sample_input(): Src: . gangen über@@ gesetz Menschenrechts@@ das wird , eintritt Menschenrechte die für jemand heute wenn : genug nicht damit und _PAD _PAD
2017-12-03 03:21:28,182:train.py:153 -         sample_input(): Src len: 20
2017-12-03 03:21:28,182:train.py:154 -         sample_input(): Trg: _BOS indeed , even when the cause of human rights is being advanced , the Human Rights Act is now overlooked . _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 03:21:28,182:train.py:155 -         sample_input(): Tar: indeed , even when the cause of human rights is being advanced , the Human Rights Act is now overlooked . _EOS _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 03:21:28,182:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 03:21:28,182:train.py:199 -         run_log_save(): Batch 1688, epoch 13/20:
2017-12-03 03:21:28,182:train.py:200 -         run_log_save():    avg word perp:   8.89
2017-12-03 03:21:28,182:train.py:201 -         run_log_save():    acc trg words/s: 2436
2017-12-03 03:21:28,182:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:22:33,385:train.py:199 -         run_log_save(): Batch 1788, epoch 13/20:
2017-12-03 03:22:33,385:train.py:200 -         run_log_save():    avg word perp:   8.57
2017-12-03 03:22:33,385:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 03:22:33,385:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:23:38,941:train.py:199 -         run_log_save(): Batch 1888, epoch 13/20:
2017-12-03 03:23:38,941:train.py:200 -         run_log_save():    avg word perp:   8.92
2017-12-03 03:23:38,941:train.py:201 -         run_log_save():    acc trg words/s: 2440
2017-12-03 03:23:38,942:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:24:44,876:train.py:199 -         run_log_save(): Batch 1988, epoch 13/20:
2017-12-03 03:24:44,876:train.py:200 -         run_log_save():    avg word perp:   8.76
2017-12-03 03:24:44,876:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 03:24:44,876:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:25:51,439:train.py:199 -         run_log_save(): Batch 2088, epoch 13/20:
2017-12-03 03:25:51,439:train.py:200 -         run_log_save():    avg word perp:   8.89
2017-12-03 03:25:51,439:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 03:25:51,440:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:26:57,769:train.py:199 -         run_log_save(): Batch 2188, epoch 13/20:
2017-12-03 03:26:57,769:train.py:200 -         run_log_save():    avg word perp:   8.77
2017-12-03 03:26:57,769:train.py:201 -         run_log_save():    acc trg words/s: 2440
2017-12-03 03:26:57,769:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:28:04,020:train.py:199 -         run_log_save(): Batch 2288, epoch 13/20:
2017-12-03 03:28:04,021:train.py:200 -         run_log_save():    avg word perp:   8.66
2017-12-03 03:28:04,021:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 03:28:04,021:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:29:09,800:train.py:199 -         run_log_save(): Batch 2388, epoch 13/20:
2017-12-03 03:29:09,800:train.py:200 -         run_log_save():    avg word perp:   8.72
2017-12-03 03:29:09,801:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 03:29:09,801:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:30:16,065:train.py:199 -         run_log_save(): Batch 2488, epoch 13/20:
2017-12-03 03:30:16,065:train.py:200 -         run_log_save():    avg word perp:   8.68
2017-12-03 03:30:16,065:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 03:30:16,065:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:30:51,734:train.py:199 -         run_log_save(): Batch 2588, epoch 13/20:
2017-12-03 03:30:51,735:train.py:200 -         run_log_save():    avg word perp:   13.35
2017-12-03 03:30:51,735:train.py:201 -         run_log_save():    acc trg words/s: 2443
2017-12-03 03:30:51,735:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 03:30:58,562:train.py:151 -         sample_input(): Sample input data:
2017-12-03 03:30:58,562:train.py:152 -         sample_input(): Src: _UNK
2017-12-03 03:30:58,562:train.py:153 -         sample_input(): Src len: 1
2017-12-03 03:30:58,562:train.py:154 -         sample_input(): Trg: _BOS operations abroad
2017-12-03 03:30:58,562:train.py:155 -         sample_input(): Tar: operations abroad _EOS
2017-12-03 03:30:58,562:train.py:156 -         sample_input(): W: 1.0 1.0 1.0
2017-12-03 03:30:58,562:train.py:199 -         run_log_save(): Batch 2688, epoch 13/20:
2017-12-03 03:30:58,562:train.py:200 -         run_log_save():    avg word perp:   341.82
2017-12-03 03:30:58,563:train.py:201 -         run_log_save():    acc trg words/s: 2443
2017-12-03 03:30:58,563:train.py:202 -         run_log_save():    acc sec/batch:   0.63
2017-12-03 03:30:58,563:validator.py:224 -    validate_and_save(): Start validation
2017-12-03 03:31:21,485:validator.py:143 -             evaluate():   Translating line 100, average 0.229214661121 seconds/sent
2017-12-03 03:31:42,164:validator.py:143 -             evaluate():   Translating line 200, average 0.218001250029 seconds/sent
2017-12-03 03:32:02,323:validator.py:143 -             evaluate():   Translating line 300, average 0.212532673677 seconds/sent
2017-12-03 03:32:22,719:validator.py:143 -             evaluate():   Translating line 400, average 0.210390105247 seconds/sent
2017-12-03 03:32:45,854:validator.py:143 -             evaluate():   Translating line 500, average 0.214581066132 seconds/sent
2017-12-03 03:33:06,240:validator.py:143 -             evaluate():   Translating line 600, average 0.212793939908 seconds/sent
2017-12-03 03:33:27,362:validator.py:143 -             evaluate():   Translating line 700, average 0.21256997994 seconds/sent
2017-12-03 03:33:46,556:validator.py:143 -             evaluate():   Translating line 800, average 0.209991501272 seconds/sent
2017-12-03 03:34:05,910:validator.py:143 -             evaluate():   Translating line 900, average 0.208163443406 seconds/sent
2017-12-03 03:34:28,033:validator.py:143 -             evaluate():   Translating line 1000, average 0.209469943047 seconds/sent
2017-12-03 03:34:49,112:validator.py:143 -             evaluate():   Translating line 1100, average 0.209590188156 seconds/sent
2017-12-03 03:35:10,490:validator.py:143 -             evaluate():   Translating line 1200, average 0.209938585758 seconds/sent
2017-12-03 03:35:35,573:validator.py:143 -             evaluate():   Translating line 1300, average 0.213084779336 seconds/sent
2017-12-03 03:35:58,885:validator.py:143 -             evaluate():   Translating line 1400, average 0.214515595777 seconds/sent
2017-12-03 03:36:19,768:validator.py:143 -             evaluate():   Translating line 1500, average 0.214136324724 seconds/sent
2017-12-03 03:36:42,555:validator.py:143 -             evaluate():   Translating line 1600, average 0.214995139986 seconds/sent
2017-12-03 03:37:04,201:validator.py:143 -             evaluate():   Translating line 1700, average 0.215080778318 seconds/sent
2017-12-03 03:37:27,447:validator.py:143 -             evaluate():   Translating line 1800, average 0.216046623389 seconds/sent
2017-12-03 03:37:49,876:validator.py:143 -             evaluate():   Translating line 1900, average 0.21648043896 seconds/sent
2017-12-03 03:38:00,801:validator.py:152 -             evaluate(): Done translating.
2017-12-03 03:38:00,801:validator.py:153 -             evaluate(): dev perplexity: 442.091
2017-12-03 03:38:01,062:validator.py:159 -             evaluate(): BLEU = 0.00, 40.4/34.3/19.6/11.7 (BP=0.000, ratio=0.071, hyp_len=3215, ref_len=45274)

2017-12-03 03:38:01,062:validator.py:160 -             evaluate(): Validation took: 7.04164990187 minutes
2017-12-03 03:38:08,002:train.py:199 -         run_log_save(): Batch 2788, epoch 13/20:
2017-12-03 03:38:08,002:train.py:200 -         run_log_save():    avg word perp:   315.02
2017-12-03 03:38:08,002:train.py:201 -         run_log_save():    acc trg words/s: 2443
2017-12-03 03:38:08,002:train.py:202 -         run_log_save():    acc sec/batch:   0.61
2017-12-03 03:38:14,866:train.py:199 -         run_log_save(): Batch 2888, epoch 13/20:
2017-12-03 03:38:14,866:train.py:200 -         run_log_save():    avg word perp:   300.24
2017-12-03 03:38:14,867:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 03:38:14,867:train.py:202 -         run_log_save():    acc sec/batch:   0.59
2017-12-03 03:38:21,707:train.py:199 -         run_log_save(): Batch 2988, epoch 13/20:
2017-12-03 03:38:21,707:train.py:200 -         run_log_save():    avg word perp:   306.65
2017-12-03 03:38:21,707:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 03:38:21,707:train.py:202 -         run_log_save():    acc sec/batch:   0.57
2017-12-03 03:38:28,598:train.py:199 -         run_log_save(): Batch 3088, epoch 13/20:
2017-12-03 03:38:28,598:train.py:200 -         run_log_save():    avg word perp:   303.50
2017-12-03 03:38:28,598:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 03:38:28,599:train.py:202 -         run_log_save():    acc sec/batch:   0.55
2017-12-03 03:38:35,503:train.py:199 -         run_log_save(): Batch 3188, epoch 13/20:
2017-12-03 03:38:35,503:train.py:200 -         run_log_save():    avg word perp:   301.09
2017-12-03 03:38:35,503:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 03:38:35,503:train.py:202 -         run_log_save():    acc sec/batch:   0.54
2017-12-03 03:38:41,610:train.py:119 -         report_epoch(): Finish epoch 13
2017-12-03 03:38:41,610:train.py:120 -         report_epoch():     It takes 0:28:40.613629
2017-12-03 03:38:41,610:train.py:121 -         report_epoch():     Avergage # words/second    2442.3373896
2017-12-03 03:38:41,610:train.py:122 -         report_epoch():     Average seconds/batch    0.525217835574
2017-12-03 03:38:41,610:train.py:133 -         report_epoch():     train perplexity: 9.65236745851
2017-12-03 03:38:42,140:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.529169082642 seconds
2017-12-03 03:38:48,897:train.py:199 -         run_log_save(): Batch 12, epoch 14/20:
2017-12-03 03:38:48,897:train.py:200 -         run_log_save():    avg word perp:   55.02
2017-12-03 03:38:48,897:train.py:201 -         run_log_save():    acc trg words/s: 2186
2017-12-03 03:38:48,897:train.py:202 -         run_log_save():    acc sec/batch:   0.56
2017-12-03 03:39:54,891:train.py:199 -         run_log_save(): Batch 112, epoch 14/20:
2017-12-03 03:39:54,891:train.py:200 -         run_log_save():    avg word perp:   8.66
2017-12-03 03:39:54,891:train.py:201 -         run_log_save():    acc trg words/s: 2424
2017-12-03 03:39:54,891:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 03:41:00,687:train.py:199 -         run_log_save(): Batch 212, epoch 14/20:
2017-12-03 03:41:00,688:train.py:200 -         run_log_save():    avg word perp:   8.27
2017-12-03 03:41:00,688:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 03:41:00,688:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 03:42:08,183:train.py:199 -         run_log_save(): Batch 312, epoch 14/20:
2017-12-03 03:42:08,183:train.py:200 -         run_log_save():    avg word perp:   8.13
2017-12-03 03:42:08,183:train.py:201 -         run_log_save():    acc trg words/s: 2429
2017-12-03 03:42:08,183:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:43:14,160:train.py:151 -         sample_input(): Sample input data:
2017-12-03 03:43:14,160:train.py:152 -         sample_input(): Src: . sorgen vor@@ sie werden so , Eigentümer der Gesellschaft der Befürworter die argumentieren , sorgen vorzu@@ Zukunft ihre für , Anreize Menschen den man gibt _PAD _PAD
2017-12-03 03:43:14,161:train.py:153 -         sample_input(): Src len: 26
2017-12-03 03:43:14,161:train.py:154 -         sample_input(): Trg: _BOS give people the incentives to plan for their future , ownership @-@ society advocates argue , and they will . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 03:43:14,161:train.py:155 -         sample_input(): Tar: give people the incentives to plan for their future , ownership @-@ society advocates argue , and they will . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 03:43:14,161:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 03:43:14,161:train.py:199 -         run_log_save(): Batch 412, epoch 14/20:
2017-12-03 03:43:14,161:train.py:200 -         run_log_save():    avg word perp:   8.19
2017-12-03 03:43:14,161:train.py:201 -         run_log_save():    acc trg words/s: 2435
2017-12-03 03:43:14,161:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:44:21,098:train.py:199 -         run_log_save(): Batch 512, epoch 14/20:
2017-12-03 03:44:21,098:train.py:200 -         run_log_save():    avg word perp:   8.29
2017-12-03 03:44:21,098:train.py:201 -         run_log_save():    acc trg words/s: 2433
2017-12-03 03:44:21,098:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:45:26,734:train.py:199 -         run_log_save(): Batch 612, epoch 14/20:
2017-12-03 03:45:26,734:train.py:200 -         run_log_save():    avg word perp:   8.29
2017-12-03 03:45:26,734:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 03:45:26,734:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:46:32,514:train.py:199 -         run_log_save(): Batch 712, epoch 14/20:
2017-12-03 03:46:32,514:train.py:200 -         run_log_save():    avg word perp:   8.15
2017-12-03 03:46:32,514:train.py:201 -         run_log_save():    acc trg words/s: 2440
2017-12-03 03:46:32,514:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:47:39,197:train.py:199 -         run_log_save(): Batch 812, epoch 14/20:
2017-12-03 03:47:39,197:train.py:200 -         run_log_save():    avg word perp:   8.25
2017-12-03 03:47:39,197:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 03:47:39,197:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:48:46,725:train.py:199 -         run_log_save(): Batch 912, epoch 14/20:
2017-12-03 03:48:46,726:train.py:200 -         run_log_save():    avg word perp:   8.36
2017-12-03 03:48:46,726:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 03:48:46,726:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:49:52,755:train.py:199 -         run_log_save(): Batch 1012, epoch 14/20:
2017-12-03 03:49:52,755:train.py:200 -         run_log_save():    avg word perp:   8.34
2017-12-03 03:49:52,755:train.py:201 -         run_log_save():    acc trg words/s: 2435
2017-12-03 03:49:52,755:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:50:58,995:train.py:199 -         run_log_save(): Batch 1112, epoch 14/20:
2017-12-03 03:50:58,995:train.py:200 -         run_log_save():    avg word perp:   8.22
2017-12-03 03:50:58,995:train.py:201 -         run_log_save():    acc trg words/s: 2436
2017-12-03 03:50:58,995:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:52:05,306:train.py:199 -         run_log_save(): Batch 1212, epoch 14/20:
2017-12-03 03:52:05,306:train.py:200 -         run_log_save():    avg word perp:   8.15
2017-12-03 03:52:05,306:train.py:201 -         run_log_save():    acc trg words/s: 2437
2017-12-03 03:52:05,306:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:53:11,504:train.py:199 -         run_log_save(): Batch 1312, epoch 14/20:
2017-12-03 03:53:11,504:train.py:200 -         run_log_save():    avg word perp:   8.34
2017-12-03 03:53:11,504:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 03:53:11,504:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:54:17,583:train.py:151 -         sample_input(): Sample input data:
2017-12-03 03:54:17,583:train.py:152 -         sample_input(): Src: . sein immens werden - legern pf@@ Kranken@@ en mobil@@ zu hin bis Ärzte über Spezialisten @-@ Software von - Länder dieser Arbeitsmärkten den in Lücken die _PAD
2017-12-03 03:54:17,583:train.py:153 -         sample_input(): Src len: 27
2017-12-03 03:54:17,583:train.py:154 -         sample_input(): Trg: _BOS the gaps in these countries &quot; labor markets - from software specialists to physicians to home health aides - will be immense . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 03:54:17,583:train.py:155 -         sample_input(): Tar: the gaps in these countries &quot; labor markets - from software specialists to physicians to home health aides - will be immense . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 03:54:17,583:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 03:54:17,583:train.py:199 -         run_log_save(): Batch 1412, epoch 14/20:
2017-12-03 03:54:17,583:train.py:200 -         run_log_save():    avg word perp:   8.24
2017-12-03 03:54:17,583:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 03:54:17,583:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:55:24,140:train.py:199 -         run_log_save(): Batch 1512, epoch 14/20:
2017-12-03 03:55:24,140:train.py:200 -         run_log_save():    avg word perp:   8.32
2017-12-03 03:55:24,140:train.py:201 -         run_log_save():    acc trg words/s: 2437
2017-12-03 03:55:24,140:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:56:30,336:train.py:199 -         run_log_save(): Batch 1612, epoch 14/20:
2017-12-03 03:56:30,336:train.py:200 -         run_log_save():    avg word perp:   8.45
2017-12-03 03:56:30,336:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 03:56:30,336:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:57:36,507:train.py:199 -         run_log_save(): Batch 1712, epoch 14/20:
2017-12-03 03:57:36,508:train.py:200 -         run_log_save():    avg word perp:   8.36
2017-12-03 03:57:36,508:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 03:57:36,508:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:58:42,400:train.py:199 -         run_log_save(): Batch 1812, epoch 14/20:
2017-12-03 03:58:42,400:train.py:200 -         run_log_save():    avg word perp:   8.32
2017-12-03 03:58:42,400:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 03:58:42,400:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 03:59:49,544:train.py:199 -         run_log_save(): Batch 1912, epoch 14/20:
2017-12-03 03:59:49,544:train.py:200 -         run_log_save():    avg word perp:   8.56
2017-12-03 03:59:49,545:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 03:59:49,545:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 04:00:55,856:train.py:199 -         run_log_save(): Batch 2012, epoch 14/20:
2017-12-03 04:00:55,856:train.py:200 -         run_log_save():    avg word perp:   8.28
2017-12-03 04:00:55,856:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 04:00:55,856:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 04:02:01,899:train.py:199 -         run_log_save(): Batch 2112, epoch 14/20:
2017-12-03 04:02:01,899:train.py:200 -         run_log_save():    avg word perp:   8.44
2017-12-03 04:02:01,899:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 04:02:01,899:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 04:03:08,696:train.py:199 -         run_log_save(): Batch 2212, epoch 14/20:
2017-12-03 04:03:08,697:train.py:200 -         run_log_save():    avg word perp:   8.50
2017-12-03 04:03:08,697:train.py:201 -         run_log_save():    acc trg words/s: 2437
2017-12-03 04:03:08,697:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 04:04:13,686:train.py:199 -         run_log_save(): Batch 2312, epoch 14/20:
2017-12-03 04:04:13,687:train.py:200 -         run_log_save():    avg word perp:   8.26
2017-12-03 04:04:13,687:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 04:04:13,687:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 04:05:19,548:train.py:151 -         sample_input(): Sample input data:
2017-12-03 04:05:19,549:train.py:152 -         sample_input(): Src: . hervorbringen Islam des Formen eigenen ihre Spanien und Niederlande die , Deutschland , Frankreich auch wie , entstehen zu , dabei ist Islam britischer ein _PAD _PAD
2017-12-03 04:05:19,549:train.py:153 -         sample_input(): Src len: 26
2017-12-03 04:05:19,549:train.py:154 -         sample_input(): Trg: _BOS a distinc@@ tively British brand of Islam is beginning to emerge , just as France , Germany , the Netherlands , and Spain are producing their own forms of Islam . _PAD _PAD _PAD _PAD
2017-12-03 04:05:19,549:train.py:155 -         sample_input(): Tar: a distinc@@ tively British brand of Islam is beginning to emerge , just as France , Germany , the Netherlands , and Spain are producing their own forms of Islam . _EOS _PAD _PAD _PAD _PAD
2017-12-03 04:05:19,549:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0
2017-12-03 04:05:19,549:train.py:199 -         run_log_save(): Batch 2412, epoch 14/20:
2017-12-03 04:05:19,549:train.py:200 -         run_log_save():    avg word perp:   8.50
2017-12-03 04:05:19,549:train.py:201 -         run_log_save():    acc trg words/s: 2439
2017-12-03 04:05:19,549:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 04:05:23,063:train.py:207 -         run_log_save(): Save model to ./nmt/saved_models/de2en_bp/de2en_bp.cpkt, takes 0:00:03.514058
2017-12-03 04:06:28,316:train.py:199 -         run_log_save(): Batch 2512, epoch 14/20:
2017-12-03 04:06:28,316:train.py:200 -         run_log_save():    avg word perp:   8.27
2017-12-03 04:06:28,316:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 04:06:28,316:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 04:06:49,919:train.py:199 -         run_log_save(): Batch 2612, epoch 14/20:
2017-12-03 04:06:49,920:train.py:200 -         run_log_save():    avg word perp:   22.32
2017-12-03 04:06:49,920:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 04:06:49,920:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-03 04:06:56,867:train.py:199 -         run_log_save(): Batch 2712, epoch 14/20:
2017-12-03 04:06:56,867:train.py:200 -         run_log_save():    avg word perp:   325.60
2017-12-03 04:06:56,867:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 04:06:56,867:train.py:202 -         run_log_save():    acc sec/batch:   0.62
2017-12-03 04:07:03,783:train.py:199 -         run_log_save(): Batch 2812, epoch 14/20:
2017-12-03 04:07:03,783:train.py:200 -         run_log_save():    avg word perp:   312.79
2017-12-03 04:07:03,783:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 04:07:03,783:train.py:202 -         run_log_save():    acc sec/batch:   0.60
2017-12-03 04:07:10,601:train.py:199 -         run_log_save(): Batch 2912, epoch 14/20:
2017-12-03 04:07:10,602:train.py:200 -         run_log_save():    avg word perp:   287.61
2017-12-03 04:07:10,602:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 04:07:10,602:train.py:202 -         run_log_save():    acc sec/batch:   0.58
2017-12-03 04:07:17,391:train.py:199 -         run_log_save(): Batch 3012, epoch 14/20:
2017-12-03 04:07:17,392:train.py:200 -         run_log_save():    avg word perp:   299.03
2017-12-03 04:07:17,392:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 04:07:17,392:train.py:202 -         run_log_save():    acc sec/batch:   0.57
2017-12-03 04:07:24,166:train.py:199 -         run_log_save(): Batch 3112, epoch 14/20:
2017-12-03 04:07:24,166:train.py:200 -         run_log_save():    avg word perp:   295.00
2017-12-03 04:07:24,166:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 04:07:24,166:train.py:202 -         run_log_save():    acc sec/batch:   0.55
2017-12-03 04:07:31,000:train.py:199 -         run_log_save(): Batch 3212, epoch 14/20:
2017-12-03 04:07:31,000:train.py:200 -         run_log_save():    avg word perp:   291.76
2017-12-03 04:07:31,000:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 04:07:31,000:train.py:202 -         run_log_save():    acc sec/batch:   0.53
2017-12-03 04:07:35,446:train.py:119 -         report_epoch(): Finish epoch 14
2017-12-03 04:07:35,446:train.py:120 -         report_epoch():     It takes 0:28:41.329773
2017-12-03 04:07:35,446:train.py:121 -         report_epoch():     Avergage # words/second    2441.3183726
2017-12-03 04:07:35,446:train.py:122 -         report_epoch():     Average seconds/batch    0.525436438629
2017-12-03 04:07:35,447:train.py:133 -         report_epoch():     train perplexity: 9.26055687148
2017-12-03 04:07:35,978:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.530396938324 seconds
2017-12-03 04:07:58,859:train.py:199 -         run_log_save(): Batch 36, epoch 15/20:
2017-12-03 04:07:58,859:train.py:200 -         run_log_save():    avg word perp:   16.22
2017-12-03 04:07:58,859:train.py:201 -         run_log_save():    acc trg words/s: 2394
2017-12-03 04:07:58,859:train.py:202 -         run_log_save():    acc sec/batch:   0.63
2017-12-03 04:09:04,434:train.py:151 -         sample_input(): Sample input data:
2017-12-03 04:09:04,435:train.py:152 -         sample_input(): Src: . Patienten einzelnen dem , liegt selbst einem bei , Gesundheit eigene die für Verantwortung die dass , Gefühl das auch tendenziell sie erzeugen doch , retten Leben Anwendung richtiger bei können ests Gent@@ _PAD _PAD
2017-12-03 04:09:04,435:train.py:153 -         sample_input(): Src len: 34
2017-12-03 04:09:04,435:train.py:154 -         sample_input(): Trg: _BOS genetic tests , if properly administered , can save lives , but they also tend to create a feeling that the responsibility for your health rests with you , the individual patient . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 04:09:04,435:train.py:155 -         sample_input(): Tar: genetic tests , if properly administered , can save lives , but they also tend to create a feeling that the responsibility for your health rests with you , the individual patient . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 04:09:04,435:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 04:09:04,435:train.py:199 -         run_log_save(): Batch 136, epoch 15/20:
2017-12-03 04:09:04,435:train.py:200 -         run_log_save():    avg word perp:   8.24
2017-12-03 04:09:04,435:train.py:201 -         run_log_save():    acc trg words/s: 2451
2017-12-03 04:09:04,435:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:10:09,885:train.py:199 -         run_log_save(): Batch 236, epoch 15/20:
2017-12-03 04:10:09,886:train.py:200 -         run_log_save():    avg word perp:   7.88
2017-12-03 04:10:09,886:train.py:201 -         run_log_save():    acc trg words/s: 2467
2017-12-03 04:10:09,886:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:11:15,799:train.py:199 -         run_log_save(): Batch 336, epoch 15/20:
2017-12-03 04:11:15,799:train.py:200 -         run_log_save():    avg word perp:   7.97
2017-12-03 04:11:15,799:train.py:201 -         run_log_save():    acc trg words/s: 2466
2017-12-03 04:11:15,799:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:12:21,891:train.py:199 -         run_log_save(): Batch 436, epoch 15/20:
2017-12-03 04:12:21,891:train.py:200 -         run_log_save():    avg word perp:   7.77
2017-12-03 04:12:21,891:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 04:12:21,891:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:13:27,373:train.py:199 -         run_log_save(): Batch 536, epoch 15/20:
2017-12-03 04:13:27,373:train.py:200 -         run_log_save():    avg word perp:   7.83
2017-12-03 04:13:27,373:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 04:13:27,374:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:14:32,704:train.py:199 -         run_log_save(): Batch 636, epoch 15/20:
2017-12-03 04:14:32,704:train.py:200 -         run_log_save():    avg word perp:   7.88
2017-12-03 04:14:32,704:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-03 04:14:32,704:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:15:38,632:train.py:199 -         run_log_save(): Batch 736, epoch 15/20:
2017-12-03 04:15:38,632:train.py:200 -         run_log_save():    avg word perp:   7.96
2017-12-03 04:15:38,632:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 04:15:38,632:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:16:44,882:train.py:199 -         run_log_save(): Batch 836, epoch 15/20:
2017-12-03 04:16:44,882:train.py:200 -         run_log_save():    avg word perp:   7.90
2017-12-03 04:16:44,882:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-03 04:16:44,883:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:17:50,534:train.py:199 -         run_log_save(): Batch 936, epoch 15/20:
2017-12-03 04:17:50,534:train.py:200 -         run_log_save():    avg word perp:   7.94
2017-12-03 04:17:50,534:train.py:201 -         run_log_save():    acc trg words/s: 2458
2017-12-03 04:17:50,534:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:18:56,449:train.py:199 -         run_log_save(): Batch 1036, epoch 15/20:
2017-12-03 04:18:56,449:train.py:200 -         run_log_save():    avg word perp:   8.03
2017-12-03 04:18:56,450:train.py:201 -         run_log_save():    acc trg words/s: 2459
2017-12-03 04:18:56,450:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:20:02,806:train.py:151 -         sample_input(): Sample input data:
2017-12-03 04:20:02,806:train.py:152 -         sample_input(): Src: . ging  anzuwenden Gewalt , Drohung die oder  Gewalt von Anwendung die um es als , unfähig und los ang@@ bel@@ vollkommen als Brüssel sich erwies Kosovo des und ens Bosni@@ Falle im _PAD
2017-12-03 04:20:02,807:train.py:153 -         sample_input(): Src len: 35
2017-12-03 04:20:02,807:train.py:154 -         sample_input(): Trg: _BOS in the case of Bosnia and Kosovo , Brussels proved itself to be totally irrelevant and impotent when the use of force - or the threat of the use of force - was concerned . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 04:20:02,807:train.py:155 -         sample_input(): Tar: in the case of Bosnia and Kosovo , Brussels proved itself to be totally irrelevant and impotent when the use of force - or the threat of the use of force - was concerned . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 04:20:02,807:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 04:20:02,807:train.py:199 -         run_log_save(): Batch 1136, epoch 15/20:
2017-12-03 04:20:02,807:train.py:200 -         run_log_save():    avg word perp:   7.96
2017-12-03 04:20:02,807:train.py:201 -         run_log_save():    acc trg words/s: 2457
2017-12-03 04:20:02,807:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:21:07,388:train.py:199 -         run_log_save(): Batch 1236, epoch 15/20:
2017-12-03 04:21:07,388:train.py:200 -         run_log_save():    avg word perp:   7.82
2017-12-03 04:21:07,388:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 04:21:07,388:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:22:12,917:train.py:199 -         run_log_save(): Batch 1336, epoch 15/20:
2017-12-03 04:22:12,917:train.py:200 -         run_log_save():    avg word perp:   7.98
2017-12-03 04:22:12,917:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 04:22:12,917:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:23:17,929:train.py:199 -         run_log_save(): Batch 1436, epoch 15/20:
2017-12-03 04:23:17,930:train.py:200 -         run_log_save():    avg word perp:   7.96
2017-12-03 04:23:17,930:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 04:23:17,930:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:24:24,482:train.py:199 -         run_log_save(): Batch 1536, epoch 15/20:
2017-12-03 04:24:24,482:train.py:200 -         run_log_save():    avg word perp:   7.95
2017-12-03 04:24:24,482:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 04:24:24,482:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:25:30,641:train.py:199 -         run_log_save(): Batch 1636, epoch 15/20:
2017-12-03 04:25:30,641:train.py:200 -         run_log_save():    avg word perp:   8.06
2017-12-03 04:25:30,641:train.py:201 -         run_log_save():    acc trg words/s: 2460
2017-12-03 04:25:30,641:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:26:35,536:train.py:199 -         run_log_save(): Batch 1736, epoch 15/20:
2017-12-03 04:26:35,536:train.py:200 -         run_log_save():    avg word perp:   8.10
2017-12-03 04:26:35,536:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 04:26:35,536:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:27:40,529:train.py:199 -         run_log_save(): Batch 1836, epoch 15/20:
2017-12-03 04:27:40,529:train.py:200 -         run_log_save():    avg word perp:   8.09
2017-12-03 04:27:40,529:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 04:27:40,529:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:28:45,013:train.py:199 -         run_log_save(): Batch 1936, epoch 15/20:
2017-12-03 04:28:45,014:train.py:200 -         run_log_save():    avg word perp:   8.17
2017-12-03 04:28:45,014:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-03 04:28:45,014:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:29:50,228:train.py:199 -         run_log_save(): Batch 2036, epoch 15/20:
2017-12-03 04:29:50,229:train.py:200 -         run_log_save():    avg word perp:   7.97
2017-12-03 04:29:50,229:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-03 04:29:50,229:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:30:56,387:train.py:151 -         sample_input(): Sample input data:
2017-12-03 04:30:56,387:train.py:152 -         sample_input(): Src: . hat otenen Verb@@ des Anschein den nehmbar wahr@@ deutlich und ist art Mach@@ ber der@@ von selbst Produkt das dass , bestehen zu darin Pornographie der Reiz be der@@ der scheint teilweise _PAD _PAD _PAD
2017-12-03 04:30:56,387:train.py:153 -         sample_input(): Src len: 33
2017-12-03 04:30:56,387:train.py:154 -         sample_input(): Trg: _BOS part of the raw appeal of pornography , it seems , is that the product itself be raw , and conspicuously illicit . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 04:30:56,387:train.py:155 -         sample_input(): Tar: part of the raw appeal of pornography , it seems , is that the product itself be raw , and conspicuously illicit . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 04:30:56,387:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 04:30:56,387:train.py:199 -         run_log_save(): Batch 2136, epoch 15/20:
2017-12-03 04:30:56,387:train.py:200 -         run_log_save():    avg word perp:   8.15
2017-12-03 04:30:56,387:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-03 04:30:56,387:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:32:02,795:train.py:199 -         run_log_save(): Batch 2236, epoch 15/20:
2017-12-03 04:32:02,796:train.py:200 -         run_log_save():    avg word perp:   8.17
2017-12-03 04:32:02,796:train.py:201 -         run_log_save():    acc trg words/s: 2464
2017-12-03 04:32:02,796:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:33:07,434:train.py:199 -         run_log_save(): Batch 2336, epoch 15/20:
2017-12-03 04:33:07,435:train.py:200 -         run_log_save():    avg word perp:   8.05
2017-12-03 04:33:07,435:train.py:201 -         run_log_save():    acc trg words/s: 2465
2017-12-03 04:33:07,435:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:34:14,865:train.py:199 -         run_log_save(): Batch 2436, epoch 15/20:
2017-12-03 04:34:14,865:train.py:200 -         run_log_save():    avg word perp:   8.10
2017-12-03 04:34:14,865:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 04:34:14,865:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:35:20,333:train.py:199 -         run_log_save(): Batch 2536, epoch 15/20:
2017-12-03 04:35:20,333:train.py:200 -         run_log_save():    avg word perp:   8.25
2017-12-03 04:35:20,333:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 04:35:20,333:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 04:35:27,266:train.py:199 -         run_log_save(): Batch 2636, epoch 15/20:
2017-12-03 04:35:27,266:train.py:200 -         run_log_save():    avg word perp:   429.62
2017-12-03 04:35:27,266:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 04:35:27,266:train.py:202 -         run_log_save():    acc sec/batch:   0.63
2017-12-03 04:35:34,122:train.py:199 -         run_log_save(): Batch 2736, epoch 15/20:
2017-12-03 04:35:34,123:train.py:200 -         run_log_save():    avg word perp:   313.40
2017-12-03 04:35:34,123:train.py:201 -         run_log_save():    acc trg words/s: 2463
2017-12-03 04:35:34,123:train.py:202 -         run_log_save():    acc sec/batch:   0.61
2017-12-03 04:35:40,974:train.py:199 -         run_log_save(): Batch 2836, epoch 15/20:
2017-12-03 04:35:40,975:train.py:200 -         run_log_save():    avg word perp:   308.20
2017-12-03 04:35:40,975:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 04:35:40,975:train.py:202 -         run_log_save():    acc sec/batch:   0.59
2017-12-03 04:35:47,822:train.py:199 -         run_log_save(): Batch 2936, epoch 15/20:
2017-12-03 04:35:47,823:train.py:200 -         run_log_save():    avg word perp:   302.90
2017-12-03 04:35:47,823:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 04:35:47,823:train.py:202 -         run_log_save():    acc sec/batch:   0.57
2017-12-03 04:35:54,723:train.py:199 -         run_log_save(): Batch 3036, epoch 15/20:
2017-12-03 04:35:54,723:train.py:200 -         run_log_save():    avg word perp:   296.54
2017-12-03 04:35:54,723:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 04:35:54,723:train.py:202 -         run_log_save():    acc sec/batch:   0.56
2017-12-03 04:36:01,641:train.py:151 -         sample_input(): Sample input data:
2017-12-03 04:36:01,641:train.py:152 -         sample_input(): Src: _UNK
2017-12-03 04:36:01,641:train.py:153 -         sample_input(): Src len: 1
2017-12-03 04:36:01,641:train.py:154 -         sample_input(): Trg: _BOS poisonflower _PAD
2017-12-03 04:36:01,641:train.py:155 -         sample_input(): Tar: poisonflower _EOS _PAD
2017-12-03 04:36:01,641:train.py:156 -         sample_input(): W: 1.0 1.0 0.0
2017-12-03 04:36:01,641:train.py:199 -         run_log_save(): Batch 3136, epoch 15/20:
2017-12-03 04:36:01,641:train.py:200 -         run_log_save():    avg word perp:   303.95
2017-12-03 04:36:01,642:train.py:201 -         run_log_save():    acc trg words/s: 2462
2017-12-03 04:36:01,642:train.py:202 -         run_log_save():    acc sec/batch:   0.54
2017-12-03 04:36:01,642:validator.py:224 -    validate_and_save(): Start validation
2017-12-03 04:37:26,957:validator.py:143 -             evaluate():   Translating line 100, average 0.853152439594 seconds/sent
2017-12-03 04:38:40,980:validator.py:143 -             evaluate():   Translating line 200, average 0.79669075489 seconds/sent
2017-12-03 04:39:50,426:validator.py:143 -             evaluate():   Translating line 300, average 0.762613836924 seconds/sent
2017-12-03 04:40:48,426:validator.py:143 -             evaluate():   Translating line 400, average 0.716960157156 seconds/sent
2017-12-03 04:42:05,307:validator.py:143 -             evaluate():   Translating line 500, average 0.727330671787 seconds/sent
2017-12-03 04:43:16,794:validator.py:143 -             evaluate():   Translating line 600, average 0.725253478289 seconds/sent
2017-12-03 04:44:34,306:validator.py:143 -             evaluate():   Translating line 700, average 0.732377049923 seconds/sent
2017-12-03 04:46:08,490:validator.py:143 -             evaluate():   Translating line 800, average 0.758560156226 seconds/sent
2017-12-03 04:47:19,321:validator.py:143 -             evaluate():   Translating line 900, average 0.752977040079 seconds/sent
2017-12-03 04:48:37,423:validator.py:143 -             evaluate():   Translating line 1000, average 0.755780787945 seconds/sent
2017-12-03 04:49:44,332:validator.py:143 -             evaluate():   Translating line 1100, average 0.747900300026 seconds/sent
2017-12-03 04:50:53,126:validator.py:143 -             evaluate():   Translating line 1200, average 0.742903025746 seconds/sent
2017-12-03 04:52:16,997:validator.py:143 -             evaluate():   Translating line 1300, average 0.750273267673 seconds/sent
2017-12-03 04:53:28,269:validator.py:143 -             evaluate():   Translating line 1400, average 0.747590502841 seconds/sent
2017-12-03 04:54:39,481:validator.py:143 -             evaluate():   Translating line 1500, average 0.745226076603 seconds/sent
2017-12-03 04:55:52,824:validator.py:143 -             evaluate():   Translating line 1600, average 0.74448889941 seconds/sent
2017-12-03 04:57:01,775:validator.py:143 -             evaluate():   Translating line 1700, average 0.741254945222 seconds/sent
2017-12-03 04:58:09,912:validator.py:143 -             evaluate():   Translating line 1800, average 0.737927671141 seconds/sent
2017-12-03 04:59:21,702:validator.py:143 -             evaluate():   Translating line 1900, average 0.736873492065 seconds/sent
2017-12-03 04:59:57,779:validator.py:152 -             evaluate(): Done translating.
2017-12-03 04:59:57,780:validator.py:153 -             evaluate(): dev perplexity: 818.136
2017-12-03 04:59:58,060:validator.py:159 -             evaluate(): BLEU = 0.02, 5.9/1.9/0.5/0.1 (BP=0.023, ratio=0.209, hyp_len=9481, ref_len=45274)

2017-12-03 04:59:58,060:validator.py:160 -             evaluate(): Validation took: 23.940305233 minutes
2017-12-03 05:00:04,991:train.py:199 -         run_log_save(): Batch 3236, epoch 15/20:
2017-12-03 05:00:04,992:train.py:200 -         run_log_save():    avg word perp:   295.17
2017-12-03 05:00:04,992:train.py:201 -         run_log_save():    acc trg words/s: 2461
2017-12-03 05:00:04,992:train.py:202 -         run_log_save():    acc sec/batch:   0.53
2017-12-03 05:00:07,748:train.py:119 -         report_epoch(): Finish epoch 15
2017-12-03 05:00:07,748:train.py:120 -         report_epoch():     It takes 0:28:26.970985
2017-12-03 05:00:07,749:train.py:121 -         report_epoch():     Avergage # words/second    2461.84793864
2017-12-03 05:00:07,749:train.py:122 -         report_epoch():     Average seconds/batch    0.521053414132
2017-12-03 05:00:07,749:train.py:133 -         report_epoch():     train perplexity: 8.92099559149
2017-12-03 05:00:08,284:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.534739971161 seconds
2017-12-03 05:00:47,801:train.py:199 -         run_log_save(): Batch 60, epoch 16/20:
2017-12-03 05:00:47,801:train.py:200 -         run_log_save():    avg word perp:   10.90
2017-12-03 05:00:47,801:train.py:201 -         run_log_save():    acc trg words/s: 2427
2017-12-03 05:00:47,801:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:01:54,786:train.py:199 -         run_log_save(): Batch 160, epoch 16/20:
2017-12-03 05:01:54,786:train.py:200 -         run_log_save():    avg word perp:   7.79
2017-12-03 05:01:54,786:train.py:201 -         run_log_save():    acc trg words/s: 2427
2017-12-03 05:01:54,786:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:03:01,677:train.py:199 -         run_log_save(): Batch 260, epoch 16/20:
2017-12-03 05:03:01,678:train.py:200 -         run_log_save():    avg word perp:   7.61
2017-12-03 05:03:01,678:train.py:201 -         run_log_save():    acc trg words/s: 2423
2017-12-03 05:03:01,678:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:04:07,854:train.py:199 -         run_log_save(): Batch 360, epoch 16/20:
2017-12-03 05:04:07,855:train.py:200 -         run_log_save():    avg word perp:   7.54
2017-12-03 05:04:07,855:train.py:201 -         run_log_save():    acc trg words/s: 2429
2017-12-03 05:04:07,855:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:05:14,164:train.py:199 -         run_log_save(): Batch 460, epoch 16/20:
2017-12-03 05:05:14,164:train.py:200 -         run_log_save():    avg word perp:   7.56
2017-12-03 05:05:14,164:train.py:201 -         run_log_save():    acc trg words/s: 2433
2017-12-03 05:05:14,164:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:06:18,663:train.py:199 -         run_log_save(): Batch 560, epoch 16/20:
2017-12-03 05:06:18,663:train.py:200 -         run_log_save():    avg word perp:   7.63
2017-12-03 05:06:18,663:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 05:06:18,663:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:07:25,586:train.py:199 -         run_log_save(): Batch 660, epoch 16/20:
2017-12-03 05:07:25,587:train.py:200 -         run_log_save():    avg word perp:   7.68
2017-12-03 05:07:25,587:train.py:201 -         run_log_save():    acc trg words/s: 2439
2017-12-03 05:07:25,587:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:08:33,156:train.py:199 -         run_log_save(): Batch 760, epoch 16/20:
2017-12-03 05:08:33,156:train.py:200 -         run_log_save():    avg word perp:   7.68
2017-12-03 05:08:33,156:train.py:201 -         run_log_save():    acc trg words/s: 2436
2017-12-03 05:08:33,156:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:09:39,188:train.py:151 -         sample_input(): Sample input data:
2017-12-03 05:09:39,189:train.py:152 -         sample_input(): Src: . müssen treffen e atom@@ um@@ thi@@ Li@@ liegenden dahinter die die , ronen ut@@ Ne@@ die für lässig durch@@ ausreichend auch sondern , sein ös por@@ und dicht gleichzeitig nur nicht dabei müsste deckung Ab@@ der Wand erste die aber , funktionieren könnte dies _PAD _PAD _PAD _PAD _PAD
2017-12-03 05:09:39,189:train.py:153 -         sample_input(): Src len: 45
2017-12-03 05:09:39,189:train.py:154 -         sample_input(): Trg: _BOS this might work , but the first wall of the blanket will need to be not only leak @-@ proof and porous , but also sufficiently perme@@ able to neutr@@ ons , which have to hit the li@@ thi@@ um atoms beyond it . _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 05:09:39,189:train.py:155 -         sample_input(): Tar: this might work , but the first wall of the blanket will need to be not only leak @-@ proof and porous , but also sufficiently perme@@ able to neutr@@ ons , which have to hit the li@@ thi@@ um atoms beyond it . _EOS _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 05:09:39,189:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 05:09:39,189:train.py:199 -         run_log_save(): Batch 860, epoch 16/20:
2017-12-03 05:09:39,189:train.py:200 -         run_log_save():    avg word perp:   7.70
2017-12-03 05:09:39,189:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 05:09:39,189:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:09:42,557:train.py:207 -         run_log_save(): Save model to ./nmt/saved_models/de2en_bp/de2en_bp.cpkt, takes 0:00:03.368152
2017-12-03 05:10:49,673:train.py:199 -         run_log_save(): Batch 960, epoch 16/20:
2017-12-03 05:10:49,674:train.py:200 -         run_log_save():    avg word perp:   7.63
2017-12-03 05:10:49,674:train.py:201 -         run_log_save():    acc trg words/s: 2435
2017-12-03 05:10:49,674:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:11:55,177:train.py:199 -         run_log_save(): Batch 1060, epoch 16/20:
2017-12-03 05:11:55,177:train.py:200 -         run_log_save():    avg word perp:   7.72
2017-12-03 05:11:55,177:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 05:11:55,177:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:13:00,160:train.py:199 -         run_log_save(): Batch 1160, epoch 16/20:
2017-12-03 05:13:00,161:train.py:200 -         run_log_save():    avg word perp:   7.57
2017-12-03 05:13:00,161:train.py:201 -         run_log_save():    acc trg words/s: 2443
2017-12-03 05:13:00,161:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:14:05,755:train.py:199 -         run_log_save(): Batch 1260, epoch 16/20:
2017-12-03 05:14:05,755:train.py:200 -         run_log_save():    avg word perp:   7.64
2017-12-03 05:14:05,755:train.py:201 -         run_log_save():    acc trg words/s: 2445
2017-12-03 05:14:05,755:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:15:11,692:train.py:199 -         run_log_save(): Batch 1360, epoch 16/20:
2017-12-03 05:15:11,692:train.py:200 -         run_log_save():    avg word perp:   7.72
2017-12-03 05:15:11,692:train.py:201 -         run_log_save():    acc trg words/s: 2445
2017-12-03 05:15:11,693:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:16:19,330:train.py:199 -         run_log_save(): Batch 1460, epoch 16/20:
2017-12-03 05:16:19,330:train.py:200 -         run_log_save():    avg word perp:   7.86
2017-12-03 05:16:19,330:train.py:201 -         run_log_save():    acc trg words/s: 2440
2017-12-03 05:16:19,330:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:17:26,474:train.py:199 -         run_log_save(): Batch 1560, epoch 16/20:
2017-12-03 05:17:26,474:train.py:200 -         run_log_save():    avg word perp:   7.90
2017-12-03 05:17:26,474:train.py:201 -         run_log_save():    acc trg words/s: 2439
2017-12-03 05:17:26,474:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:18:32,282:train.py:199 -         run_log_save(): Batch 1660, epoch 16/20:
2017-12-03 05:18:32,283:train.py:200 -         run_log_save():    avg word perp:   7.80
2017-12-03 05:18:32,283:train.py:201 -         run_log_save():    acc trg words/s: 2439
2017-12-03 05:18:32,283:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:19:38,482:train.py:199 -         run_log_save(): Batch 1760, epoch 16/20:
2017-12-03 05:19:38,482:train.py:200 -         run_log_save():    avg word perp:   7.74
2017-12-03 05:19:38,483:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 05:19:38,483:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:20:43,964:train.py:151 -         sample_input(): Sample input data:
2017-12-03 05:20:43,964:train.py:152 -         sample_input(): Src: . lang Zeit eine zumindest , akzeptieren das werden esen al@@ Nep@@ viele und , retten zu Demokratie die um , müsse aufgeben vorübergehend Demokratie die Volk esische pal@@ ne@@ das dass , a endr@@ yan@@ G@@ König sagte Februar 1. am Rede seiner in _PAD _PAD _PAD _PAD _PAD
2017-12-03 05:20:43,964:train.py:153 -         sample_input(): Src len: 45
2017-12-03 05:20:43,964:train.py:154 -         sample_input(): Trg: _BOS in his speech on February 1 , King G@@ yan@@ endr@@ a said the Nep@@ ali people would have to temporarily give up democracy in order to save democracy , and many Nep@@ al@@ ese will go along with that , at least for a while . _PAD _PAD _PAD
2017-12-03 05:20:43,964:train.py:155 -         sample_input(): Tar: in his speech on February 1 , King G@@ yan@@ endr@@ a said the Nep@@ ali people would have to temporarily give up democracy in order to save democracy , and many Nep@@ al@@ ese will go along with that , at least for a while . _EOS _PAD _PAD _PAD
2017-12-03 05:20:43,964:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0
2017-12-03 05:20:43,964:train.py:199 -         run_log_save(): Batch 1860, epoch 16/20:
2017-12-03 05:20:43,964:train.py:200 -         run_log_save():    avg word perp:   7.92
2017-12-03 05:20:43,964:train.py:201 -         run_log_save():    acc trg words/s: 2439
2017-12-03 05:20:43,964:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:21:50,828:train.py:199 -         run_log_save(): Batch 1960, epoch 16/20:
2017-12-03 05:21:50,828:train.py:200 -         run_log_save():    avg word perp:   7.77
2017-12-03 05:21:50,828:train.py:201 -         run_log_save():    acc trg words/s: 2439
2017-12-03 05:21:50,828:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:22:56,384:train.py:199 -         run_log_save(): Batch 2060, epoch 16/20:
2017-12-03 05:22:56,384:train.py:200 -         run_log_save():    avg word perp:   7.75
2017-12-03 05:22:56,384:train.py:201 -         run_log_save():    acc trg words/s: 2440
2017-12-03 05:22:56,384:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:24:02,199:train.py:199 -         run_log_save(): Batch 2160, epoch 16/20:
2017-12-03 05:24:02,199:train.py:200 -         run_log_save():    avg word perp:   7.77
2017-12-03 05:24:02,200:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 05:24:02,200:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:25:08,378:train.py:199 -         run_log_save(): Batch 2260, epoch 16/20:
2017-12-03 05:25:08,378:train.py:200 -         run_log_save():    avg word perp:   7.96
2017-12-03 05:25:08,378:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 05:25:08,378:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:26:14,330:train.py:199 -         run_log_save(): Batch 2360, epoch 16/20:
2017-12-03 05:26:14,330:train.py:200 -         run_log_save():    avg word perp:   7.80
2017-12-03 05:26:14,330:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 05:26:14,330:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:27:20,271:train.py:199 -         run_log_save(): Batch 2460, epoch 16/20:
2017-12-03 05:27:20,271:train.py:200 -         run_log_save():    avg word perp:   7.93
2017-12-03 05:27:20,271:train.py:201 -         run_log_save():    acc trg words/s: 2443
2017-12-03 05:27:20,271:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:28:11,173:train.py:199 -         run_log_save(): Batch 2560, epoch 16/20:
2017-12-03 05:28:11,174:train.py:200 -         run_log_save():    avg word perp:   8.97
2017-12-03 05:28:11,174:train.py:201 -         run_log_save():    acc trg words/s: 2443
2017-12-03 05:28:11,174:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 05:28:18,029:train.py:199 -         run_log_save(): Batch 2660, epoch 16/20:
2017-12-03 05:28:18,029:train.py:200 -         run_log_save():    avg word perp:   357.88
2017-12-03 05:28:18,029:train.py:201 -         run_log_save():    acc trg words/s: 2443
2017-12-03 05:28:18,029:train.py:202 -         run_log_save():    acc sec/batch:   0.63
2017-12-03 05:28:24,920:train.py:199 -         run_log_save(): Batch 2760, epoch 16/20:
2017-12-03 05:28:24,920:train.py:200 -         run_log_save():    avg word perp:   306.81
2017-12-03 05:28:24,921:train.py:201 -         run_log_save():    acc trg words/s: 2443
2017-12-03 05:28:24,921:train.py:202 -         run_log_save():    acc sec/batch:   0.61
2017-12-03 05:28:31,795:train.py:151 -         sample_input(): Sample input data:
2017-12-03 05:28:31,795:train.py:152 -         sample_input(): Src: Flugzeugabfertigung
2017-12-03 05:28:31,795:train.py:153 -         sample_input(): Src len: 1
2017-12-03 05:28:31,795:train.py:154 -         sample_input(): Trg: _BOS ramp services
2017-12-03 05:28:31,795:train.py:155 -         sample_input(): Tar: ramp services _EOS
2017-12-03 05:28:31,795:train.py:156 -         sample_input(): W: 1.0 1.0 1.0
2017-12-03 05:28:31,795:train.py:199 -         run_log_save(): Batch 2860, epoch 16/20:
2017-12-03 05:28:31,795:train.py:200 -         run_log_save():    avg word perp:   296.45
2017-12-03 05:28:31,795:train.py:201 -         run_log_save():    acc trg words/s: 2443
2017-12-03 05:28:31,795:train.py:202 -         run_log_save():    acc sec/batch:   0.59
2017-12-03 05:28:38,671:train.py:199 -         run_log_save(): Batch 2960, epoch 16/20:
2017-12-03 05:28:38,671:train.py:200 -         run_log_save():    avg word perp:   305.42
2017-12-03 05:28:38,671:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 05:28:38,671:train.py:202 -         run_log_save():    acc sec/batch:   0.57
2017-12-03 05:28:45,524:train.py:199 -         run_log_save(): Batch 3060, epoch 16/20:
2017-12-03 05:28:45,525:train.py:200 -         run_log_save():    avg word perp:   295.92
2017-12-03 05:28:45,525:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 05:28:45,525:train.py:202 -         run_log_save():    acc sec/batch:   0.56
2017-12-03 05:28:52,386:train.py:199 -         run_log_save(): Batch 3160, epoch 16/20:
2017-12-03 05:28:52,387:train.py:200 -         run_log_save():    avg word perp:   303.82
2017-12-03 05:28:52,387:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 05:28:52,387:train.py:202 -         run_log_save():    acc sec/batch:   0.54
2017-12-03 05:28:59,309:train.py:199 -         run_log_save(): Batch 3260, epoch 16/20:
2017-12-03 05:28:59,309:train.py:200 -         run_log_save():    avg word perp:   304.00
2017-12-03 05:28:59,309:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 05:28:59,309:train.py:202 -         run_log_save():    acc sec/batch:   0.53
2017-12-03 05:29:00,431:train.py:119 -         report_epoch(): Finish epoch 16
2017-12-03 05:29:00,431:train.py:120 -         report_epoch():     It takes 0:28:40.447290
2017-12-03 05:29:00,432:train.py:121 -         report_epoch():     Avergage # words/second    2442.58049902
2017-12-03 05:29:00,432:train.py:122 -         report_epoch():     Average seconds/batch    0.525167060422
2017-12-03 05:29:00,432:train.py:133 -         report_epoch():     train perplexity: 8.63576675732
2017-12-03 05:29:00,970:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.537684202194 seconds
2017-12-03 05:29:55,355:train.py:199 -         run_log_save(): Batch 84, epoch 17/20:
2017-12-03 05:29:55,355:train.py:200 -         run_log_save():    avg word perp:   8.56
2017-12-03 05:29:55,355:train.py:201 -         run_log_save():    acc trg words/s: 2420
2017-12-03 05:29:55,355:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-03 05:31:02,511:train.py:199 -         run_log_save(): Batch 184, epoch 17/20:
2017-12-03 05:31:02,511:train.py:200 -         run_log_save():    avg word perp:   7.21
2017-12-03 05:31:02,511:train.py:201 -         run_log_save():    acc trg words/s: 2422
2017-12-03 05:31:02,511:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:32:08,844:train.py:199 -         run_log_save(): Batch 284, epoch 17/20:
2017-12-03 05:32:08,844:train.py:200 -         run_log_save():    avg word perp:   7.52
2017-12-03 05:32:08,844:train.py:201 -         run_log_save():    acc trg words/s: 2424
2017-12-03 05:32:08,844:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:33:14,820:train.py:199 -         run_log_save(): Batch 384, epoch 17/20:
2017-12-03 05:33:14,820:train.py:200 -         run_log_save():    avg word perp:   7.41
2017-12-03 05:33:14,820:train.py:201 -         run_log_save():    acc trg words/s: 2430
2017-12-03 05:33:14,820:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:34:20,189:train.py:199 -         run_log_save(): Batch 484, epoch 17/20:
2017-12-03 05:34:20,189:train.py:200 -         run_log_save():    avg word perp:   7.43
2017-12-03 05:34:20,189:train.py:201 -         run_log_save():    acc trg words/s: 2437
2017-12-03 05:34:20,189:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:35:25,848:train.py:151 -         sample_input(): Sample input data:
2017-12-03 05:35:25,848:train.py:152 -         sample_input(): Src: . Würde nach Schrei ähnlichen einen Ukraine der in ich beobachtete Winter letzten im _PAD _PAD
2017-12-03 05:35:25,848:train.py:153 -         sample_input(): Src len: 14
2017-12-03 05:35:25,848:train.py:154 -         sample_input(): Trg: _BOS last winter , I saw a similar cry for dignity in Ukraine . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 05:35:25,848:train.py:155 -         sample_input(): Tar: last winter , I saw a similar cry for dignity in Ukraine . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 05:35:25,848:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 05:35:25,848:train.py:199 -         run_log_save(): Batch 584, epoch 17/20:
2017-12-03 05:35:25,848:train.py:200 -         run_log_save():    avg word perp:   7.35
2017-12-03 05:35:25,848:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 05:35:25,849:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:36:32,046:train.py:199 -         run_log_save(): Batch 684, epoch 17/20:
2017-12-03 05:36:32,046:train.py:200 -         run_log_save():    avg word perp:   7.45
2017-12-03 05:36:32,047:train.py:201 -         run_log_save():    acc trg words/s: 2445
2017-12-03 05:36:32,047:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:37:39,268:train.py:199 -         run_log_save(): Batch 784, epoch 17/20:
2017-12-03 05:37:39,268:train.py:200 -         run_log_save():    avg word perp:   7.48
2017-12-03 05:37:39,268:train.py:201 -         run_log_save():    acc trg words/s: 2440
2017-12-03 05:37:39,268:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:38:45,708:train.py:199 -         run_log_save(): Batch 884, epoch 17/20:
2017-12-03 05:38:45,708:train.py:200 -         run_log_save():    avg word perp:   7.52
2017-12-03 05:38:45,708:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 05:38:45,708:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:39:52,595:train.py:199 -         run_log_save(): Batch 984, epoch 17/20:
2017-12-03 05:39:52,595:train.py:200 -         run_log_save():    avg word perp:   7.42
2017-12-03 05:39:52,595:train.py:201 -         run_log_save():    acc trg words/s: 2440
2017-12-03 05:39:52,595:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:40:59,215:train.py:199 -         run_log_save(): Batch 1084, epoch 17/20:
2017-12-03 05:40:59,215:train.py:200 -         run_log_save():    avg word perp:   7.36
2017-12-03 05:40:59,215:train.py:201 -         run_log_save():    acc trg words/s: 2439
2017-12-03 05:40:59,215:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:42:06,395:train.py:199 -         run_log_save(): Batch 1184, epoch 17/20:
2017-12-03 05:42:06,395:train.py:200 -         run_log_save():    avg word perp:   7.50
2017-12-03 05:42:06,395:train.py:201 -         run_log_save():    acc trg words/s: 2436
2017-12-03 05:42:06,395:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:43:12,490:train.py:199 -         run_log_save(): Batch 1284, epoch 17/20:
2017-12-03 05:43:12,491:train.py:200 -         run_log_save():    avg word perp:   7.52
2017-12-03 05:43:12,491:train.py:201 -         run_log_save():    acc trg words/s: 2436
2017-12-03 05:43:12,491:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:44:17,807:train.py:199 -         run_log_save(): Batch 1384, epoch 17/20:
2017-12-03 05:44:17,807:train.py:200 -         run_log_save():    avg word perp:   7.45
2017-12-03 05:44:17,807:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 05:44:17,807:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:45:24,321:train.py:199 -         run_log_save(): Batch 1484, epoch 17/20:
2017-12-03 05:45:24,321:train.py:200 -         run_log_save():    avg word perp:   7.48
2017-12-03 05:45:24,321:train.py:201 -         run_log_save():    acc trg words/s: 2437
2017-12-03 05:45:24,321:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:46:30,295:train.py:151 -         sample_input(): Sample input data:
2017-12-03 05:46:30,295:train.py:152 -         sample_input(): Src: . Außenstehenden von nicht , werden entschieden Mitgliedern @-@ NATO von sollten Fragen diese _PAD
2017-12-03 05:46:30,295:train.py:153 -         sample_input(): Src len: 14
2017-12-03 05:46:30,295:train.py:154 -         sample_input(): Trg: _BOS these questions should be decided by NATO &apos;s members , not outsiders . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 05:46:30,295:train.py:155 -         sample_input(): Tar: these questions should be decided by NATO &apos;s members , not outsiders . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 05:46:30,295:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 05:46:30,296:train.py:199 -         run_log_save(): Batch 1584, epoch 17/20:
2017-12-03 05:46:30,296:train.py:200 -         run_log_save():    avg word perp:   7.47
2017-12-03 05:46:30,296:train.py:201 -         run_log_save():    acc trg words/s: 2437
2017-12-03 05:46:30,296:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:47:38,146:train.py:199 -         run_log_save(): Batch 1684, epoch 17/20:
2017-12-03 05:47:38,146:train.py:200 -         run_log_save():    avg word perp:   7.70
2017-12-03 05:47:38,146:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 05:47:38,146:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:48:44,849:train.py:199 -         run_log_save(): Batch 1784, epoch 17/20:
2017-12-03 05:48:44,850:train.py:200 -         run_log_save():    avg word perp:   7.44
2017-12-03 05:48:44,850:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 05:48:44,850:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:49:51,392:train.py:199 -         run_log_save(): Batch 1884, epoch 17/20:
2017-12-03 05:49:51,393:train.py:200 -         run_log_save():    avg word perp:   7.49
2017-12-03 05:49:51,393:train.py:201 -         run_log_save():    acc trg words/s: 2433
2017-12-03 05:49:51,393:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:50:56,908:train.py:199 -         run_log_save(): Batch 1984, epoch 17/20:
2017-12-03 05:50:56,908:train.py:200 -         run_log_save():    avg word perp:   7.57
2017-12-03 05:50:56,908:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 05:50:56,908:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:52:03,779:train.py:199 -         run_log_save(): Batch 2084, epoch 17/20:
2017-12-03 05:52:03,781:train.py:200 -         run_log_save():    avg word perp:   7.71
2017-12-03 05:52:03,781:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 05:52:03,781:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:53:10,668:train.py:199 -         run_log_save(): Batch 2184, epoch 17/20:
2017-12-03 05:53:10,668:train.py:200 -         run_log_save():    avg word perp:   7.66
2017-12-03 05:53:10,668:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 05:53:10,668:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:54:17,339:train.py:199 -         run_log_save(): Batch 2284, epoch 17/20:
2017-12-03 05:54:17,339:train.py:200 -         run_log_save():    avg word perp:   7.66
2017-12-03 05:54:17,340:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 05:54:17,340:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:55:24,783:train.py:199 -         run_log_save(): Batch 2384, epoch 17/20:
2017-12-03 05:55:24,784:train.py:200 -         run_log_save():    avg word perp:   7.56
2017-12-03 05:55:24,784:train.py:201 -         run_log_save():    acc trg words/s: 2432
2017-12-03 05:55:24,784:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:56:31,232:train.py:199 -         run_log_save(): Batch 2484, epoch 17/20:
2017-12-03 05:56:31,232:train.py:200 -         run_log_save():    avg word perp:   7.61
2017-12-03 05:56:31,232:train.py:201 -         run_log_save():    acc trg words/s: 2432
2017-12-03 05:56:31,232:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 05:57:08,415:train.py:151 -         sample_input(): Sample input data:
2017-12-03 05:57:08,415:train.py:152 -         sample_input(): Src: _UNK
2017-12-03 05:57:08,415:train.py:153 -         sample_input(): Src len: 1
2017-12-03 05:57:08,416:train.py:154 -         sample_input(): Trg: _BOS to convert
2017-12-03 05:57:08,416:train.py:155 -         sample_input(): Tar: to convert _EOS
2017-12-03 05:57:08,416:train.py:156 -         sample_input(): W: 1.0 1.0 1.0
2017-12-03 05:57:08,416:train.py:199 -         run_log_save(): Batch 2584, epoch 17/20:
2017-12-03 05:57:08,416:train.py:200 -         run_log_save():    avg word perp:   11.09
2017-12-03 05:57:08,416:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 05:57:08,416:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 05:57:11,703:train.py:207 -         run_log_save(): Save model to ./nmt/saved_models/de2en_bp/de2en_bp.cpkt, takes 0:00:03.287493
2017-12-03 05:57:18,571:train.py:199 -         run_log_save(): Batch 2684, epoch 17/20:
2017-12-03 05:57:18,571:train.py:200 -         run_log_save():    avg word perp:   312.23
2017-12-03 05:57:18,571:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 05:57:18,572:train.py:202 -         run_log_save():    acc sec/batch:   0.63
2017-12-03 05:57:25,417:train.py:199 -         run_log_save(): Batch 2784, epoch 17/20:
2017-12-03 05:57:25,417:train.py:200 -         run_log_save():    avg word perp:   294.93
2017-12-03 05:57:25,417:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 05:57:25,417:train.py:202 -         run_log_save():    acc sec/batch:   0.61
2017-12-03 05:57:32,269:train.py:199 -         run_log_save(): Batch 2884, epoch 17/20:
2017-12-03 05:57:32,270:train.py:200 -         run_log_save():    avg word perp:   291.08
2017-12-03 05:57:32,270:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 05:57:32,270:train.py:202 -         run_log_save():    acc sec/batch:   0.59
2017-12-03 05:57:39,101:train.py:199 -         run_log_save(): Batch 2984, epoch 17/20:
2017-12-03 05:57:39,101:train.py:200 -         run_log_save():    avg word perp:   282.04
2017-12-03 05:57:39,101:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 05:57:39,101:train.py:202 -         run_log_save():    acc sec/batch:   0.57
2017-12-03 05:57:45,944:train.py:199 -         run_log_save(): Batch 3084, epoch 17/20:
2017-12-03 05:57:45,944:train.py:200 -         run_log_save():    avg word perp:   282.02
2017-12-03 05:57:45,944:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 05:57:45,944:train.py:202 -         run_log_save():    acc sec/batch:   0.56
2017-12-03 05:57:52,776:train.py:199 -         run_log_save(): Batch 3184, epoch 17/20:
2017-12-03 05:57:52,776:train.py:200 -         run_log_save():    avg word perp:   272.77
2017-12-03 05:57:52,776:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 05:57:52,776:train.py:202 -         run_log_save():    acc sec/batch:   0.54
2017-12-03 05:57:59,284:train.py:119 -         report_epoch(): Finish epoch 17
2017-12-03 05:57:59,284:train.py:120 -         report_epoch():     It takes 0:28:46.586288
2017-12-03 05:57:59,284:train.py:121 -         report_epoch():     Avergage # words/second    2433.87314568
2017-12-03 05:57:59,284:train.py:122 -         report_epoch():     Average seconds/batch    0.527040991445
2017-12-03 05:57:59,284:train.py:133 -         report_epoch():     train perplexity: 8.36100867842
2017-12-03 05:57:59,859:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.574545860291 seconds
2017-12-03 05:58:03,640:train.py:199 -         run_log_save(): Batch 8, epoch 18/20:
2017-12-03 05:58:03,642:train.py:200 -         run_log_save():    avg word perp:   81.93
2017-12-03 05:58:03,642:train.py:201 -         run_log_save():    acc trg words/s: 2130
2017-12-03 05:58:03,642:train.py:202 -         run_log_save():    acc sec/batch:   0.46
2017-12-03 05:59:10,819:train.py:199 -         run_log_save(): Batch 108, epoch 18/20:
2017-12-03 05:59:10,819:train.py:200 -         run_log_save():    avg word perp:   7.59
2017-12-03 05:59:10,819:train.py:201 -         run_log_save():    acc trg words/s: 2396
2017-12-03 05:59:10,819:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 06:00:16,537:train.py:199 -         run_log_save(): Batch 208, epoch 18/20:
2017-12-03 06:00:16,537:train.py:200 -         run_log_save():    avg word perp:   7.24
2017-12-03 06:00:16,538:train.py:201 -         run_log_save():    acc trg words/s: 2422
2017-12-03 06:00:16,538:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 06:01:24,052:train.py:151 -         sample_input(): Sample input data:
2017-12-03 06:01:24,052:train.py:152 -         sample_input(): Src: . Deutschlands Strategie politische reichste aussichts@@ die bleiben Institutionen transatlantische und europäische über Einflussnahme und Souveränität geteilte Europäern anderen mit _PAD _PAD
2017-12-03 06:01:24,052:train.py:153 -         sample_input(): Src len: 20
2017-12-03 06:01:24,052:train.py:154 -         sample_input(): Trg: _BOS sharing sovereignty with its fellow Europeans and exer@@ ting influence through European and Atlantic institutions remains Germany &apos;s most promising political strategy . _PAD _PAD _PAD
2017-12-03 06:01:24,052:train.py:155 -         sample_input(): Tar: sharing sovereignty with its fellow Europeans and exer@@ ting influence through European and Atlantic institutions remains Germany &apos;s most promising political strategy . _EOS _PAD _PAD _PAD
2017-12-03 06:01:24,053:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0
2017-12-03 06:01:24,053:train.py:199 -         run_log_save(): Batch 308, epoch 18/20:
2017-12-03 06:01:24,053:train.py:200 -         run_log_save():    avg word perp:   7.24
2017-12-03 06:01:24,053:train.py:201 -         run_log_save():    acc trg words/s: 2415
2017-12-03 06:01:24,053:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:01:24,053:validator.py:224 -    validate_and_save(): Start validation
2017-12-03 06:02:23,006:validator.py:143 -             evaluate():   Translating line 100, average 0.589521780014 seconds/sent
2017-12-03 06:03:24,457:validator.py:143 -             evaluate():   Translating line 200, average 0.602018270493 seconds/sent
2017-12-03 06:04:15,047:validator.py:143 -             evaluate():   Translating line 300, average 0.56998017629 seconds/sent
2017-12-03 06:05:10,235:validator.py:143 -             evaluate():   Translating line 400, average 0.565453264713 seconds/sent
2017-12-03 06:06:14,107:validator.py:143 -             evaluate():   Translating line 500, average 0.580107302189 seconds/sent
2017-12-03 06:07:08,878:validator.py:143 -             evaluate():   Translating line 600, average 0.574707634846 seconds/sent
2017-12-03 06:08:06,250:validator.py:143 -             evaluate():   Translating line 700, average 0.574566844191 seconds/sent
2017-12-03 06:08:52,992:validator.py:143 -             evaluate():   Translating line 800, average 0.561173063815 seconds/sent
2017-12-03 06:09:34,564:validator.py:143 -             evaluate():   Translating line 900, average 0.545012101067 seconds/sent
2017-12-03 06:10:27,797:validator.py:143 -             evaluate():   Translating line 1000, average 0.543743696928 seconds/sent
2017-12-03 06:11:23,882:validator.py:143 -             evaluate():   Translating line 1100, average 0.545298421816 seconds/sent
2017-12-03 06:12:11,501:validator.py:143 -             evaluate():   Translating line 1200, average 0.539539715846 seconds/sent
2017-12-03 06:13:15,265:validator.py:143 -             evaluate():   Translating line 1300, average 0.547085776146 seconds/sent
2017-12-03 06:14:14,222:validator.py:143 -             evaluate():   Translating line 1400, average 0.550120302779 seconds/sent
2017-12-03 06:15:16,570:validator.py:143 -             evaluate():   Translating line 1500, average 0.555011056582 seconds/sent
2017-12-03 06:16:19,806:validator.py:143 -             evaluate():   Translating line 1600, average 0.55984555319 seconds/sent
2017-12-03 06:17:19,963:validator.py:143 -             evaluate():   Translating line 1700, average 0.562299710582 seconds/sent
2017-12-03 06:18:25,130:validator.py:143 -             evaluate():   Translating line 1800, average 0.567264691061 seconds/sent
2017-12-03 06:19:28,812:validator.py:143 -             evaluate():   Translating line 1900, average 0.570925607305 seconds/sent
2017-12-03 06:20:01,424:validator.py:152 -             evaluate(): Done translating.
2017-12-03 06:20:01,425:validator.py:153 -             evaluate(): dev perplexity: 56.249
2017-12-03 06:20:01,914:validator.py:159 -             evaluate(): BLEU = 13.59, 40.6/18.0/9.3/5.0 (BP=1.000, ratio=1.013, hyp_len=45861, ref_len=45274)

2017-12-03 06:20:01,915:validator.py:160 -             evaluate(): Validation took: 18.6310229659 minutes
2017-12-03 06:20:01,918:validator.py:195 -           maybe_save(): Current best bleus: 12.71
2017-12-03 06:20:01,918:validator.py:196 -           maybe_save(): Delete 12.71 & use 13.59 instead
2017-12-03 06:20:01,918:validator.py:206 -           maybe_save(): Delete ./nmt/saved_models/de2en_bp/de2en_bp-12.71.cpkt.data-00000-of-00001 & ./nmt/saved_models/de2en_bp/de2en_bp-12.71.cpkt.meta & ./nmt/saved_models/de2en_bp/de2en_bp-12.71.cpkt.index
2017-12-03 06:20:01,943:validator.py:212 -           maybe_save(): Save 13.59 to list of best bleu scores
2017-12-03 06:20:02,510:validator.py:216 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en_bp/de2en_bp-13.59.cpkt
2017-12-03 06:20:02,511:validator.py:217 -           maybe_save(): Best bleu scores so far: 13.59
2017-12-03 06:21:10,232:train.py:199 -         run_log_save(): Batch 408, epoch 18/20:
2017-12-03 06:21:10,232:train.py:200 -         run_log_save():    avg word perp:   7.17
2017-12-03 06:21:10,233:train.py:201 -         run_log_save():    acc trg words/s: 2413
2017-12-03 06:21:10,233:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:22:17,947:train.py:199 -         run_log_save(): Batch 508, epoch 18/20:
2017-12-03 06:22:17,947:train.py:200 -         run_log_save():    avg word perp:   7.21
2017-12-03 06:22:17,947:train.py:201 -         run_log_save():    acc trg words/s: 2411
2017-12-03 06:22:17,948:train.py:202 -         run_log_save():    acc sec/batch:   0.67
2017-12-03 06:23:26,495:train.py:199 -         run_log_save(): Batch 608, epoch 18/20:
2017-12-03 06:23:26,495:train.py:200 -         run_log_save():    avg word perp:   7.02
2017-12-03 06:23:26,495:train.py:201 -         run_log_save():    acc trg words/s: 2401
2017-12-03 06:23:26,495:train.py:202 -         run_log_save():    acc sec/batch:   0.67
2017-12-03 06:24:32,879:train.py:199 -         run_log_save(): Batch 708, epoch 18/20:
2017-12-03 06:24:32,879:train.py:200 -         run_log_save():    avg word perp:   7.40
2017-12-03 06:24:32,879:train.py:201 -         run_log_save():    acc trg words/s: 2405
2017-12-03 06:24:32,879:train.py:202 -         run_log_save():    acc sec/batch:   0.67
2017-12-03 06:25:39,922:train.py:199 -         run_log_save(): Batch 808, epoch 18/20:
2017-12-03 06:25:39,924:train.py:200 -         run_log_save():    avg word perp:   7.21
2017-12-03 06:25:39,924:train.py:201 -         run_log_save():    acc trg words/s: 2405
2017-12-03 06:25:39,924:train.py:202 -         run_log_save():    acc sec/batch:   0.67
2017-12-03 06:26:47,009:train.py:199 -         run_log_save(): Batch 908, epoch 18/20:
2017-12-03 06:26:47,009:train.py:200 -         run_log_save():    avg word perp:   7.31
2017-12-03 06:26:47,009:train.py:201 -         run_log_save():    acc trg words/s: 2405
2017-12-03 06:26:47,009:train.py:202 -         run_log_save():    acc sec/batch:   0.67
2017-12-03 06:27:53,859:train.py:199 -         run_log_save(): Batch 1008, epoch 18/20:
2017-12-03 06:27:53,859:train.py:200 -         run_log_save():    avg word perp:   7.18
2017-12-03 06:27:53,859:train.py:201 -         run_log_save():    acc trg words/s: 2406
2017-12-03 06:27:53,859:train.py:202 -         run_log_save():    acc sec/batch:   0.67
2017-12-03 06:29:00,905:train.py:199 -         run_log_save(): Batch 1108, epoch 18/20:
2017-12-03 06:29:00,905:train.py:200 -         run_log_save():    avg word perp:   7.42
2017-12-03 06:29:00,905:train.py:201 -         run_log_save():    acc trg words/s: 2410
2017-12-03 06:29:00,905:train.py:202 -         run_log_save():    acc sec/batch:   0.67
2017-12-03 06:30:06,589:train.py:199 -         run_log_save(): Batch 1208, epoch 18/20:
2017-12-03 06:30:06,589:train.py:200 -         run_log_save():    avg word perp:   7.16
2017-12-03 06:30:06,589:train.py:201 -         run_log_save():    acc trg words/s: 2414
2017-12-03 06:30:06,589:train.py:202 -         run_log_save():    acc sec/batch:   0.67
2017-12-03 06:31:12,606:train.py:151 -         sample_input(): Sample input data:
2017-12-03 06:31:12,606:train.py:152 -         sample_input(): Src: . passen zusammen@@ nicht eben ) Partei kommunistische chinesische ( P C@@ und PC dass , bemerkte Kopf kluger ein _PAD _PAD
2017-12-03 06:31:12,606:train.py:153 -         sample_input(): Src len: 20
2017-12-03 06:31:12,606:train.py:154 -         sample_input(): Trg: _BOS as one wi@@ t has observed , the PC ( personal computer ) and the C@@ P ( Communist Party ) do not go together . _PAD
2017-12-03 06:31:12,606:train.py:155 -         sample_input(): Tar: as one wi@@ t has observed , the PC ( personal computer ) and the C@@ P ( Communist Party ) do not go together . _EOS _PAD
2017-12-03 06:31:12,606:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0
2017-12-03 06:31:12,606:train.py:199 -         run_log_save(): Batch 1308, epoch 18/20:
2017-12-03 06:31:12,606:train.py:200 -         run_log_save():    avg word perp:   7.26
2017-12-03 06:31:12,607:train.py:201 -         run_log_save():    acc trg words/s: 2416
2017-12-03 06:31:12,607:train.py:202 -         run_log_save():    acc sec/batch:   0.67
2017-12-03 06:32:19,291:train.py:199 -         run_log_save(): Batch 1408, epoch 18/20:
2017-12-03 06:32:19,292:train.py:200 -         run_log_save():    avg word perp:   7.40
2017-12-03 06:32:19,292:train.py:201 -         run_log_save():    acc trg words/s: 2417
2017-12-03 06:32:19,292:train.py:202 -         run_log_save():    acc sec/batch:   0.67
2017-12-03 06:33:25,021:train.py:199 -         run_log_save(): Batch 1508, epoch 18/20:
2017-12-03 06:33:25,021:train.py:200 -         run_log_save():    avg word perp:   7.14
2017-12-03 06:33:25,021:train.py:201 -         run_log_save():    acc trg words/s: 2420
2017-12-03 06:33:25,021:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:34:30,698:train.py:199 -         run_log_save(): Batch 1608, epoch 18/20:
2017-12-03 06:34:30,698:train.py:200 -         run_log_save():    avg word perp:   7.32
2017-12-03 06:34:30,698:train.py:201 -         run_log_save():    acc trg words/s: 2422
2017-12-03 06:34:30,698:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:35:35,223:train.py:199 -         run_log_save(): Batch 1708, epoch 18/20:
2017-12-03 06:35:35,223:train.py:200 -         run_log_save():    avg word perp:   7.26
2017-12-03 06:35:35,223:train.py:201 -         run_log_save():    acc trg words/s: 2425
2017-12-03 06:35:35,223:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:36:41,101:train.py:199 -         run_log_save(): Batch 1808, epoch 18/20:
2017-12-03 06:36:41,102:train.py:200 -         run_log_save():    avg word perp:   7.42
2017-12-03 06:36:41,102:train.py:201 -         run_log_save():    acc trg words/s: 2427
2017-12-03 06:36:41,102:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:37:47,272:train.py:199 -         run_log_save(): Batch 1908, epoch 18/20:
2017-12-03 06:37:47,272:train.py:200 -         run_log_save():    avg word perp:   7.19
2017-12-03 06:37:47,272:train.py:201 -         run_log_save():    acc trg words/s: 2428
2017-12-03 06:37:47,272:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:38:53,559:train.py:199 -         run_log_save(): Batch 2008, epoch 18/20:
2017-12-03 06:38:53,559:train.py:200 -         run_log_save():    avg word perp:   7.35
2017-12-03 06:38:53,559:train.py:201 -         run_log_save():    acc trg words/s: 2429
2017-12-03 06:38:53,559:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:40:00,612:train.py:199 -         run_log_save(): Batch 2108, epoch 18/20:
2017-12-03 06:40:00,612:train.py:200 -         run_log_save():    avg word perp:   7.39
2017-12-03 06:40:00,612:train.py:201 -         run_log_save():    acc trg words/s: 2428
2017-12-03 06:40:00,612:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:41:06,329:train.py:199 -         run_log_save(): Batch 2208, epoch 18/20:
2017-12-03 06:41:06,329:train.py:200 -         run_log_save():    avg word perp:   7.49
2017-12-03 06:41:06,329:train.py:201 -         run_log_save():    acc trg words/s: 2429
2017-12-03 06:41:06,329:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:42:12,845:train.py:151 -         sample_input(): Sample input data:
2017-12-03 06:42:12,845:train.py:152 -         sample_input(): Src: . werden unterschätzt nicht Manöver diese durch Rechtssystems irakischen des Institutionen die für Schaden langfristige der sollte Politik der von abgesehen _PAD
2017-12-03 06:42:12,845:train.py:153 -         sample_input(): Src len: 21
2017-12-03 06:42:12,846:train.py:154 -         sample_input(): Trg: _BOS politics aside , the long @-@ term damage to Iraq &apos;s legal institutions caused by these maneu@@ ver@@ ings should not be underestimated . _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 06:42:12,846:train.py:155 -         sample_input(): Tar: politics aside , the long @-@ term damage to Iraq &apos;s legal institutions caused by these maneu@@ ver@@ ings should not be underestimated . _EOS _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 06:42:12,846:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 06:42:12,846:train.py:199 -         run_log_save(): Batch 2308, epoch 18/20:
2017-12-03 06:42:12,846:train.py:200 -         run_log_save():    avg word perp:   7.32
2017-12-03 06:42:12,846:train.py:201 -         run_log_save():    acc trg words/s: 2429
2017-12-03 06:42:12,846:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:43:18,547:train.py:199 -         run_log_save(): Batch 2408, epoch 18/20:
2017-12-03 06:43:18,548:train.py:200 -         run_log_save():    avg word perp:   7.36
2017-12-03 06:43:18,548:train.py:201 -         run_log_save():    acc trg words/s: 2431
2017-12-03 06:43:18,548:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:44:26,262:train.py:199 -         run_log_save(): Batch 2508, epoch 18/20:
2017-12-03 06:44:26,263:train.py:200 -         run_log_save():    avg word perp:   7.40
2017-12-03 06:44:26,263:train.py:201 -         run_log_save():    acc trg words/s: 2429
2017-12-03 06:44:26,263:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:44:50,281:train.py:199 -         run_log_save(): Batch 2608, epoch 18/20:
2017-12-03 06:44:50,282:train.py:200 -         run_log_save():    avg word perp:   17.77
2017-12-03 06:44:50,282:train.py:201 -         run_log_save():    acc trg words/s: 2430
2017-12-03 06:44:50,282:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 06:44:57,134:train.py:199 -         run_log_save(): Batch 2708, epoch 18/20:
2017-12-03 06:44:57,134:train.py:200 -         run_log_save():    avg word perp:   320.80
2017-12-03 06:44:57,134:train.py:201 -         run_log_save():    acc trg words/s: 2430
2017-12-03 06:44:57,134:train.py:202 -         run_log_save():    acc sec/batch:   0.62
2017-12-03 06:45:04,005:train.py:199 -         run_log_save(): Batch 2808, epoch 18/20:
2017-12-03 06:45:04,005:train.py:200 -         run_log_save():    avg word perp:   300.34
2017-12-03 06:45:04,005:train.py:201 -         run_log_save():    acc trg words/s: 2430
2017-12-03 06:45:04,005:train.py:202 -         run_log_save():    acc sec/batch:   0.60
2017-12-03 06:45:10,938:train.py:199 -         run_log_save(): Batch 2908, epoch 18/20:
2017-12-03 06:45:10,938:train.py:200 -         run_log_save():    avg word perp:   279.32
2017-12-03 06:45:10,938:train.py:201 -         run_log_save():    acc trg words/s: 2430
2017-12-03 06:45:10,938:train.py:202 -         run_log_save():    acc sec/batch:   0.59
2017-12-03 06:45:17,908:train.py:199 -         run_log_save(): Batch 3008, epoch 18/20:
2017-12-03 06:45:17,909:train.py:200 -         run_log_save():    avg word perp:   286.17
2017-12-03 06:45:17,909:train.py:201 -         run_log_save():    acc trg words/s: 2430
2017-12-03 06:45:17,909:train.py:202 -         run_log_save():    acc sec/batch:   0.57
2017-12-03 06:45:24,860:train.py:199 -         run_log_save(): Batch 3108, epoch 18/20:
2017-12-03 06:45:24,860:train.py:200 -         run_log_save():    avg word perp:   284.45
2017-12-03 06:45:24,860:train.py:201 -         run_log_save():    acc trg words/s: 2430
2017-12-03 06:45:24,860:train.py:202 -         run_log_save():    acc sec/batch:   0.55
2017-12-03 06:45:31,796:train.py:199 -         run_log_save(): Batch 3208, epoch 18/20:
2017-12-03 06:45:31,796:train.py:200 -         run_log_save():    avg word perp:   288.92
2017-12-03 06:45:31,796:train.py:201 -         run_log_save():    acc trg words/s: 2429
2017-12-03 06:45:31,797:train.py:202 -         run_log_save():    acc sec/batch:   0.54
2017-12-03 06:45:36,554:train.py:119 -         report_epoch(): Finish epoch 18
2017-12-03 06:45:36,554:train.py:120 -         report_epoch():     It takes 0:28:49.548152
2017-12-03 06:45:36,554:train.py:121 -         report_epoch():     Avergage # words/second    2429.71784035
2017-12-03 06:45:36,554:train.py:122 -         report_epoch():     Average seconds/batch    0.527945101261
2017-12-03 06:45:36,554:train.py:133 -         report_epoch():     train perplexity: 8.13621021773
2017-12-03 06:45:37,088:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.533798933029 seconds
2017-12-03 06:45:57,057:train.py:151 -         sample_input(): Sample input data:
2017-12-03 06:45:57,057:train.py:152 -         sample_input(): Src: . formen Ausdrucks@@ kulturellen geprägten national alle akzeptierte und , vermied selbst Wort das es obwohl , europäisch nach Wesen seinem war Christentum liche mittelalter@@ das _PAD _PAD
2017-12-03 06:45:57,057:train.py:153 -         sample_input(): Src len: 26
2017-12-03 06:45:57,057:train.py:154 -         sample_input(): Trg: _BOS medieval Christianity was by nature European , although it avoided the word itself and accepted all national forms of cultural expression . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 06:45:57,057:train.py:155 -         sample_input(): Tar: medieval Christianity was by nature European , although it avoided the word itself and accepted all national forms of cultural expression . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 06:45:57,057:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 06:45:57,057:train.py:199 -         run_log_save(): Batch 32, epoch 19/20:
2017-12-03 06:45:57,058:train.py:200 -         run_log_save():    avg word perp:   16.14
2017-12-03 06:45:57,058:train.py:201 -         run_log_save():    acc trg words/s: 2345
2017-12-03 06:45:57,058:train.py:202 -         run_log_save():    acc sec/batch:   0.62
2017-12-03 06:47:02,826:train.py:199 -         run_log_save(): Batch 132, epoch 19/20:
2017-12-03 06:47:02,826:train.py:200 -         run_log_save():    avg word perp:   7.00
2017-12-03 06:47:02,827:train.py:201 -         run_log_save():    acc trg words/s: 2414
2017-12-03 06:47:02,827:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 06:48:08,492:train.py:199 -         run_log_save(): Batch 232, epoch 19/20:
2017-12-03 06:48:08,492:train.py:200 -         run_log_save():    avg word perp:   6.99
2017-12-03 06:48:08,492:train.py:201 -         run_log_save():    acc trg words/s: 2439
2017-12-03 06:48:08,492:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 06:49:14,650:train.py:199 -         run_log_save(): Batch 332, epoch 19/20:
2017-12-03 06:49:14,650:train.py:200 -         run_log_save():    avg word perp:   7.00
2017-12-03 06:49:14,650:train.py:201 -         run_log_save():    acc trg words/s: 2443
2017-12-03 06:49:14,650:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 06:50:20,240:train.py:199 -         run_log_save(): Batch 432, epoch 19/20:
2017-12-03 06:50:20,240:train.py:200 -         run_log_save():    avg word perp:   7.00
2017-12-03 06:50:20,240:train.py:201 -         run_log_save():    acc trg words/s: 2449
2017-12-03 06:50:20,240:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 06:51:27,780:train.py:199 -         run_log_save(): Batch 532, epoch 19/20:
2017-12-03 06:51:27,780:train.py:200 -         run_log_save():    avg word perp:   7.05
2017-12-03 06:51:27,780:train.py:201 -         run_log_save():    acc trg words/s: 2440
2017-12-03 06:51:27,780:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:52:34,188:train.py:199 -         run_log_save(): Batch 632, epoch 19/20:
2017-12-03 06:52:34,189:train.py:200 -         run_log_save():    avg word perp:   7.00
2017-12-03 06:52:34,189:train.py:201 -         run_log_save():    acc trg words/s: 2439
2017-12-03 06:52:34,189:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:53:40,178:train.py:199 -         run_log_save(): Batch 732, epoch 19/20:
2017-12-03 06:53:40,178:train.py:200 -         run_log_save():    avg word perp:   7.12
2017-12-03 06:53:40,178:train.py:201 -         run_log_save():    acc trg words/s: 2439
2017-12-03 06:53:40,178:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:54:45,890:train.py:199 -         run_log_save(): Batch 832, epoch 19/20:
2017-12-03 06:54:45,890:train.py:200 -         run_log_save():    avg word perp:   7.09
2017-12-03 06:54:45,890:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 06:54:45,890:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:55:50,987:train.py:199 -         run_log_save(): Batch 932, epoch 19/20:
2017-12-03 06:55:50,987:train.py:200 -         run_log_save():    avg word perp:   7.06
2017-12-03 06:55:50,987:train.py:201 -         run_log_save():    acc trg words/s: 2447
2017-12-03 06:55:50,987:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 06:56:55,991:train.py:151 -         sample_input(): Sample input data:
2017-12-03 06:56:55,991:train.py:152 -         sample_input(): Src: . niedrig war quote s@@ gen@@ Versa@@ die ; besetzen zu Arbeitsplätze echte um , aus Tagen zwei von Länge einer von ungen Schul@@ reichten plötzlich _PAD _PAD
2017-12-03 06:56:55,991:train.py:153 -         sample_input(): Src len: 26
2017-12-03 06:56:55,991:train.py:154 -         sample_input(): Trg: _BOS suddenly , two days of training became sufficient before starting real jobs ; the failure rate was low . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 06:56:55,991:train.py:155 -         sample_input(): Tar: suddenly , two days of training became sufficient before starting real jobs ; the failure rate was low . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 06:56:55,991:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 06:56:55,991:train.py:199 -         run_log_save(): Batch 1032, epoch 19/20:
2017-12-03 06:56:55,992:train.py:200 -         run_log_save():    avg word perp:   7.08
2017-12-03 06:56:55,992:train.py:201 -         run_log_save():    acc trg words/s: 2451
2017-12-03 06:56:55,992:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 06:56:59,340:train.py:207 -         run_log_save(): Save model to ./nmt/saved_models/de2en_bp/de2en_bp.cpkt, takes 0:00:03.348500
2017-12-03 06:58:05,338:train.py:199 -         run_log_save(): Batch 1132, epoch 19/20:
2017-12-03 06:58:05,338:train.py:200 -         run_log_save():    avg word perp:   7.10
2017-12-03 06:58:05,338:train.py:201 -         run_log_save():    acc trg words/s: 2452
2017-12-03 06:58:05,338:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 06:59:11,854:train.py:199 -         run_log_save(): Batch 1232, epoch 19/20:
2017-12-03 06:59:11,854:train.py:200 -         run_log_save():    avg word perp:   6.96
2017-12-03 06:59:11,854:train.py:201 -         run_log_save():    acc trg words/s: 2452
2017-12-03 06:59:11,855:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:00:17,552:train.py:199 -         run_log_save(): Batch 1332, epoch 19/20:
2017-12-03 07:00:17,553:train.py:200 -         run_log_save():    avg word perp:   7.17
2017-12-03 07:00:17,553:train.py:201 -         run_log_save():    acc trg words/s: 2452
2017-12-03 07:00:17,553:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:01:23,994:train.py:199 -         run_log_save(): Batch 1432, epoch 19/20:
2017-12-03 07:01:23,994:train.py:200 -         run_log_save():    avg word perp:   7.11
2017-12-03 07:01:23,994:train.py:201 -         run_log_save():    acc trg words/s: 2451
2017-12-03 07:01:23,994:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:02:30,027:train.py:199 -         run_log_save(): Batch 1532, epoch 19/20:
2017-12-03 07:02:30,027:train.py:200 -         run_log_save():    avg word perp:   7.11
2017-12-03 07:02:30,027:train.py:201 -         run_log_save():    acc trg words/s: 2450
2017-12-03 07:02:30,027:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:03:36,098:train.py:199 -         run_log_save(): Batch 1632, epoch 19/20:
2017-12-03 07:03:36,098:train.py:200 -         run_log_save():    avg word perp:   6.90
2017-12-03 07:03:36,098:train.py:201 -         run_log_save():    acc trg words/s: 2449
2017-12-03 07:03:36,098:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:04:42,468:train.py:199 -         run_log_save(): Batch 1732, epoch 19/20:
2017-12-03 07:04:42,468:train.py:200 -         run_log_save():    avg word perp:   7.16
2017-12-03 07:04:42,468:train.py:201 -         run_log_save():    acc trg words/s: 2449
2017-12-03 07:04:42,468:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:05:48,992:train.py:199 -         run_log_save(): Batch 1832, epoch 19/20:
2017-12-03 07:05:48,992:train.py:200 -         run_log_save():    avg word perp:   7.14
2017-12-03 07:05:48,992:train.py:201 -         run_log_save():    acc trg words/s: 2448
2017-12-03 07:05:48,992:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:06:56,496:train.py:199 -         run_log_save(): Batch 1932, epoch 19/20:
2017-12-03 07:06:56,497:train.py:200 -         run_log_save():    avg word perp:   7.23
2017-12-03 07:06:56,497:train.py:201 -         run_log_save():    acc trg words/s: 2445
2017-12-03 07:06:56,497:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:08:04,587:train.py:151 -         sample_input(): Sample input data:
2017-12-03 07:08:04,587:train.py:152 -         sample_input(): Src: . unterliegen Schwankungen starken die , zögerungen ver@@ Zeit@@ langen : nannte es Friedman Milton wie , unterworfen &quot; lags variable and long &quot; ist sie _PAD _PAD
2017-12-03 07:08:04,588:train.py:153 -         sample_input(): Src len: 26
2017-12-03 07:08:04,588:train.py:154 -         sample_input(): Trg: _BOS it is subject to what Milton Friedman called &quot; long and variable lags . &quot; _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 07:08:04,588:train.py:155 -         sample_input(): Tar: it is subject to what Milton Friedman called &quot; long and variable lags . &quot; _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 07:08:04,588:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 07:08:04,588:train.py:199 -         run_log_save(): Batch 2032, epoch 19/20:
2017-12-03 07:08:04,588:train.py:200 -         run_log_save():    avg word perp:   7.26
2017-12-03 07:08:04,588:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 07:08:04,588:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:09:11,234:train.py:199 -         run_log_save(): Batch 2132, epoch 19/20:
2017-12-03 07:09:11,235:train.py:200 -         run_log_save():    avg word perp:   7.23
2017-12-03 07:09:11,235:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 07:09:11,235:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:10:17,760:train.py:199 -         run_log_save(): Batch 2232, epoch 19/20:
2017-12-03 07:10:17,760:train.py:200 -         run_log_save():    avg word perp:   7.23
2017-12-03 07:10:17,760:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 07:10:17,760:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:11:23,537:train.py:199 -         run_log_save(): Batch 2332, epoch 19/20:
2017-12-03 07:11:23,538:train.py:200 -         run_log_save():    avg word perp:   7.16
2017-12-03 07:11:23,538:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 07:11:23,538:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:12:29,671:train.py:199 -         run_log_save(): Batch 2432, epoch 19/20:
2017-12-03 07:12:29,671:train.py:200 -         run_log_save():    avg word perp:   7.21
2017-12-03 07:12:29,671:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 07:12:29,672:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:13:36,084:train.py:199 -         run_log_save(): Batch 2532, epoch 19/20:
2017-12-03 07:13:36,085:train.py:200 -         run_log_save():    avg word perp:   7.24
2017-12-03 07:13:36,085:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 07:13:36,085:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:13:45,558:train.py:199 -         run_log_save(): Batch 2632, epoch 19/20:
2017-12-03 07:13:45,558:train.py:200 -         run_log_save():    avg word perp:   126.09
2017-12-03 07:13:45,558:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 07:13:45,558:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-03 07:13:52,505:train.py:199 -         run_log_save(): Batch 2732, epoch 19/20:
2017-12-03 07:13:52,506:train.py:200 -         run_log_save():    avg word perp:   274.68
2017-12-03 07:13:52,506:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 07:13:52,506:train.py:202 -         run_log_save():    acc sec/batch:   0.62
2017-12-03 07:13:59,441:train.py:199 -         run_log_save(): Batch 2832, epoch 19/20:
2017-12-03 07:13:59,441:train.py:200 -         run_log_save():    avg word perp:   281.21
2017-12-03 07:13:59,441:train.py:201 -         run_log_save():    acc trg words/s: 2442
2017-12-03 07:13:59,441:train.py:202 -         run_log_save():    acc sec/batch:   0.60
2017-12-03 07:14:06,365:train.py:199 -         run_log_save(): Batch 2932, epoch 19/20:
2017-12-03 07:14:06,365:train.py:200 -         run_log_save():    avg word perp:   278.21
2017-12-03 07:14:06,365:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 07:14:06,366:train.py:202 -         run_log_save():    acc sec/batch:   0.58
2017-12-03 07:14:13,275:train.py:151 -         sample_input(): Sample input data:
2017-12-03 07:14:13,275:train.py:152 -         sample_input(): Src: _UNK
2017-12-03 07:14:13,275:train.py:153 -         sample_input(): Src len: 1
2017-12-03 07:14:13,275:train.py:154 -         sample_input(): Trg: _BOS lunchtime _PAD
2017-12-03 07:14:13,275:train.py:155 -         sample_input(): Tar: lunchtime _EOS _PAD
2017-12-03 07:14:13,275:train.py:156 -         sample_input(): W: 1.0 1.0 0.0
2017-12-03 07:14:13,275:train.py:199 -         run_log_save(): Batch 3032, epoch 19/20:
2017-12-03 07:14:13,275:train.py:200 -         run_log_save():    avg word perp:   270.78
2017-12-03 07:14:13,275:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 07:14:13,275:train.py:202 -         run_log_save():    acc sec/batch:   0.56
2017-12-03 07:14:20,203:train.py:199 -         run_log_save(): Batch 3132, epoch 19/20:
2017-12-03 07:14:20,203:train.py:200 -         run_log_save():    avg word perp:   266.40
2017-12-03 07:14:20,204:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 07:14:20,204:train.py:202 -         run_log_save():    acc sec/batch:   0.55
2017-12-03 07:14:27,129:train.py:199 -         run_log_save(): Batch 3232, epoch 19/20:
2017-12-03 07:14:27,130:train.py:200 -         run_log_save():    avg word perp:   272.20
2017-12-03 07:14:27,130:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 07:14:27,130:train.py:202 -         run_log_save():    acc sec/batch:   0.53
2017-12-03 07:14:30,223:train.py:119 -         report_epoch(): Finish epoch 19
2017-12-03 07:14:30,223:train.py:120 -         report_epoch():     It takes 0:28:41.329058
2017-12-03 07:14:30,223:train.py:121 -         report_epoch():     Avergage # words/second    2441.30486269
2017-12-03 07:14:30,224:train.py:122 -         report_epoch():     Average seconds/batch    0.525436220443
2017-12-03 07:14:30,224:train.py:133 -         report_epoch():     train perplexity: 7.92138931778
2017-12-03 07:14:30,756:data_manager.py:338 -            get_batch(): Shuffling ./nmt/data/de2en_bp/train.ids takes 0.532004117966 seconds
2017-12-03 07:15:06,873:train.py:199 -         run_log_save(): Batch 56, epoch 20/20:
2017-12-03 07:15:06,874:train.py:200 -         run_log_save():    avg word perp:   10.24
2017-12-03 07:15:06,874:train.py:201 -         run_log_save():    acc trg words/s: 2436
2017-12-03 07:15:06,874:train.py:202 -         run_log_save():    acc sec/batch:   0.64
2017-12-03 07:16:12,709:train.py:199 -         run_log_save(): Batch 156, epoch 20/20:
2017-12-03 07:16:12,709:train.py:200 -         run_log_save():    avg word perp:   6.89
2017-12-03 07:16:12,709:train.py:201 -         run_log_save():    acc trg words/s: 2448
2017-12-03 07:16:12,709:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 07:17:19,074:train.py:199 -         run_log_save(): Batch 256, epoch 20/20:
2017-12-03 07:17:19,075:train.py:200 -         run_log_save():    avg word perp:   6.82
2017-12-03 07:17:19,075:train.py:201 -         run_log_save():    acc trg words/s: 2450
2017-12-03 07:17:19,075:train.py:202 -         run_log_save():    acc sec/batch:   0.65
2017-12-03 07:18:25,081:train.py:199 -         run_log_save(): Batch 356, epoch 20/20:
2017-12-03 07:18:25,082:train.py:200 -         run_log_save():    avg word perp:   6.86
2017-12-03 07:18:25,082:train.py:201 -         run_log_save():    acc trg words/s: 2451
2017-12-03 07:18:25,082:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:19:32,114:train.py:199 -         run_log_save(): Batch 456, epoch 20/20:
2017-12-03 07:19:32,114:train.py:200 -         run_log_save():    avg word perp:   6.77
2017-12-03 07:19:32,114:train.py:201 -         run_log_save():    acc trg words/s: 2443
2017-12-03 07:19:32,114:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:20:39,361:train.py:199 -         run_log_save(): Batch 556, epoch 20/20:
2017-12-03 07:20:39,361:train.py:200 -         run_log_save():    avg word perp:   6.84
2017-12-03 07:20:39,361:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 07:20:39,361:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:21:46,109:train.py:199 -         run_log_save(): Batch 656, epoch 20/20:
2017-12-03 07:21:46,109:train.py:200 -         run_log_save():    avg word perp:   6.70
2017-12-03 07:21:46,109:train.py:201 -         run_log_save():    acc trg words/s: 2433
2017-12-03 07:21:46,109:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:22:52,996:train.py:151 -         sample_input(): Sample input data:
2017-12-03 07:22:52,997:train.py:152 -         sample_input(): Src: . ielten th@@ fes@@ Dollar am bels Ru@@ des Abwertung weiteren einer Erwartung in Banken kommerziellen die während , stützte Korrektur langsame diese sie indem , Reserven ihre Zentralbank die verlor Zwischenzeit der in _PAD _PAD _PAD
2017-12-03 07:22:52,997:train.py:153 -         sample_input(): Src len: 34
2017-12-03 07:22:52,997:train.py:154 -         sample_input(): Trg: _BOS in the meantime , the central bank hemorrha@@ ged reserves defending this slow correction , while commercial banks have been holding on to dollars in anticipation of the ruble &apos;s further decline . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 07:22:52,997:train.py:155 -         sample_input(): Tar: in the meantime , the central bank hemorrha@@ ged reserves defending this slow correction , while commercial banks have been holding on to dollars in anticipation of the ruble &apos;s further decline . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-12-03 07:22:52,997:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-12-03 07:22:52,997:train.py:199 -         run_log_save(): Batch 756, epoch 20/20:
2017-12-03 07:22:52,997:train.py:200 -         run_log_save():    avg word perp:   6.88
2017-12-03 07:22:52,997:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 07:22:52,997:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:22:52,997:validator.py:224 -    validate_and_save(): Start validation
2017-12-03 07:23:52,669:validator.py:143 -             evaluate():   Translating line 100, average 0.59670689106 seconds/sent
2017-12-03 07:24:51,832:validator.py:143 -             evaluate():   Translating line 200, average 0.59416939497 seconds/sent
2017-12-03 07:25:42,173:validator.py:143 -             evaluate():   Translating line 300, average 0.563916403453 seconds/sent
2017-12-03 07:26:36,168:validator.py:143 -             evaluate():   Translating line 400, average 0.557923955321 seconds/sent
2017-12-03 07:27:36,622:validator.py:143 -             evaluate():   Translating line 500, average 0.567247426033 seconds/sent
2017-12-03 07:28:24,338:validator.py:143 -             evaluate():   Translating line 600, average 0.5522336936 seconds/sent
2017-12-03 07:29:21,719:validator.py:143 -             evaluate():   Translating line 700, average 0.555316242831 seconds/sent
2017-12-03 07:30:07,750:validator.py:143 -             evaluate():   Translating line 800, average 0.543439661264 seconds/sent
2017-12-03 07:30:48,361:validator.py:143 -             evaluate():   Translating line 900, average 0.528181242413 seconds/sent
2017-12-03 07:31:36,938:validator.py:143 -             evaluate():   Translating line 1000, average 0.523940304995 seconds/sent
2017-12-03 07:32:31,668:validator.py:143 -             evaluate():   Translating line 1100, average 0.526063146374 seconds/sent
2017-12-03 07:33:19,680:validator.py:143 -             evaluate():   Translating line 1200, average 0.522234774232 seconds/sent
2017-12-03 07:34:24,024:validator.py:143 -             evaluate():   Translating line 1300, average 0.531558735371 seconds/sent
2017-12-03 07:35:24,202:validator.py:143 -             evaluate():   Translating line 1400, average 0.536574056489 seconds/sent
2017-12-03 07:36:24,545:validator.py:143 -             evaluate():   Translating line 1500, average 0.541031586647 seconds/sent
2017-12-03 07:37:20,520:validator.py:143 -             evaluate():   Translating line 1600, average 0.542201495022 seconds/sent
2017-12-03 07:38:20,603:validator.py:143 -             evaluate():   Translating line 1700, average 0.545649944754 seconds/sent
2017-12-03 07:39:27,916:validator.py:143 -             evaluate():   Translating line 1800, average 0.552732332283 seconds/sent
2017-12-03 07:40:26,154:validator.py:143 -             evaluate():   Translating line 1900, average 0.554292396872 seconds/sent
2017-12-03 07:40:59,684:validator.py:152 -             evaluate(): Done translating.
2017-12-03 07:40:59,684:validator.py:153 -             evaluate(): dev perplexity: 55.219
2017-12-03 07:41:00,169:validator.py:159 -             evaluate(): BLEU = 14.72, 43.5/19.7/10.3/5.6 (BP=0.985, ratio=0.985, hyp_len=44607, ref_len=45274)

2017-12-03 07:41:00,169:validator.py:160 -             evaluate(): Validation took: 18.1195163846 minutes
2017-12-03 07:41:00,172:validator.py:195 -           maybe_save(): Current best bleus: 13.59
2017-12-03 07:41:00,173:validator.py:196 -           maybe_save(): Delete 13.59 & use 14.72 instead
2017-12-03 07:41:00,173:validator.py:206 -           maybe_save(): Delete ./nmt/saved_models/de2en_bp/de2en_bp-13.59.cpkt.data-00000-of-00001 & ./nmt/saved_models/de2en_bp/de2en_bp-13.59.cpkt.meta & ./nmt/saved_models/de2en_bp/de2en_bp-13.59.cpkt.index
2017-12-03 07:41:00,198:validator.py:212 -           maybe_save(): Save 14.72 to list of best bleu scores
2017-12-03 07:41:00,909:validator.py:216 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en_bp/de2en_bp-14.72.cpkt
2017-12-03 07:41:00,909:validator.py:217 -           maybe_save(): Best bleu scores so far: 14.72
2017-12-03 07:42:06,665:train.py:199 -         run_log_save(): Batch 856, epoch 20/20:
2017-12-03 07:42:06,665:train.py:200 -         run_log_save():    avg word perp:   6.91
2017-12-03 07:42:06,665:train.py:201 -         run_log_save():    acc trg words/s: 2438
2017-12-03 07:42:06,665:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:43:11,461:train.py:199 -         run_log_save(): Batch 956, epoch 20/20:
2017-12-03 07:43:11,462:train.py:200 -         run_log_save():    avg word perp:   6.88
2017-12-03 07:43:11,462:train.py:201 -         run_log_save():    acc trg words/s: 2443
2017-12-03 07:43:11,462:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:44:17,908:train.py:199 -         run_log_save(): Batch 1056, epoch 20/20:
2017-12-03 07:44:17,908:train.py:200 -         run_log_save():    avg word perp:   6.72
2017-12-03 07:44:17,908:train.py:201 -         run_log_save():    acc trg words/s: 2441
2017-12-03 07:44:17,908:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:45:24,277:train.py:199 -         run_log_save(): Batch 1156, epoch 20/20:
2017-12-03 07:45:24,277:train.py:200 -         run_log_save():    avg word perp:   6.91
2017-12-03 07:45:24,277:train.py:201 -         run_log_save():    acc trg words/s: 2440
2017-12-03 07:45:24,277:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:46:30,206:train.py:199 -         run_log_save(): Batch 1256, epoch 20/20:
2017-12-03 07:46:30,206:train.py:200 -         run_log_save():    avg word perp:   6.97
2017-12-03 07:46:30,206:train.py:201 -         run_log_save():    acc trg words/s: 2439
2017-12-03 07:46:30,206:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:47:37,339:train.py:199 -         run_log_save(): Batch 1356, epoch 20/20:
2017-12-03 07:47:37,339:train.py:200 -         run_log_save():    avg word perp:   6.93
2017-12-03 07:47:37,339:train.py:201 -         run_log_save():    acc trg words/s: 2437
2017-12-03 07:47:37,339:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:48:44,440:train.py:199 -         run_log_save(): Batch 1456, epoch 20/20:
2017-12-03 07:48:44,440:train.py:200 -         run_log_save():    avg word perp:   6.85
2017-12-03 07:48:44,440:train.py:201 -         run_log_save():    acc trg words/s: 2435
2017-12-03 07:48:44,440:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:49:50,967:train.py:199 -         run_log_save(): Batch 1556, epoch 20/20:
2017-12-03 07:49:50,967:train.py:200 -         run_log_save():    avg word perp:   6.99
2017-12-03 07:49:50,968:train.py:201 -         run_log_save():    acc trg words/s: 2436
2017-12-03 07:49:50,968:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:50:56,835:train.py:199 -         run_log_save(): Batch 1656, epoch 20/20:
2017-12-03 07:50:56,836:train.py:200 -         run_log_save():    avg word perp:   6.91
2017-12-03 07:50:56,836:train.py:201 -         run_log_save():    acc trg words/s: 2435
2017-12-03 07:50:56,836:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:52:02,972:train.py:151 -         sample_input(): Sample input data:
2017-12-03 07:52:02,972:train.py:152 -         sample_input(): Src: . &quot; come Over@@ all Sh@@ We &quot; sondern , angen s@@ &quot; Internationale &quot; die nicht schen är@@ m@@ Protest@@ ihren bei Studenten die dass , begründet darin teilweise Antwort die liegt vielleicht _PAD
2017-12-03 07:52:02,972:train.py:153 -         sample_input(): Src len: 34
2017-12-03 07:52:02,973:train.py:154 -         sample_input(): Trg: _BOS part of the answer may be that when students were marching in the streets protesting , they did not sing the &quot; _UNK &quot; ; they s@@ ang &quot; We Sh@@ all Over@@ come . &quot; _PAD _PAD _PAD _PAD
2017-12-03 07:52:02,973:train.py:155 -         sample_input(): Tar: part of the answer may be that when students were marching in the streets protesting , they did not sing the &quot; _UNK &quot; ; they s@@ ang &quot; We Sh@@ all Over@@ come . &quot; _EOS _PAD _PAD _PAD _PAD
2017-12-03 07:52:02,973:train.py:156 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0
2017-12-03 07:52:02,973:train.py:199 -         run_log_save(): Batch 1756, epoch 20/20:
2017-12-03 07:52:02,973:train.py:200 -         run_log_save():    avg word perp:   6.94
2017-12-03 07:52:02,973:train.py:201 -         run_log_save():    acc trg words/s: 2436
2017-12-03 07:52:02,973:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:53:09,880:train.py:199 -         run_log_save(): Batch 1856, epoch 20/20:
2017-12-03 07:53:09,880:train.py:200 -         run_log_save():    avg word perp:   7.10
2017-12-03 07:53:09,881:train.py:201 -         run_log_save():    acc trg words/s: 2435
2017-12-03 07:53:09,881:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:54:16,325:train.py:199 -         run_log_save(): Batch 1956, epoch 20/20:
2017-12-03 07:54:16,326:train.py:200 -         run_log_save():    avg word perp:   7.03
2017-12-03 07:54:16,326:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 07:54:16,326:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:55:22,970:train.py:199 -         run_log_save(): Batch 2056, epoch 20/20:
2017-12-03 07:55:22,971:train.py:200 -         run_log_save():    avg word perp:   6.90
2017-12-03 07:55:22,971:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 07:55:22,971:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:56:29,294:train.py:199 -         run_log_save(): Batch 2156, epoch 20/20:
2017-12-03 07:56:29,294:train.py:200 -         run_log_save():    avg word perp:   7.01
2017-12-03 07:56:29,294:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 07:56:29,294:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:57:36,104:train.py:199 -         run_log_save(): Batch 2256, epoch 20/20:
2017-12-03 07:57:36,104:train.py:200 -         run_log_save():    avg word perp:   7.14
2017-12-03 07:57:36,104:train.py:201 -         run_log_save():    acc trg words/s: 2433
2017-12-03 07:57:36,104:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:58:43,142:train.py:199 -         run_log_save(): Batch 2356, epoch 20/20:
2017-12-03 07:58:43,142:train.py:200 -         run_log_save():    avg word perp:   7.08
2017-12-03 07:58:43,142:train.py:201 -         run_log_save():    acc trg words/s: 2433
2017-12-03 07:58:43,142:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 07:59:49,729:train.py:199 -         run_log_save(): Batch 2456, epoch 20/20:
2017-12-03 07:59:49,729:train.py:200 -         run_log_save():    avg word perp:   6.95
2017-12-03 07:59:49,729:train.py:201 -         run_log_save():    acc trg words/s: 2433
2017-12-03 07:59:49,729:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 08:00:44,249:train.py:199 -         run_log_save(): Batch 2556, epoch 20/20:
2017-12-03 08:00:44,249:train.py:200 -         run_log_save():    avg word perp:   8.09
2017-12-03 08:00:44,249:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 08:00:44,249:train.py:202 -         run_log_save():    acc sec/batch:   0.66
2017-12-03 08:00:51,197:train.py:199 -         run_log_save(): Batch 2656, epoch 20/20:
2017-12-03 08:00:51,197:train.py:200 -         run_log_save():    avg word perp:   327.57
2017-12-03 08:00:51,197:train.py:201 -         run_log_save():    acc trg words/s: 2434
2017-12-03 08:00:51,197:train.py:202 -         run_log_save():    acc sec/batch:   0.63
2017-12-03 08:00:58,171:train.py:151 -         sample_input(): Sample input data:
2017-12-03 08:00:58,171:train.py:152 -         sample_input(): Src: Bildung
2017-12-03 08:00:58,171:train.py:153 -         sample_input(): Src len: 1
2017-12-03 08:00:58,171:train.py:154 -         sample_input(): Trg: _BOS formation _PAD
2017-12-03 08:00:58,171:train.py:155 -         sample_input(): Tar: formation _EOS _PAD
2017-12-03 08:00:58,171:train.py:156 -         sample_input(): W: 1.0 1.0 0.0
2017-12-03 08:00:58,171:train.py:199 -         run_log_save(): Batch 2756, epoch 20/20:
2017-12-03 08:00:58,171:train.py:200 -         run_log_save():    avg word perp:   283.41
2017-12-03 08:00:58,171:train.py:201 -         run_log_save():    acc trg words/s: 2433
2017-12-03 08:00:58,171:train.py:202 -         run_log_save():    acc sec/batch:   0.61
2017-12-03 08:01:01,664:train.py:207 -         run_log_save(): Save model to ./nmt/saved_models/de2en_bp/de2en_bp.cpkt, takes 0:00:03.492180
2017-12-03 08:01:08,740:train.py:199 -         run_log_save(): Batch 2856, epoch 20/20:
2017-12-03 08:01:08,740:train.py:200 -         run_log_save():    avg word perp:   285.90
2017-12-03 08:01:08,740:train.py:201 -         run_log_save():    acc trg words/s: 2433
2017-12-03 08:01:08,740:train.py:202 -         run_log_save():    acc sec/batch:   0.59
2017-12-03 08:01:15,707:train.py:199 -         run_log_save(): Batch 2956, epoch 20/20:
2017-12-03 08:01:15,707:train.py:200 -         run_log_save():    avg word perp:   271.39
2017-12-03 08:01:15,707:train.py:201 -         run_log_save():    acc trg words/s: 2433
2017-12-03 08:01:15,708:train.py:202 -         run_log_save():    acc sec/batch:   0.58
2017-12-03 08:01:22,655:train.py:199 -         run_log_save(): Batch 3056, epoch 20/20:
2017-12-03 08:01:22,655:train.py:200 -         run_log_save():    avg word perp:   265.65
2017-12-03 08:01:22,655:train.py:201 -         run_log_save():    acc trg words/s: 2433
2017-12-03 08:01:22,655:train.py:202 -         run_log_save():    acc sec/batch:   0.56
2017-12-03 08:01:29,515:train.py:199 -         run_log_save(): Batch 3156, epoch 20/20:
2017-12-03 08:01:29,515:train.py:200 -         run_log_save():    avg word perp:   268.87
2017-12-03 08:01:29,516:train.py:201 -         run_log_save():    acc trg words/s: 2433
2017-12-03 08:01:29,516:train.py:202 -         run_log_save():    acc sec/batch:   0.54
2017-12-03 08:01:36,489:train.py:199 -         run_log_save(): Batch 3256, epoch 20/20:
2017-12-03 08:01:36,489:train.py:200 -         run_log_save():    avg word perp:   263.00
2017-12-03 08:01:36,489:train.py:201 -         run_log_save():    acc trg words/s: 2432
2017-12-03 08:01:36,489:train.py:202 -         run_log_save():    acc sec/batch:   0.53
2017-12-03 08:01:37,868:train.py:119 -         report_epoch(): Finish epoch 20
2017-12-03 08:01:37,868:train.py:120 -         report_epoch():     It takes 0:28:47.236463
2017-12-03 08:01:37,868:train.py:121 -         report_epoch():     Avergage # words/second    2432.96102754
2017-12-03 08:01:37,868:train.py:122 -         report_epoch():     Average seconds/batch    0.527239457592
2017-12-03 08:01:37,868:train.py:133 -         report_epoch():     train perplexity: 7.73103371928
2017-12-03 08:01:37,868:train.py:101 -                train(): It is finally done, mate!
2017-12-03 08:01:37,868:train.py:102 -                train(): Train perplexities:
2017-12-03 08:01:37,869:train.py:103 -                train(): 170.408071362, 48.946551528, 30.4926977636, 22.9261760494, 18.8271321047, 16.2675811444, 14.4353549231, 13.1018846286, 12.096572879, 11.3017257256, 10.659552814, 10.1229238387, 9.65236745851, 9.26055687148, 8.92099559149, 8.63576675732, 8.36100867842, 8.13621021773, 7.92138931778, 7.73103371928
2017-12-03 08:01:37,869:train.py:106 -                train(): Save final checkpoint
2017-12-03 08:01:41,274:train.py:111 -                train(): Evaluate on test
2017-12-03 08:01:41,275:train.py:114 -                train(): Restore best cpkt from ./nmt/saved_models/de2en_bp/de2en_bp-14.72.cpkt
2017-12-03 08:02:35,787:validator.py:143 -             evaluate():   Translating line 100, average 0.542939579487 seconds/sent
2017-12-03 08:03:37,767:validator.py:143 -             evaluate():   Translating line 200, average 0.581369695663 seconds/sent
2017-12-03 08:04:41,061:validator.py:143 -             evaluate():   Translating line 300, average 0.598559947014 seconds/sent
2017-12-03 08:05:46,422:validator.py:143 -             evaluate():   Translating line 400, average 0.612321360111 seconds/sent
2017-12-03 08:06:43,234:validator.py:143 -             evaluate():   Translating line 500, average 0.603481610298 seconds/sent
2017-12-03 08:07:54,020:validator.py:143 -             evaluate():   Translating line 600, average 0.620877590179 seconds/sent
2017-12-03 08:08:48,910:validator.py:143 -             evaluate():   Translating line 700, average 0.610595151356 seconds/sent
2017-12-03 08:09:40,231:validator.py:143 -             evaluate():   Translating line 800, average 0.598421636224 seconds/sent
2017-12-03 08:10:44,044:validator.py:143 -             evaluate():   Translating line 900, average 0.602834448814 seconds/sent
2017-12-03 08:11:33,854:validator.py:143 -             evaluate():   Translating line 1000, average 0.592360724926 seconds/sent
2017-12-03 08:12:33,102:validator.py:143 -             evaluate():   Translating line 1100, average 0.592371806448 seconds/sent
2017-12-03 08:13:37,255:validator.py:143 -             evaluate():   Translating line 1200, average 0.596467642585 seconds/sent
2017-12-03 08:14:33,874:validator.py:143 -             evaluate():   Translating line 1300, average 0.594138839245 seconds/sent
2017-12-03 08:15:26,182:validator.py:143 -             evaluate():   Translating line 1400, average 0.589063343661 seconds/sent
2017-12-03 08:16:18,777:validator.py:143 -             evaluate():   Translating line 1500, average 0.584855425994 seconds/sent
2017-12-03 08:17:28,862:validator.py:143 -             evaluate():   Translating line 1600, average 0.592105611861 seconds/sent
2017-12-03 08:18:30,544:validator.py:143 -             evaluate():   Translating line 1700, average 0.593559111848 seconds/sent
2017-12-03 08:19:30,590:validator.py:143 -             evaluate():   Translating line 1800, average 0.593942608303 seconds/sent
2017-12-03 08:20:25,728:validator.py:143 -             evaluate():   Translating line 1900, average 0.591702543183 seconds/sent
2017-12-03 08:21:21,140:validator.py:143 -             evaluate():   Translating line 2000, average 0.589823256016 seconds/sent
2017-12-03 08:22:19,554:validator.py:143 -             evaluate():   Translating line 2100, average 0.589552747181 seconds/sent
2017-12-03 08:23:20,643:validator.py:143 -             evaluate():   Translating line 2200, average 0.590522457795 seconds/sent
2017-12-03 08:24:18,770:validator.py:143 -             evaluate():   Translating line 2300, average 0.590120128238 seconds/sent
2017-12-03 08:25:26,721:validator.py:143 -             evaluate():   Translating line 2400, average 0.593844635884 seconds/sent
2017-12-03 08:26:22,761:validator.py:143 -             evaluate():   Translating line 2500, average 0.592507020378 seconds/sent
2017-12-03 08:27:41,845:validator.py:143 -             evaluate():   Translating line 2600, average 0.600135063483 seconds/sent
2017-12-03 08:28:43,518:validator.py:143 -             evaluate():   Translating line 2700, average 0.600749706339 seconds/sent
2017-12-03 08:28:54,791:validator.py:152 -             evaluate(): Done translating.
2017-12-03 08:28:54,791:validator.py:153 -             evaluate(): dev perplexity: 92.265
2017-12-03 08:28:55,444:validator.py:159 -             evaluate(): BLEU = 11.84, 37.1/15.7/7.9/4.2 (BP=1.000, ratio=1.182, hyp_len=67201, ref_len=56852)

2017-12-03 08:28:55,444:validator.py:160 -             evaluate(): Validation took: 27.2325146834 minutes
