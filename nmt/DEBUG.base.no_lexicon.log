2017-11-29 19:21:32,560:data_manager.py:95 - parallel_filter_long_sentences(): Filter ./nmt/data/de2en/train.de & ./nmt/data/de2en/train.en by length 50 & 50
2017-11-29 19:21:40,931:data_manager.py:123 -        create_vocabs(): Create vocabulary for de with size 36616 from ./nmt/data/de2en/train.de.clean-50
2017-11-29 19:21:41,396:data_manager.py:134 -        create_vocabs():    processing line 10000
2017-11-29 19:21:41,875:data_manager.py:134 -        create_vocabs():    processing line 20000
2017-11-29 19:21:42,353:data_manager.py:134 -        create_vocabs():    processing line 30000
2017-11-29 19:21:42,826:data_manager.py:134 -        create_vocabs():    processing line 40000
2017-11-29 19:21:43,308:data_manager.py:134 -        create_vocabs():    processing line 50000
2017-11-29 19:21:43,785:data_manager.py:134 -        create_vocabs():    processing line 60000
2017-11-29 19:21:44,263:data_manager.py:134 -        create_vocabs():    processing line 70000
2017-11-29 19:21:44,735:data_manager.py:134 -        create_vocabs():    processing line 80000
2017-11-29 19:21:45,203:data_manager.py:134 -        create_vocabs():    processing line 90000
2017-11-29 19:21:45,674:data_manager.py:134 -        create_vocabs():    processing line 100000
2017-11-29 19:21:46,149:data_manager.py:134 -        create_vocabs():    processing line 110000
2017-11-29 19:21:46,627:data_manager.py:134 -        create_vocabs():    processing line 120000
2017-11-29 19:21:47,106:data_manager.py:134 -        create_vocabs():    processing line 130000
2017-11-29 19:21:47,583:data_manager.py:134 -        create_vocabs():    processing line 140000
2017-11-29 19:21:48,072:data_manager.py:134 -        create_vocabs():    processing line 150000
2017-11-29 19:21:48,554:data_manager.py:134 -        create_vocabs():    processing line 160000
2017-11-29 19:21:48,972:data_manager.py:123 -        create_vocabs(): Create vocabulary for en with size 23262 from ./nmt/data/de2en/train.en.clean-50
2017-11-29 19:21:49,400:data_manager.py:134 -        create_vocabs():    processing line 10000
2017-11-29 19:21:49,835:data_manager.py:134 -        create_vocabs():    processing line 20000
2017-11-29 19:21:50,266:data_manager.py:134 -        create_vocabs():    processing line 30000
2017-11-29 19:21:50,691:data_manager.py:134 -        create_vocabs():    processing line 40000
2017-11-29 19:21:51,127:data_manager.py:134 -        create_vocabs():    processing line 50000
2017-11-29 19:21:51,571:data_manager.py:134 -        create_vocabs():    processing line 60000
2017-11-29 19:21:52,016:data_manager.py:134 -        create_vocabs():    processing line 70000
2017-11-29 19:21:52,455:data_manager.py:134 -        create_vocabs():    processing line 80000
2017-11-29 19:21:52,898:data_manager.py:134 -        create_vocabs():    processing line 90000
2017-11-29 19:21:53,338:data_manager.py:134 -        create_vocabs():    processing line 100000
2017-11-29 19:21:53,768:data_manager.py:134 -        create_vocabs():    processing line 110000
2017-11-29 19:21:54,214:data_manager.py:134 -        create_vocabs():    processing line 120000
2017-11-29 19:21:54,656:data_manager.py:134 -        create_vocabs():    processing line 130000
2017-11-29 19:21:55,089:data_manager.py:134 -        create_vocabs():    processing line 140000
2017-11-29 19:21:55,529:data_manager.py:134 -        create_vocabs():    processing line 150000
2017-11-29 19:21:55,966:data_manager.py:134 -        create_vocabs():    processing line 160000
2017-11-29 19:21:56,260:data_manager.py:158 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en/vocab-36616.de
2017-11-29 19:21:56,429:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 19:21:56,540:data_manager.py:192 - parallel_data_to_token_ids(): Parallel convert tokens from ./nmt/data/de2en/train.de.clean-50 & ./nmt/data/de2en/train.en.clean-50 to ids and save to ./nmt/data/de2en/train.ids
Also save the total data length to ./nmt/data/de2en/train.length
2017-11-29 19:21:57,644:data_manager.py:212 - parallel_data_to_token_ids():     converting line 10000
2017-11-29 19:21:58,801:data_manager.py:212 - parallel_data_to_token_ids():     converting line 20000
2017-11-29 19:21:59,952:data_manager.py:212 - parallel_data_to_token_ids():     converting line 30000
2017-11-29 19:22:01,098:data_manager.py:212 - parallel_data_to_token_ids():     converting line 40000
2017-11-29 19:22:02,239:data_manager.py:212 - parallel_data_to_token_ids():     converting line 50000
2017-11-29 19:22:03,407:data_manager.py:212 - parallel_data_to_token_ids():     converting line 60000
2017-11-29 19:22:04,573:data_manager.py:212 - parallel_data_to_token_ids():     converting line 70000
2017-11-29 19:22:05,720:data_manager.py:212 - parallel_data_to_token_ids():     converting line 80000
2017-11-29 19:22:06,888:data_manager.py:212 - parallel_data_to_token_ids():     converting line 90000
2017-11-29 19:22:08,018:data_manager.py:212 - parallel_data_to_token_ids():     converting line 100000
2017-11-29 19:22:09,156:data_manager.py:212 - parallel_data_to_token_ids():     converting line 110000
2017-11-29 19:22:10,281:data_manager.py:212 - parallel_data_to_token_ids():     converting line 120000
2017-11-29 19:22:11,374:data_manager.py:212 - parallel_data_to_token_ids():     converting line 130000
2017-11-29 19:22:12,516:data_manager.py:212 - parallel_data_to_token_ids():     converting line 140000
2017-11-29 19:22:13,534:data_manager.py:212 - parallel_data_to_token_ids():     converting line 150000
2017-11-29 19:22:14,669:data_manager.py:212 - parallel_data_to_token_ids():     converting line 160000
2017-11-29 19:22:15,251:data_manager.py:158 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en/vocab-36616.de
2017-11-29 19:22:15,483:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 19:22:15,587:data_manager.py:192 - parallel_data_to_token_ids(): Parallel convert tokens from ./nmt/data/de2en/dev.de & ./nmt/data/de2en/dev.en to ids and save to ./nmt/data/de2en/dev.ids
Also save the total data length to ./nmt/data/de2en/dev.length
2017-11-29 19:22:15,799:data_manager.py:158 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en/vocab-36616.de
2017-11-29 19:22:15,961:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 19:22:16,138:data_manager.py:192 - parallel_data_to_token_ids(): Parallel convert tokens from ./nmt/data/de2en/test.de & ./nmt/data/de2en/test.en to ids and save to ./nmt/data/de2en/test.ids
Also save the total data length to ./nmt/data/de2en/test.length
2017-11-29 19:22:16,425:validator.py:23 -             __init__(): Initializing validator
2017-11-29 19:22:16,426:train.py:43 -             __init__(): Evaluate every 126 batches
2017-11-29 19:22:16,426:data_manager.py:158 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en/vocab-36616.de
2017-11-29 19:22:16,593:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 19:22:18,461:model.py:165 -             __init__(): train model:
2017-11-29 19:22:18,461:model.py:166 -             __init__(): Num trainable variables 12
2017-11-29 19:22:18,461:model.py:167 -             __init__(): Num params: 35,062,886
2017-11-29 19:22:18,461:model.py:168 -             __init__(): List of all trainable parameters:
2017-11-29 19:22:18,461:model.py:170 -             __init__():    de2en/encoder/embedding:0
2017-11-29 19:22:18,461:model.py:170 -             __init__():    de2en/decoder/embedding:0
2017-11-29 19:22:18,461:model.py:170 -             __init__():    de2en/outputer/W:0
2017-11-29 19:22:18,461:model.py:170 -             __init__():    de2en/outputer/b:0
2017-11-29 19:22:18,461:model.py:170 -             __init__():    de2en/softmax/W:0
2017-11-29 19:22:18,461:model.py:170 -             __init__():    de2en/softmax/b:0
2017-11-29 19:22:18,461:model.py:170 -             __init__():    de2en/encoder/lstm_cell/kernel:0
2017-11-29 19:22:18,461:model.py:170 -             __init__():    de2en/encoder/lstm_cell/bias:0
2017-11-29 19:22:18,461:model.py:170 -             __init__():    de2en/attention/W:0
2017-11-29 19:22:18,461:model.py:170 -             __init__():    de2en/attention/b:0
2017-11-29 19:22:18,462:model.py:170 -             __init__():    de2en/decoder/lstm_cell/kernel:0
2017-11-29 19:22:18,462:model.py:170 -             __init__():    de2en/decoder/lstm_cell/bias:0
2017-11-29 19:22:22,411:train.py:88 -                train(): Set learning rate to 1.0
2017-11-29 19:22:23,091:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.601613998413 seconds
2017-11-29 19:22:58,734:train.py:188 -         run_log_save(): Batch 100, epoch 1/20:
2017-11-29 19:22:58,734:train.py:189 -         run_log_save():    avg word perp:   1595.58
2017-11-29 19:22:58,734:train.py:190 -         run_log_save():    acc trg words/s: 4585
2017-11-29 19:22:58,734:train.py:191 -         run_log_save():    acc sec/batch:   0.35
2017-11-29 19:23:07,054:validator.py:225 -    validate_and_save(): Start validation
2017-11-29 19:23:07,054:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 19:25:30,130:validator.py:144 -             evaluate():   Translating line 100, average 1.42964134932 seconds/sent
2017-11-29 19:27:48,470:validator.py:144 -             evaluate():   Translating line 200, average 1.40651781917 seconds/sent
2017-11-29 19:29:45,710:validator.py:144 -             evaluate():   Translating line 300, average 1.32847972631 seconds/sent
2017-11-29 19:33:15,795:data_manager.py:95 - parallel_filter_long_sentences(): Filter ./nmt/data/de2en/train.de & ./nmt/data/de2en/train.en by length 50 & 50
2017-11-29 19:33:15,847:data_manager.py:98 - parallel_filter_long_sentences():     Length-filtered files exist at ./nmt/data/de2en/train.de.clean-50 & ./nmt/data/de2en/train.en.clean-50
2017-11-29 19:33:15,847:data_manager.py:123 -        create_vocabs(): Create vocabulary for de with size 36616 from ./nmt/data/de2en/train.de.clean-50
2017-11-29 19:33:15,847:data_manager.py:125 -        create_vocabs():     Vocabulary for data ./nmt/data/de2en/train.de.clean-50 exists at ./nmt/data/de2en/vocab-36616.de
2017-11-29 19:33:15,847:data_manager.py:123 -        create_vocabs(): Create vocabulary for en with size 23262 from ./nmt/data/de2en/train.en.clean-50
2017-11-29 19:33:15,847:data_manager.py:125 -        create_vocabs():     Vocabulary for data ./nmt/data/de2en/train.en.clean-50 exists at ./nmt/data/de2en/vocab-23262.en
2017-11-29 19:33:15,847:data_manager.py:158 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en/vocab-36616.de
2017-11-29 19:33:15,963:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 19:33:16,033:data_manager.py:192 - parallel_data_to_token_ids(): Parallel convert tokens from ./nmt/data/de2en/train.de.clean-50 & ./nmt/data/de2en/train.en.clean-50 to ids and save to ./nmt/data/de2en/train.ids
Also save the total data length to ./nmt/data/de2en/train.length
2017-11-29 19:33:16,033:data_manager.py:195 - parallel_data_to_token_ids():     Token-id-ed data exists at ./nmt/data/de2en/train.ids
2017-11-29 19:33:16,038:data_manager.py:158 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en/vocab-36616.de
2017-11-29 19:33:16,154:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 19:33:16,204:data_manager.py:192 - parallel_data_to_token_ids(): Parallel convert tokens from ./nmt/data/de2en/dev.de & ./nmt/data/de2en/dev.en to ids and save to ./nmt/data/de2en/dev.ids
Also save the total data length to ./nmt/data/de2en/dev.length
2017-11-29 19:33:16,204:data_manager.py:195 - parallel_data_to_token_ids():     Token-id-ed data exists at ./nmt/data/de2en/dev.ids
2017-11-29 19:33:16,209:data_manager.py:158 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en/vocab-36616.de
2017-11-29 19:33:16,290:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 19:33:16,341:data_manager.py:192 - parallel_data_to_token_ids(): Parallel convert tokens from ./nmt/data/de2en/test.de & ./nmt/data/de2en/test.en to ids and save to ./nmt/data/de2en/test.ids
Also save the total data length to ./nmt/data/de2en/test.length
2017-11-29 19:33:16,341:data_manager.py:195 - parallel_data_to_token_ids():     Token-id-ed data exists at ./nmt/data/de2en/test.ids
2017-11-29 19:33:16,346:validator.py:23 -             __init__(): Initializing validator
2017-11-29 19:33:16,452:train.py:43 -             __init__(): Evaluate every 0 batches
2017-11-29 19:33:16,452:data_manager.py:158 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en/vocab-36616.de
2017-11-29 19:33:16,569:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 19:33:17,808:model.py:165 -             __init__(): train model:
2017-11-29 19:33:17,810:model.py:166 -             __init__(): Num trainable variables 12
2017-11-29 19:33:17,810:model.py:167 -             __init__(): Num params: 35,062,886
2017-11-29 19:33:17,810:model.py:168 -             __init__(): List of all trainable parameters:
2017-11-29 19:33:17,810:model.py:170 -             __init__():    de2en/encoder/embedding:0
2017-11-29 19:33:17,810:model.py:170 -             __init__():    de2en/decoder/embedding:0
2017-11-29 19:33:17,810:model.py:170 -             __init__():    de2en/outputer/W:0
2017-11-29 19:33:17,810:model.py:170 -             __init__():    de2en/outputer/b:0
2017-11-29 19:33:17,810:model.py:170 -             __init__():    de2en/softmax/W:0
2017-11-29 19:33:17,811:model.py:170 -             __init__():    de2en/softmax/b:0
2017-11-29 19:33:17,811:model.py:170 -             __init__():    de2en/encoder/lstm_cell/kernel:0
2017-11-29 19:33:17,811:model.py:170 -             __init__():    de2en/encoder/lstm_cell/bias:0
2017-11-29 19:33:17,811:model.py:170 -             __init__():    de2en/attention/W:0
2017-11-29 19:33:17,811:model.py:170 -             __init__():    de2en/attention/b:0
2017-11-29 19:33:17,811:model.py:170 -             __init__():    de2en/decoder/lstm_cell/kernel:0
2017-11-29 19:33:17,811:model.py:170 -             __init__():    de2en/decoder/lstm_cell/bias:0
2017-11-29 19:33:35,826:train.py:88 -                train(): Set learning rate to 1.0
2017-11-29 19:33:37,024:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 1.10064506531 seconds
2017-11-29 19:38:46,474:data_manager.py:95 - parallel_filter_long_sentences(): Filter ./nmt/data/de2en/train.de & ./nmt/data/de2en/train.en by length 50 & 50
2017-11-29 19:38:46,474:data_manager.py:98 - parallel_filter_long_sentences():     Length-filtered files exist at ./nmt/data/de2en/train.de.clean-50 & ./nmt/data/de2en/train.en.clean-50
2017-11-29 19:38:46,474:data_manager.py:123 -        create_vocabs(): Create vocabulary for de with size 36616 from ./nmt/data/de2en/train.de.clean-50
2017-11-29 19:38:46,474:data_manager.py:125 -        create_vocabs():     Vocabulary for data ./nmt/data/de2en/train.de.clean-50 exists at ./nmt/data/de2en/vocab-36616.de
2017-11-29 19:38:46,474:data_manager.py:123 -        create_vocabs(): Create vocabulary for en with size 23262 from ./nmt/data/de2en/train.en.clean-50
2017-11-29 19:38:46,474:data_manager.py:125 -        create_vocabs():     Vocabulary for data ./nmt/data/de2en/train.en.clean-50 exists at ./nmt/data/de2en/vocab-23262.en
2017-11-29 19:38:46,474:data_manager.py:158 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en/vocab-36616.de
2017-11-29 19:38:46,557:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 19:38:46,608:data_manager.py:192 - parallel_data_to_token_ids(): Parallel convert tokens from ./nmt/data/de2en/train.de.clean-50 & ./nmt/data/de2en/train.en.clean-50 to ids and save to ./nmt/data/de2en/train.ids
Also save the total data length to ./nmt/data/de2en/train.length
2017-11-29 19:38:46,609:data_manager.py:195 - parallel_data_to_token_ids():     Token-id-ed data exists at ./nmt/data/de2en/train.ids
2017-11-29 19:38:46,613:data_manager.py:158 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en/vocab-36616.de
2017-11-29 19:38:46,725:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 19:38:46,776:data_manager.py:192 - parallel_data_to_token_ids(): Parallel convert tokens from ./nmt/data/de2en/dev.de & ./nmt/data/de2en/dev.en to ids and save to ./nmt/data/de2en/dev.ids
Also save the total data length to ./nmt/data/de2en/dev.length
2017-11-29 19:38:46,776:data_manager.py:195 - parallel_data_to_token_ids():     Token-id-ed data exists at ./nmt/data/de2en/dev.ids
2017-11-29 19:38:46,781:data_manager.py:158 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en/vocab-36616.de
2017-11-29 19:38:46,860:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 19:38:46,912:data_manager.py:192 - parallel_data_to_token_ids(): Parallel convert tokens from ./nmt/data/de2en/test.de & ./nmt/data/de2en/test.en to ids and save to ./nmt/data/de2en/test.ids
Also save the total data length to ./nmt/data/de2en/test.length
2017-11-29 19:38:46,912:data_manager.py:195 - parallel_data_to_token_ids():     Token-id-ed data exists at ./nmt/data/de2en/test.ids
2017-11-29 19:38:46,917:validator.py:23 -             __init__(): Initializing validator
2017-11-29 19:38:46,917:train.py:43 -             __init__(): Evaluate every 5000 batches
2017-11-29 19:38:46,917:data_manager.py:158 -           init_vocab(): Initialize de vocab from ./nmt/data/de2en/vocab-36616.de
2017-11-29 19:38:47,032:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 19:38:48,000:model.py:165 -             __init__(): train model:
2017-11-29 19:38:48,000:model.py:166 -             __init__(): Num trainable variables 12
2017-11-29 19:38:48,000:model.py:167 -             __init__(): Num params: 35,062,886
2017-11-29 19:38:48,000:model.py:168 -             __init__(): List of all trainable parameters:
2017-11-29 19:38:48,000:model.py:170 -             __init__():    de2en/encoder/embedding:0
2017-11-29 19:38:48,000:model.py:170 -             __init__():    de2en/decoder/embedding:0
2017-11-29 19:38:48,000:model.py:170 -             __init__():    de2en/outputer/W:0
2017-11-29 19:38:48,000:model.py:170 -             __init__():    de2en/outputer/b:0
2017-11-29 19:38:48,000:model.py:170 -             __init__():    de2en/softmax/W:0
2017-11-29 19:38:48,000:model.py:170 -             __init__():    de2en/softmax/b:0
2017-11-29 19:38:48,000:model.py:170 -             __init__():    de2en/encoder/lstm_cell/kernel:0
2017-11-29 19:38:48,000:model.py:170 -             __init__():    de2en/encoder/lstm_cell/bias:0
2017-11-29 19:38:48,000:model.py:170 -             __init__():    de2en/attention/W:0
2017-11-29 19:38:48,000:model.py:170 -             __init__():    de2en/attention/b:0
2017-11-29 19:38:48,000:model.py:170 -             __init__():    de2en/decoder/lstm_cell/kernel:0
2017-11-29 19:38:48,001:model.py:170 -             __init__():    de2en/decoder/lstm_cell/bias:0
2017-11-29 19:38:50,374:train.py:88 -                train(): Set learning rate to 1.0
2017-11-29 19:38:50,856:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.404557943344 seconds
2017-11-29 19:39:20,854:train.py:188 -         run_log_save(): Batch 100, epoch 1/20:
2017-11-29 19:39:20,854:train.py:189 -         run_log_save():    avg word perp:   1591.52
2017-11-29 19:39:20,854:train.py:190 -         run_log_save():    acc trg words/s: 5439
2017-11-29 19:39:20,854:train.py:191 -         run_log_save():    acc sec/batch:   0.30
2017-11-29 19:39:50,270:train.py:188 -         run_log_save(): Batch 200, epoch 1/20:
2017-11-29 19:39:50,270:train.py:189 -         run_log_save():    avg word perp:   1045.70
2017-11-29 19:39:50,270:train.py:190 -         run_log_save():    acc trg words/s: 5482
2017-11-29 19:39:50,270:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:40:20,883:train.py:188 -         run_log_save(): Batch 300, epoch 1/20:
2017-11-29 19:40:20,883:train.py:189 -         run_log_save():    avg word perp:   866.46
2017-11-29 19:40:20,883:train.py:190 -         run_log_save():    acc trg words/s: 5431
2017-11-29 19:40:20,883:train.py:191 -         run_log_save():    acc sec/batch:   0.30
2017-11-29 19:40:50,516:train.py:188 -         run_log_save(): Batch 400, epoch 1/20:
2017-11-29 19:40:50,516:train.py:189 -         run_log_save():    avg word perp:   715.52
2017-11-29 19:40:50,516:train.py:190 -         run_log_save():    acc trg words/s: 5429
2017-11-29 19:40:50,516:train.py:191 -         run_log_save():    acc sec/batch:   0.30
2017-11-29 19:41:20,239:train.py:188 -         run_log_save(): Batch 500, epoch 1/20:
2017-11-29 19:41:20,240:train.py:189 -         run_log_save():    avg word perp:   617.97
2017-11-29 19:41:20,240:train.py:190 -         run_log_save():    acc trg words/s: 5441
2017-11-29 19:41:20,240:train.py:191 -         run_log_save():    acc sec/batch:   0.30
2017-11-29 19:41:49,724:train.py:188 -         run_log_save(): Batch 600, epoch 1/20:
2017-11-29 19:41:49,724:train.py:189 -         run_log_save():    avg word perp:   548.72
2017-11-29 19:41:49,724:train.py:190 -         run_log_save():    acc trg words/s: 5448
2017-11-29 19:41:49,724:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:42:19,450:train.py:188 -         run_log_save(): Batch 700, epoch 1/20:
2017-11-29 19:42:19,450:train.py:189 -         run_log_save():    avg word perp:   493.92
2017-11-29 19:42:19,450:train.py:190 -         run_log_save():    acc trg words/s: 5451
2017-11-29 19:42:19,451:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:42:49,218:train.py:188 -         run_log_save(): Batch 800, epoch 1/20:
2017-11-29 19:42:49,218:train.py:189 -         run_log_save():    avg word perp:   458.00
2017-11-29 19:42:49,218:train.py:190 -         run_log_save():    acc trg words/s: 5457
2017-11-29 19:42:49,219:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:43:18,544:train.py:188 -         run_log_save(): Batch 900, epoch 1/20:
2017-11-29 19:43:18,544:train.py:189 -         run_log_save():    avg word perp:   428.16
2017-11-29 19:43:18,544:train.py:190 -         run_log_save():    acc trg words/s: 5464
2017-11-29 19:43:18,544:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:43:48,503:train.py:148 -         sample_input(): Sample input data:
2017-11-29 19:43:48,503:train.py:149 -         sample_input(): Src: ; nbsp &amp; . könnte werden geschaffen Militärpräsenz chinesische eine für brett ung@@ Spr@@ ein damit dass , fürchtet man weil , werden blockiert spläne Investition@@ manche dass so , Paranoia lokale Ausmaß eres schi@@ ihr durch schüren Firmen chinesischer käufe Land@@ die und _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 19:43:48,503:train.py:150 -         sample_input(): Src len: 44
2017-11-29 19:43:48,503:train.py:151 -         sample_input(): Trg: _BOS and Chinese companies &quot; land purchases in Iceland have been so extensive as to fuel local paranoia , with some investment plans blocked for fear that they might be a stepping @-@ stone to a Chinese military presence . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 19:43:48,503:train.py:152 -         sample_input(): Tar: and Chinese companies &quot; land purchases in Iceland have been so extensive as to fuel local paranoia , with some investment plans blocked for fear that they might be a stepping @-@ stone to a Chinese military presence . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 19:43:48,503:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 19:43:48,503:train.py:188 -         run_log_save(): Batch 1000, epoch 1/20:
2017-11-29 19:43:48,503:train.py:189 -         run_log_save():    avg word perp:   400.04
2017-11-29 19:43:48,503:train.py:190 -         run_log_save():    acc trg words/s: 5467
2017-11-29 19:43:48,503:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:44:18,239:train.py:188 -         run_log_save(): Batch 1100, epoch 1/20:
2017-11-29 19:44:18,239:train.py:189 -         run_log_save():    avg word perp:   373.97
2017-11-29 19:44:18,239:train.py:190 -         run_log_save():    acc trg words/s: 5469
2017-11-29 19:44:18,239:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:44:47,970:train.py:188 -         run_log_save(): Batch 1200, epoch 1/20:
2017-11-29 19:44:47,970:train.py:189 -         run_log_save():    avg word perp:   352.79
2017-11-29 19:44:47,970:train.py:190 -         run_log_save():    acc trg words/s: 5470
2017-11-29 19:44:47,970:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:45:17,854:train.py:188 -         run_log_save(): Batch 1300, epoch 1/20:
2017-11-29 19:45:17,854:train.py:189 -         run_log_save():    avg word perp:   336.12
2017-11-29 19:45:17,854:train.py:190 -         run_log_save():    acc trg words/s: 5472
2017-11-29 19:45:17,854:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:45:47,024:train.py:188 -         run_log_save(): Batch 1400, epoch 1/20:
2017-11-29 19:45:47,024:train.py:189 -         run_log_save():    avg word perp:   315.27
2017-11-29 19:45:47,024:train.py:190 -         run_log_save():    acc trg words/s: 5473
2017-11-29 19:45:47,024:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:46:16,487:train.py:188 -         run_log_save(): Batch 1500, epoch 1/20:
2017-11-29 19:46:16,487:train.py:189 -         run_log_save():    avg word perp:   306.85
2017-11-29 19:46:16,488:train.py:190 -         run_log_save():    acc trg words/s: 5477
2017-11-29 19:46:16,488:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:46:45,969:train.py:188 -         run_log_save(): Batch 1600, epoch 1/20:
2017-11-29 19:46:45,969:train.py:189 -         run_log_save():    avg word perp:   295.73
2017-11-29 19:46:45,969:train.py:190 -         run_log_save():    acc trg words/s: 5479
2017-11-29 19:46:45,969:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:47:16,101:train.py:188 -         run_log_save(): Batch 1700, epoch 1/20:
2017-11-29 19:47:16,101:train.py:189 -         run_log_save():    avg word perp:   278.22
2017-11-29 19:47:16,101:train.py:190 -         run_log_save():    acc trg words/s: 5476
2017-11-29 19:47:16,101:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:47:45,687:train.py:188 -         run_log_save(): Batch 1800, epoch 1/20:
2017-11-29 19:47:45,688:train.py:189 -         run_log_save():    avg word perp:   270.45
2017-11-29 19:47:45,688:train.py:190 -         run_log_save():    acc trg words/s: 5480
2017-11-29 19:47:45,688:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:48:15,147:train.py:188 -         run_log_save(): Batch 1900, epoch 1/20:
2017-11-29 19:48:15,147:train.py:189 -         run_log_save():    avg word perp:   262.15
2017-11-29 19:48:15,147:train.py:190 -         run_log_save():    acc trg words/s: 5479
2017-11-29 19:48:15,147:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:48:44,777:train.py:148 -         sample_input(): Sample input data:
2017-11-29 19:48:44,778:train.py:149 -         sample_input(): Src: . sein Platz noch wird Kernenergie die für auch und , haben x emi@@ Energi@@ am Anteil großen einen werden Biokraftstoffe und Wasserkraft , Windenergie und - Sonnen@@ wie Energien Alternative . heute als aussehen anders völlig Welt der Energieversorgung die wird 2100 Jahr im _PAD _PAD _PAD _PAD _PAD
2017-11-29 19:48:44,778:train.py:150 -         sample_input(): Src len: 45
2017-11-29 19:48:44,778:train.py:151 -         sample_input(): Trg: _BOS by 2100 , the world &apos;s energy system will be radically different from today &apos;s . renewable energy like solar , wind , hydro@@ electricity , and biofuels will make up a large share of the energy mix , and nuclear energy , too , will have a place .
2017-11-29 19:48:44,778:train.py:152 -         sample_input(): Tar: by 2100 , the world &apos;s energy system will be radically different from today &apos;s . renewable energy like solar , wind , hydro@@ electricity , and biofuels will make up a large share of the energy mix , and nuclear energy , too , will have a place . _EOS
2017-11-29 19:48:44,778:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0
2017-11-29 19:48:44,778:train.py:188 -         run_log_save(): Batch 2000, epoch 1/20:
2017-11-29 19:48:44,778:train.py:189 -         run_log_save():    avg word perp:   256.62
2017-11-29 19:48:44,778:train.py:190 -         run_log_save():    acc trg words/s: 5482
2017-11-29 19:48:44,778:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:48:45,351:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:00.572767
2017-11-29 19:49:14,732:train.py:188 -         run_log_save(): Batch 2100, epoch 1/20:
2017-11-29 19:49:14,732:train.py:189 -         run_log_save():    avg word perp:   245.54
2017-11-29 19:49:14,732:train.py:190 -         run_log_save():    acc trg words/s: 5484
2017-11-29 19:49:14,732:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:49:44,130:train.py:188 -         run_log_save(): Batch 2200, epoch 1/20:
2017-11-29 19:49:44,130:train.py:189 -         run_log_save():    avg word perp:   241.73
2017-11-29 19:49:44,130:train.py:190 -         run_log_save():    acc trg words/s: 5486
2017-11-29 19:49:44,130:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:50:13,294:train.py:188 -         run_log_save(): Batch 2300, epoch 1/20:
2017-11-29 19:50:13,295:train.py:189 -         run_log_save():    avg word perp:   227.90
2017-11-29 19:50:13,295:train.py:190 -         run_log_save():    acc trg words/s: 5490
2017-11-29 19:50:13,295:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:50:42,655:train.py:188 -         run_log_save(): Batch 2400, epoch 1/20:
2017-11-29 19:50:42,655:train.py:189 -         run_log_save():    avg word perp:   222.24
2017-11-29 19:50:42,655:train.py:190 -         run_log_save():    acc trg words/s: 5492
2017-11-29 19:50:42,656:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:51:12,330:train.py:188 -         run_log_save(): Batch 2500, epoch 1/20:
2017-11-29 19:51:12,331:train.py:189 -         run_log_save():    avg word perp:   219.44
2017-11-29 19:51:12,331:train.py:190 -         run_log_save():    acc trg words/s: 5492
2017-11-29 19:51:12,331:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:51:22,488:train.py:116 -         report_epoch(): Finish epoch 1
2017-11-29 19:51:22,488:train.py:117 -         report_epoch():     It takes 0:12:23.118669
2017-11-29 19:51:22,488:train.py:118 -         report_epoch():     Avergage # words/second    5491.38808021
2017-11-29 19:51:22,488:train.py:119 -         report_epoch():     Average seconds/batch    0.293143459091
2017-11-29 19:51:22,488:train.py:130 -         report_epoch():     train perplexity: 386.143510061
2017-11-29 19:51:22,937:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.44872713089 seconds
2017-11-29 19:51:41,678:train.py:188 -         run_log_save(): Batch 65, epoch 2/20:
2017-11-29 19:51:41,678:train.py:189 -         run_log_save():    avg word perp:   207.95
2017-11-29 19:51:41,678:train.py:190 -         run_log_save():    acc trg words/s: 5428
2017-11-29 19:51:41,678:train.py:191 -         run_log_save():    acc sec/batch:   0.28
2017-11-29 19:52:11,612:train.py:188 -         run_log_save(): Batch 165, epoch 2/20:
2017-11-29 19:52:11,613:train.py:189 -         run_log_save():    avg word perp:   207.05
2017-11-29 19:52:11,613:train.py:190 -         run_log_save():    acc trg words/s: 5461
2017-11-29 19:52:11,613:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:52:41,036:train.py:188 -         run_log_save(): Batch 265, epoch 2/20:
2017-11-29 19:52:41,037:train.py:189 -         run_log_save():    avg word perp:   203.50
2017-11-29 19:52:41,037:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-29 19:52:41,037:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:53:10,333:train.py:188 -         run_log_save(): Batch 365, epoch 2/20:
2017-11-29 19:53:10,333:train.py:189 -         run_log_save():    avg word perp:   194.49
2017-11-29 19:53:10,333:train.py:190 -         run_log_save():    acc trg words/s: 5516
2017-11-29 19:53:10,333:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:53:39,509:train.py:148 -         sample_input(): Sample input data:
2017-11-29 19:53:39,509:train.py:149 -         sample_input(): Src: . spürbar Länder dieser systemen Bildungs@@ den in bereits sind terung Al@@ dieser Auswirkungen die _PAD _PAD
2017-11-29 19:53:39,509:train.py:150 -         sample_input(): Src len: 15
2017-11-29 19:53:39,509:train.py:151 -         sample_input(): Trg: _BOS the impact of aging is already being felt in these countries &quot; education systems . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 19:53:39,509:train.py:152 -         sample_input(): Tar: the impact of aging is already being felt in these countries &quot; education systems . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 19:53:39,509:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 19:53:39,509:train.py:188 -         run_log_save(): Batch 465, epoch 2/20:
2017-11-29 19:53:39,509:train.py:189 -         run_log_save():    avg word perp:   195.89
2017-11-29 19:53:39,509:train.py:190 -         run_log_save():    acc trg words/s: 5525
2017-11-29 19:53:39,509:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:54:09,131:train.py:188 -         run_log_save(): Batch 565, epoch 2/20:
2017-11-29 19:54:09,131:train.py:189 -         run_log_save():    avg word perp:   190.62
2017-11-29 19:54:09,131:train.py:190 -         run_log_save():    acc trg words/s: 5527
2017-11-29 19:54:09,131:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:54:38,472:train.py:188 -         run_log_save(): Batch 665, epoch 2/20:
2017-11-29 19:54:38,473:train.py:189 -         run_log_save():    avg word perp:   190.01
2017-11-29 19:54:38,473:train.py:190 -         run_log_save():    acc trg words/s: 5534
2017-11-29 19:54:38,473:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:55:08,559:train.py:188 -         run_log_save(): Batch 765, epoch 2/20:
2017-11-29 19:55:08,559:train.py:189 -         run_log_save():    avg word perp:   186.91
2017-11-29 19:55:08,559:train.py:190 -         run_log_save():    acc trg words/s: 5520
2017-11-29 19:55:08,559:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:55:38,192:train.py:188 -         run_log_save(): Batch 865, epoch 2/20:
2017-11-29 19:55:38,192:train.py:189 -         run_log_save():    avg word perp:   185.38
2017-11-29 19:55:38,192:train.py:190 -         run_log_save():    acc trg words/s: 5517
2017-11-29 19:55:38,192:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:56:07,350:train.py:188 -         run_log_save(): Batch 965, epoch 2/20:
2017-11-29 19:56:07,351:train.py:189 -         run_log_save():    avg word perp:   177.42
2017-11-29 19:56:07,351:train.py:190 -         run_log_save():    acc trg words/s: 5519
2017-11-29 19:56:07,351:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:56:37,037:train.py:188 -         run_log_save(): Batch 1065, epoch 2/20:
2017-11-29 19:56:37,037:train.py:189 -         run_log_save():    avg word perp:   173.95
2017-11-29 19:56:37,037:train.py:190 -         run_log_save():    acc trg words/s: 5517
2017-11-29 19:56:37,037:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:57:06,337:train.py:188 -         run_log_save(): Batch 1165, epoch 2/20:
2017-11-29 19:57:06,337:train.py:189 -         run_log_save():    avg word perp:   171.49
2017-11-29 19:57:06,337:train.py:190 -         run_log_save():    acc trg words/s: 5520
2017-11-29 19:57:06,338:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:57:36,367:train.py:188 -         run_log_save(): Batch 1265, epoch 2/20:
2017-11-29 19:57:36,367:train.py:189 -         run_log_save():    avg word perp:   167.91
2017-11-29 19:57:36,367:train.py:190 -         run_log_save():    acc trg words/s: 5511
2017-11-29 19:57:36,367:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:58:05,515:train.py:188 -         run_log_save(): Batch 1365, epoch 2/20:
2017-11-29 19:58:05,515:train.py:189 -         run_log_save():    avg word perp:   165.90
2017-11-29 19:58:05,515:train.py:190 -         run_log_save():    acc trg words/s: 5515
2017-11-29 19:58:05,515:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:58:35,022:train.py:148 -         sample_input(): Sample input data:
2017-11-29 19:58:35,022:train.py:149 -         sample_input(): Src: . Rechtsstaatlichkeit und Verfassung von Schutz dem unter &quot; ständen Bürger amerikanische , betonte Obama _PAD _PAD
2017-11-29 19:58:35,022:train.py:150 -         sample_input(): Src len: 15
2017-11-29 19:58:35,022:train.py:151 -         sample_input(): Trg: _BOS Obama aver@@ red that American citizens &quot; are subject to the protections of the constitution and due process . &quot; _PAD _PAD
2017-11-29 19:58:35,022:train.py:152 -         sample_input(): Tar: Obama aver@@ red that American citizens &quot; are subject to the protections of the constitution and due process . &quot; _EOS _PAD _PAD
2017-11-29 19:58:35,022:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0
2017-11-29 19:58:35,023:train.py:188 -         run_log_save(): Batch 1465, epoch 2/20:
2017-11-29 19:58:35,023:train.py:189 -         run_log_save():    avg word perp:   161.66
2017-11-29 19:58:35,023:train.py:190 -         run_log_save():    acc trg words/s: 5515
2017-11-29 19:58:35,023:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:58:37,128:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.105008
2017-11-29 19:59:06,245:train.py:188 -         run_log_save(): Batch 1565, epoch 2/20:
2017-11-29 19:59:06,245:train.py:189 -         run_log_save():    avg word perp:   158.36
2017-11-29 19:59:06,245:train.py:190 -         run_log_save():    acc trg words/s: 5517
2017-11-29 19:59:06,245:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 19:59:35,666:train.py:188 -         run_log_save(): Batch 1665, epoch 2/20:
2017-11-29 19:59:35,666:train.py:189 -         run_log_save():    avg word perp:   155.45
2017-11-29 19:59:35,666:train.py:190 -         run_log_save():    acc trg words/s: 5517
2017-11-29 19:59:35,666:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:00:05,393:train.py:188 -         run_log_save(): Batch 1765, epoch 2/20:
2017-11-29 20:00:05,393:train.py:189 -         run_log_save():    avg word perp:   153.08
2017-11-29 20:00:05,393:train.py:190 -         run_log_save():    acc trg words/s: 5515
2017-11-29 20:00:05,393:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:00:34,657:train.py:188 -         run_log_save(): Batch 1865, epoch 2/20:
2017-11-29 20:00:34,658:train.py:189 -         run_log_save():    avg word perp:   150.51
2017-11-29 20:00:34,658:train.py:190 -         run_log_save():    acc trg words/s: 5515
2017-11-29 20:00:34,658:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:01:03,990:train.py:188 -         run_log_save(): Batch 1965, epoch 2/20:
2017-11-29 20:01:03,990:train.py:189 -         run_log_save():    avg word perp:   146.48
2017-11-29 20:01:03,991:train.py:190 -         run_log_save():    acc trg words/s: 5516
2017-11-29 20:01:03,991:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:01:33,708:train.py:188 -         run_log_save(): Batch 2065, epoch 2/20:
2017-11-29 20:01:33,708:train.py:189 -         run_log_save():    avg word perp:   145.82
2017-11-29 20:01:33,708:train.py:190 -         run_log_save():    acc trg words/s: 5514
2017-11-29 20:01:33,708:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:02:03,794:train.py:188 -         run_log_save(): Batch 2165, epoch 2/20:
2017-11-29 20:02:03,794:train.py:189 -         run_log_save():    avg word perp:   140.89
2017-11-29 20:02:03,795:train.py:190 -         run_log_save():    acc trg words/s: 5511
2017-11-29 20:02:03,795:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:02:33,195:train.py:188 -         run_log_save(): Batch 2265, epoch 2/20:
2017-11-29 20:02:33,197:train.py:189 -         run_log_save():    avg word perp:   136.46
2017-11-29 20:02:33,197:train.py:190 -         run_log_save():    acc trg words/s: 5513
2017-11-29 20:02:33,197:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:03:02,747:train.py:188 -         run_log_save(): Batch 2365, epoch 2/20:
2017-11-29 20:03:02,747:train.py:189 -         run_log_save():    avg word perp:   130.25
2017-11-29 20:03:02,747:train.py:190 -         run_log_save():    acc trg words/s: 5511
2017-11-29 20:03:02,747:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:03:31,740:train.py:148 -         sample_input(): Sample input data:
2017-11-29 20:03:31,740:train.py:149 -         sample_input(): Src: . unterschied vollkommen Arafats dem von sich der , ein stil Verwaltungs@@ einen führte Abbas _PAD _PAD
2017-11-29 20:03:31,740:train.py:150 -         sample_input(): Src len: 15
2017-11-29 20:03:31,740:train.py:151 -         sample_input(): Trg: _BOS Abbas introduced a totally different style of management from that of Arafat . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 20:03:31,741:train.py:152 -         sample_input(): Tar: Abbas introduced a totally different style of management from that of Arafat . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 20:03:31,741:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 20:03:31,741:train.py:188 -         run_log_save(): Batch 2465, epoch 2/20:
2017-11-29 20:03:31,741:train.py:189 -         run_log_save():    avg word perp:   123.35
2017-11-29 20:03:31,741:train.py:190 -         run_log_save():    acc trg words/s: 5515
2017-11-29 20:03:31,741:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:03:31,741:validator.py:225 -    validate_and_save(): Start validation
2017-11-29 20:03:31,741:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 20:04:21,252:validator.py:144 -             evaluate():   Translating line 100, average 0.493717429638 seconds/sent
2017-11-29 20:05:09,699:validator.py:144 -             evaluate():   Translating line 200, average 0.489092119932 seconds/sent
2017-11-29 20:05:50,524:validator.py:144 -             evaluate():   Translating line 300, average 0.462144676844 seconds/sent
2017-11-29 20:06:30,062:validator.py:144 -             evaluate():   Translating line 400, average 0.445455164909 seconds/sent
2017-11-29 20:07:18,041:validator.py:144 -             evaluate():   Translating line 500, average 0.45232264185 seconds/sent
2017-11-29 20:07:58,171:validator.py:144 -             evaluate():   Translating line 600, average 0.443818165064 seconds/sent
2017-11-29 20:08:42,291:validator.py:144 -             evaluate():   Translating line 700, average 0.443443904264 seconds/sent
2017-11-29 20:09:23,719:validator.py:144 -             evaluate():   Translating line 800, average 0.439798987508 seconds/sent
2017-11-29 20:09:59,360:validator.py:144 -             evaluate():   Translating line 900, average 0.430533657869 seconds/sent
2017-11-29 20:10:40,353:validator.py:144 -             evaluate():   Translating line 1000, average 0.428473093033 seconds/sent
2017-11-29 20:11:18,168:validator.py:144 -             evaluate():   Translating line 1100, average 0.423897969939 seconds/sent
2017-11-29 20:11:57,065:validator.py:144 -             evaluate():   Translating line 1200, average 0.420987594128 seconds/sent
2017-11-29 20:12:48,375:validator.py:144 -             evaluate():   Translating line 1300, average 0.428073109297 seconds/sent
2017-11-29 20:13:35,606:validator.py:144 -             evaluate():   Translating line 1400, average 0.431232509272 seconds/sent
2017-11-29 20:14:22,604:validator.py:144 -             evaluate():   Translating line 1500, average 0.433815639973 seconds/sent
2017-11-29 20:15:07,471:validator.py:144 -             evaluate():   Translating line 1600, average 0.434744549394 seconds/sent
2017-11-29 20:15:50,576:validator.py:144 -             evaluate():   Translating line 1700, average 0.434526951734 seconds/sent
2017-11-29 20:16:39,405:validator.py:144 -             evaluate():   Translating line 1800, average 0.437513555023 seconds/sent
2017-11-29 20:17:30,206:validator.py:144 -             evaluate():   Translating line 1900, average 0.441223895299 seconds/sent
2017-11-29 20:17:53,685:validator.py:153 -             evaluate(): Done translating.
2017-11-29 20:17:53,686:validator.py:154 -             evaluate(): dev perplexity: 422.878
2017-11-29 20:17:54,239:validator.py:160 -             evaluate(): BLEU = 0.71, 20.2/1.9/0.2/0.0 (BP=0.978, ratio=0.979, hyp_len=44302, ref_len=45274)

2017-11-29 20:17:54,240:validator.py:161 -             evaluate(): Validation took: 14.3726571004 minutes
2017-11-29 20:17:54,243:validator.py:213 -           maybe_save(): Save 0.71 to list of best bleu scores
2017-11-29 20:17:54,645:validator.py:217 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en/de2en-0.71.cpkt
2017-11-29 20:17:54,645:validator.py:218 -           maybe_save(): Best bleu scores so far: 0.71
2017-11-29 20:18:15,877:train.py:116 -         report_epoch(): Finish epoch 2
2017-11-29 20:18:15,878:train.py:117 -         report_epoch():     It takes 0:12:20.072914
2017-11-29 20:18:15,878:train.py:118 -         report_epoch():     Avergage # words/second    5514.03641739
2017-11-29 20:18:15,878:train.py:119 -         report_epoch():     Average seconds/batch    0.291941977958
2017-11-29 20:18:15,878:train.py:130 -         report_epoch():     train perplexity: 164.945083584
2017-11-29 20:18:16,425:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.546507120132 seconds
2017-11-29 20:18:24,425:train.py:188 -         run_log_save(): Batch 30, epoch 3/20:
2017-11-29 20:18:24,426:train.py:189 -         run_log_save():    avg word perp:   113.97
2017-11-29 20:18:24,426:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-29 20:18:24,426:train.py:191 -         run_log_save():    acc sec/batch:   0.26
2017-11-29 20:18:53,699:train.py:188 -         run_log_save(): Batch 130, epoch 3/20:
2017-11-29 20:18:53,699:train.py:189 -         run_log_save():    avg word perp:   103.92
2017-11-29 20:18:53,699:train.py:190 -         run_log_save():    acc trg words/s: 5528
2017-11-29 20:18:53,699:train.py:191 -         run_log_save():    acc sec/batch:   0.28
2017-11-29 20:19:23,594:train.py:188 -         run_log_save(): Batch 230, epoch 3/20:
2017-11-29 20:19:23,596:train.py:189 -         run_log_save():    avg word perp:   100.94
2017-11-29 20:19:23,596:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 20:19:23,596:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:19:53,351:train.py:188 -         run_log_save(): Batch 330, epoch 3/20:
2017-11-29 20:19:53,352:train.py:189 -         run_log_save():    avg word perp:   99.86
2017-11-29 20:19:53,352:train.py:190 -         run_log_save():    acc trg words/s: 5488
2017-11-29 20:19:53,352:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:20:23,073:train.py:188 -         run_log_save(): Batch 430, epoch 3/20:
2017-11-29 20:20:23,073:train.py:189 -         run_log_save():    avg word perp:   93.56
2017-11-29 20:20:23,074:train.py:190 -         run_log_save():    acc trg words/s: 5486
2017-11-29 20:20:23,074:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:20:52,176:train.py:188 -         run_log_save(): Batch 530, epoch 3/20:
2017-11-29 20:20:52,176:train.py:189 -         run_log_save():    avg word perp:   88.41
2017-11-29 20:20:52,176:train.py:190 -         run_log_save():    acc trg words/s: 5503
2017-11-29 20:20:52,176:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:21:22,001:train.py:188 -         run_log_save(): Batch 630, epoch 3/20:
2017-11-29 20:21:22,001:train.py:189 -         run_log_save():    avg word perp:   85.34
2017-11-29 20:21:22,001:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-29 20:21:22,001:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:21:51,949:train.py:188 -         run_log_save(): Batch 730, epoch 3/20:
2017-11-29 20:21:51,949:train.py:189 -         run_log_save():    avg word perp:   81.41
2017-11-29 20:21:51,949:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 20:21:51,949:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:22:21,526:train.py:188 -         run_log_save(): Batch 830, epoch 3/20:
2017-11-29 20:22:21,527:train.py:189 -         run_log_save():    avg word perp:   76.79
2017-11-29 20:22:21,527:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 20:22:21,527:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:22:50,857:train.py:148 -         sample_input(): Sample input data:
2017-11-29 20:22:50,858:train.py:149 -         sample_input(): Src: . ändern zu Kurs seinen ziehung An@@ gegenseitige die durch um , zieren plat@@ zu Nähe seiner in Objekt großes ein , propagieren einige _PAD
2017-11-29 20:22:50,858:train.py:150 -         sample_input(): Src len: 24
2017-11-29 20:22:50,858:train.py:151 -         sample_input(): Trg: _BOS some have suggested placing a large object nearby to change its trajectory through mutual gravit@@ ational attraction . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 20:22:50,858:train.py:152 -         sample_input(): Tar: some have suggested placing a large object nearby to change its trajectory through mutual gravit@@ ational attraction . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 20:22:50,858:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 20:22:50,858:train.py:188 -         run_log_save(): Batch 930, epoch 3/20:
2017-11-29 20:22:50,858:train.py:189 -         run_log_save():    avg word perp:   73.91
2017-11-29 20:22:50,858:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-29 20:22:50,858:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:22:53,004:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.145927
2017-11-29 20:23:22,776:train.py:188 -         run_log_save(): Batch 1030, epoch 3/20:
2017-11-29 20:23:22,776:train.py:189 -         run_log_save():    avg word perp:   71.82
2017-11-29 20:23:22,776:train.py:190 -         run_log_save():    acc trg words/s: 5492
2017-11-29 20:23:22,776:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:23:52,298:train.py:188 -         run_log_save(): Batch 1130, epoch 3/20:
2017-11-29 20:23:52,299:train.py:189 -         run_log_save():    avg word perp:   68.22
2017-11-29 20:23:52,299:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 20:23:52,299:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:24:21,528:train.py:188 -         run_log_save(): Batch 1230, epoch 3/20:
2017-11-29 20:24:21,528:train.py:189 -         run_log_save():    avg word perp:   66.41
2017-11-29 20:24:21,528:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 20:24:21,528:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:24:51,003:train.py:188 -         run_log_save(): Batch 1330, epoch 3/20:
2017-11-29 20:24:51,003:train.py:189 -         run_log_save():    avg word perp:   64.06
2017-11-29 20:24:51,003:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-29 20:24:51,003:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:25:20,673:train.py:188 -         run_log_save(): Batch 1430, epoch 3/20:
2017-11-29 20:25:20,673:train.py:189 -         run_log_save():    avg word perp:   61.58
2017-11-29 20:25:20,674:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-29 20:25:20,674:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:25:50,082:train.py:188 -         run_log_save(): Batch 1530, epoch 3/20:
2017-11-29 20:25:50,082:train.py:189 -         run_log_save():    avg word perp:   58.78
2017-11-29 20:25:50,083:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 20:25:50,083:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:26:19,378:train.py:188 -         run_log_save(): Batch 1630, epoch 3/20:
2017-11-29 20:26:19,378:train.py:189 -         run_log_save():    avg word perp:   57.41
2017-11-29 20:26:19,378:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-29 20:26:19,378:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:26:48,892:train.py:188 -         run_log_save(): Batch 1730, epoch 3/20:
2017-11-29 20:26:48,893:train.py:189 -         run_log_save():    avg word perp:   56.03
2017-11-29 20:26:48,893:train.py:190 -         run_log_save():    acc trg words/s: 5503
2017-11-29 20:26:48,893:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:27:18,337:train.py:188 -         run_log_save(): Batch 1830, epoch 3/20:
2017-11-29 20:27:18,338:train.py:189 -         run_log_save():    avg word perp:   52.03
2017-11-29 20:27:18,338:train.py:190 -         run_log_save():    acc trg words/s: 5504
2017-11-29 20:27:18,338:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:27:47,787:train.py:148 -         sample_input(): Sample input data:
2017-11-29 20:27:47,787:train.py:149 -         sample_input(): Src: . anerkannt Israel mit Friedensprozesses seines Bestandteil als Sinai des arisierung milit@@ Ent@@ die hat , Nation souveräne und große eine , Ägypten selbst _PAD
2017-11-29 20:27:47,788:train.py:150 -         sample_input(): Src len: 24
2017-11-29 20:27:47,788:train.py:151 -         sample_input(): Trg: _BOS even Egypt , a great and sovereign nation , accepted de@@ militarization of Sinai as a part of its peace process with Israel . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 20:27:47,788:train.py:152 -         sample_input(): Tar: even Egypt , a great and sovereign nation , accepted de@@ militarization of Sinai as a part of its peace process with Israel . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 20:27:47,788:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 20:27:47,788:train.py:188 -         run_log_save(): Batch 1930, epoch 3/20:
2017-11-29 20:27:47,788:train.py:189 -         run_log_save():    avg word perp:   51.23
2017-11-29 20:27:47,788:train.py:190 -         run_log_save():    acc trg words/s: 5505
2017-11-29 20:27:47,788:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:28:17,372:train.py:188 -         run_log_save(): Batch 2030, epoch 3/20:
2017-11-29 20:28:17,372:train.py:189 -         run_log_save():    avg word perp:   49.69
2017-11-29 20:28:17,372:train.py:190 -         run_log_save():    acc trg words/s: 5504
2017-11-29 20:28:17,372:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:28:47,004:train.py:188 -         run_log_save(): Batch 2130, epoch 3/20:
2017-11-29 20:28:47,004:train.py:189 -         run_log_save():    avg word perp:   48.17
2017-11-29 20:28:47,004:train.py:190 -         run_log_save():    acc trg words/s: 5504
2017-11-29 20:28:47,004:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:29:16,249:train.py:188 -         run_log_save(): Batch 2230, epoch 3/20:
2017-11-29 20:29:16,249:train.py:189 -         run_log_save():    avg word perp:   47.03
2017-11-29 20:29:16,249:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-29 20:29:16,249:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:29:45,728:train.py:188 -         run_log_save(): Batch 2330, epoch 3/20:
2017-11-29 20:29:45,729:train.py:189 -         run_log_save():    avg word perp:   45.29
2017-11-29 20:29:45,729:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-29 20:29:45,729:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:30:15,757:train.py:188 -         run_log_save(): Batch 2430, epoch 3/20:
2017-11-29 20:30:15,757:train.py:189 -         run_log_save():    avg word perp:   44.64
2017-11-29 20:30:15,757:train.py:190 -         run_log_save():    acc trg words/s: 5506
2017-11-29 20:30:15,757:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:30:45,672:train.py:188 -         run_log_save(): Batch 2530, epoch 3/20:
2017-11-29 20:30:45,672:train.py:189 -         run_log_save():    avg word perp:   43.67
2017-11-29 20:30:45,672:train.py:190 -         run_log_save():    acc trg words/s: 5505
2017-11-29 20:30:45,672:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:30:47,623:train.py:116 -         report_epoch(): Finish epoch 3
2017-11-29 20:30:47,624:train.py:117 -         report_epoch():     It takes 0:12:21.153630
2017-11-29 20:30:47,624:train.py:118 -         report_epoch():     Avergage # words/second    5505.98665838
2017-11-29 20:30:47,624:train.py:119 -         report_epoch():     Average seconds/batch    0.292368295959
2017-11-29 20:30:47,624:train.py:130 -         report_epoch():     train perplexity: 65.3424870486
2017-11-29 20:30:48,088:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.464174032211 seconds
2017-11-29 20:31:15,768:train.py:188 -         run_log_save(): Batch 95, epoch 4/20:
2017-11-29 20:31:15,768:train.py:189 -         run_log_save():    avg word perp:   36.83
2017-11-29 20:31:15,768:train.py:190 -         run_log_save():    acc trg words/s: 5472
2017-11-29 20:31:15,769:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:31:45,143:train.py:188 -         run_log_save(): Batch 195, epoch 4/20:
2017-11-29 20:31:45,143:train.py:189 -         run_log_save():    avg word perp:   36.99
2017-11-29 20:31:45,143:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-29 20:31:45,144:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:32:14,794:train.py:188 -         run_log_save(): Batch 295, epoch 4/20:
2017-11-29 20:32:14,794:train.py:189 -         run_log_save():    avg word perp:   35.91
2017-11-29 20:32:14,794:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-29 20:32:14,794:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:32:44,072:train.py:148 -         sample_input(): Sample input data:
2017-11-29 20:32:44,072:train.py:149 -         sample_input(): Src: . ert ori@@ hon@@ Krediten langfristigen bei Zinssatz niedrigeren einem mit , einzulassen Experimente auf testen entfern@@ im nicht sich und bekämpfen zu Inflation die , Bereitschaft diese wurde Kapitalmärkten den auf _PAD
2017-11-29 20:32:44,072:train.py:150 -         sample_input(): Src len: 32
2017-11-29 20:32:44,072:train.py:151 -         sample_input(): Trg: _BOS in capital markets , the commitment to fight inflation , to not be even remotely experimental , was welcomed with a lower long @-@ term rate . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 20:32:44,072:train.py:152 -         sample_input(): Tar: in capital markets , the commitment to fight inflation , to not be even remotely experimental , was welcomed with a lower long @-@ term rate . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 20:32:44,072:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 20:32:44,072:train.py:188 -         run_log_save(): Batch 395, epoch 4/20:
2017-11-29 20:32:44,072:train.py:189 -         run_log_save():    avg word perp:   35.51
2017-11-29 20:32:44,072:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-29 20:32:44,072:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:32:46,335:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.262024
2017-11-29 20:33:16,169:train.py:188 -         run_log_save(): Batch 495, epoch 4/20:
2017-11-29 20:33:16,169:train.py:189 -         run_log_save():    avg word perp:   34.52
2017-11-29 20:33:16,169:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-29 20:33:16,169:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:33:45,528:train.py:188 -         run_log_save(): Batch 595, epoch 4/20:
2017-11-29 20:33:45,528:train.py:189 -         run_log_save():    avg word perp:   34.30
2017-11-29 20:33:45,528:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-29 20:33:45,528:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:34:15,216:train.py:188 -         run_log_save(): Batch 695, epoch 4/20:
2017-11-29 20:34:15,216:train.py:189 -         run_log_save():    avg word perp:   33.90
2017-11-29 20:34:15,216:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 20:34:15,216:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:34:44,973:train.py:188 -         run_log_save(): Batch 795, epoch 4/20:
2017-11-29 20:34:44,973:train.py:189 -         run_log_save():    avg word perp:   33.99
2017-11-29 20:34:44,973:train.py:190 -         run_log_save():    acc trg words/s: 5492
2017-11-29 20:34:44,973:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:35:14,454:train.py:188 -         run_log_save(): Batch 895, epoch 4/20:
2017-11-29 20:35:14,454:train.py:189 -         run_log_save():    avg word perp:   33.52
2017-11-29 20:35:14,454:train.py:190 -         run_log_save():    acc trg words/s: 5493
2017-11-29 20:35:14,455:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:35:44,077:train.py:188 -         run_log_save(): Batch 995, epoch 4/20:
2017-11-29 20:35:44,077:train.py:189 -         run_log_save():    avg word perp:   32.68
2017-11-29 20:35:44,077:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 20:35:44,077:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:36:14,018:train.py:188 -         run_log_save(): Batch 1095, epoch 4/20:
2017-11-29 20:36:14,018:train.py:189 -         run_log_save():    avg word perp:   31.71
2017-11-29 20:36:14,018:train.py:190 -         run_log_save():    acc trg words/s: 5490
2017-11-29 20:36:14,018:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:36:43,537:train.py:188 -         run_log_save(): Batch 1195, epoch 4/20:
2017-11-29 20:36:43,537:train.py:189 -         run_log_save():    avg word perp:   31.47
2017-11-29 20:36:43,537:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-29 20:36:43,537:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:37:12,685:train.py:188 -         run_log_save(): Batch 1295, epoch 4/20:
2017-11-29 20:37:12,685:train.py:189 -         run_log_save():    avg word perp:   30.81
2017-11-29 20:37:12,686:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-29 20:37:12,686:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:37:42,111:train.py:148 -         sample_input(): Sample input data:
2017-11-29 20:37:42,111:train.py:149 -         sample_input(): Src: . lassen zu klingen scher üb@@ h@@ bewegungen Bevölkerungs@@ erzwungene um , ) &quot; turen korrek@@ Grenz@@ &quot; ( &quot; frontiers of tification rec@@ &quot; Ausdruck der war Beispiele seiner eines _PAD _PAD
2017-11-29 20:37:42,111:train.py:150 -         sample_input(): Src len: 31
2017-11-29 20:37:42,111:train.py:151 -         sample_input(): Trg: _BOS one of his examples was the phrase &quot; rec@@ tification of frontiers &quot; to sugar @-@ co@@ at forced population movements . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 20:37:42,111:train.py:152 -         sample_input(): Tar: one of his examples was the phrase &quot; rec@@ tification of frontiers &quot; to sugar @-@ co@@ at forced population movements . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 20:37:42,111:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 20:37:42,111:train.py:188 -         run_log_save(): Batch 1395, epoch 4/20:
2017-11-29 20:37:42,111:train.py:189 -         run_log_save():    avg word perp:   30.88
2017-11-29 20:37:42,111:train.py:190 -         run_log_save():    acc trg words/s: 5503
2017-11-29 20:37:42,111:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:38:11,483:train.py:188 -         run_log_save(): Batch 1495, epoch 4/20:
2017-11-29 20:38:11,484:train.py:189 -         run_log_save():    avg word perp:   30.66
2017-11-29 20:38:11,484:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-29 20:38:11,484:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:38:40,803:train.py:188 -         run_log_save(): Batch 1595, epoch 4/20:
2017-11-29 20:38:40,803:train.py:189 -         run_log_save():    avg word perp:   29.52
2017-11-29 20:38:40,803:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-29 20:38:40,803:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:39:09,753:train.py:188 -         run_log_save(): Batch 1695, epoch 4/20:
2017-11-29 20:39:09,779:train.py:189 -         run_log_save():    avg word perp:   28.46
2017-11-29 20:39:09,779:train.py:190 -         run_log_save():    acc trg words/s: 5513
2017-11-29 20:39:09,779:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:39:39,741:train.py:188 -         run_log_save(): Batch 1795, epoch 4/20:
2017-11-29 20:39:39,741:train.py:189 -         run_log_save():    avg word perp:   28.42
2017-11-29 20:39:39,741:train.py:190 -         run_log_save():    acc trg words/s: 5510
2017-11-29 20:39:39,741:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:40:09,434:train.py:188 -         run_log_save(): Batch 1895, epoch 4/20:
2017-11-29 20:40:09,434:train.py:189 -         run_log_save():    avg word perp:   28.87
2017-11-29 20:40:09,434:train.py:190 -         run_log_save():    acc trg words/s: 5509
2017-11-29 20:40:09,434:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:40:39,554:train.py:188 -         run_log_save(): Batch 1995, epoch 4/20:
2017-11-29 20:40:39,555:train.py:189 -         run_log_save():    avg word perp:   28.02
2017-11-29 20:40:39,555:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-29 20:40:39,555:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:41:09,274:train.py:188 -         run_log_save(): Batch 2095, epoch 4/20:
2017-11-29 20:41:09,274:train.py:189 -         run_log_save():    avg word perp:   27.31
2017-11-29 20:41:09,274:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-29 20:41:09,274:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:41:38,447:train.py:188 -         run_log_save(): Batch 2195, epoch 4/20:
2017-11-29 20:41:38,447:train.py:189 -         run_log_save():    avg word perp:   27.00
2017-11-29 20:41:38,447:train.py:190 -         run_log_save():    acc trg words/s: 5505
2017-11-29 20:41:38,447:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:42:07,869:train.py:188 -         run_log_save(): Batch 2295, epoch 4/20:
2017-11-29 20:42:07,869:train.py:189 -         run_log_save():    avg word perp:   26.99
2017-11-29 20:42:07,869:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-29 20:42:07,869:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:42:37,395:train.py:148 -         sample_input(): Sample input data:
2017-11-29 20:42:37,395:train.py:149 -         sample_input(): Src: ? ) ert heu@@ an@@ Team ges klassi@@ dritt@@ ein Regierung die wenn etwa ( werden verwendet lich ch@@ bräu@@ miss@@ Geldes des Teile dass , verhindern Unternehmen können wie und _PAD
2017-11-29 20:42:37,395:train.py:150 -         sample_input(): Src len: 31
2017-11-29 20:42:37,395:train.py:151 -         sample_input(): Trg: _BOS and how can companies prevent some of the funds from being mis@@ used ( say , if the government hi@@ res a third @-@ rate team ) ? _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 20:42:37,395:train.py:152 -         sample_input(): Tar: and how can companies prevent some of the funds from being mis@@ used ( say , if the government hi@@ res a third @-@ rate team ) ? _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 20:42:37,395:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 20:42:37,395:train.py:188 -         run_log_save(): Batch 2395, epoch 4/20:
2017-11-29 20:42:37,396:train.py:189 -         run_log_save():    avg word perp:   26.49
2017-11-29 20:42:37,396:train.py:190 -         run_log_save():    acc trg words/s: 5506
2017-11-29 20:42:37,396:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:42:39,616:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.220501
2017-11-29 20:42:39,617:validator.py:225 -    validate_and_save(): Start validation
2017-11-29 20:42:39,617:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 20:43:26,910:validator.py:144 -             evaluate():   Translating line 100, average 0.472393949032 seconds/sent
2017-11-29 20:44:13,003:validator.py:144 -             evaluate():   Translating line 200, average 0.46666046977 seconds/sent
2017-11-29 20:44:58,018:validator.py:144 -             evaluate():   Translating line 300, average 0.461157596111 seconds/sent
2017-11-29 20:45:38,094:validator.py:144 -             evaluate():   Translating line 400, average 0.446058832407 seconds/sent
2017-11-29 20:46:27,502:validator.py:144 -             evaluate():   Translating line 500, average 0.455661505699 seconds/sent
2017-11-29 20:47:06,663:validator.py:144 -             evaluate():   Translating line 600, average 0.444986553192 seconds/sent
2017-11-29 20:47:47,950:validator.py:144 -             evaluate():   Translating line 700, average 0.440398988383 seconds/sent
2017-11-29 20:48:24,236:validator.py:144 -             evaluate():   Translating line 800, average 0.430706563592 seconds/sent
2017-11-29 20:48:57,087:validator.py:144 -             evaluate():   Translating line 900, average 0.419351687696 seconds/sent
2017-11-29 20:49:36,893:validator.py:144 -             evaluate():   Translating line 1000, average 0.417222121 seconds/sent
2017-11-29 20:50:19,811:validator.py:144 -             evaluate():   Translating line 1100, average 0.418308937116 seconds/sent
2017-11-29 20:50:59,000:validator.py:144 -             evaluate():   Translating line 1200, average 0.416107359131 seconds/sent
2017-11-29 20:51:50,269:validator.py:144 -             evaluate():   Translating line 1300, average 0.423536712206 seconds/sent
2017-11-29 20:52:37,711:validator.py:144 -             evaluate():   Translating line 1400, average 0.427171685014 seconds/sent
2017-11-29 20:53:25,816:validator.py:144 -             evaluate():   Translating line 1500, average 0.430763634682 seconds/sent
2017-11-29 20:54:11,615:validator.py:144 -             evaluate():   Translating line 1600, average 0.432465022504 seconds/sent
2017-11-29 20:54:58,352:validator.py:144 -             evaluate():   Translating line 1700, average 0.434518083404 seconds/sent
2017-11-29 20:55:56,597:validator.py:144 -             evaluate():   Translating line 1800, average 0.442736437188 seconds/sent
2017-11-29 20:56:47,663:validator.py:144 -             evaluate():   Translating line 1900, average 0.446311410477 seconds/sent
2017-11-29 20:57:15,795:validator.py:153 -             evaluate(): Done translating.
2017-11-29 20:57:15,795:validator.py:154 -             evaluate(): dev perplexity: 144.284
2017-11-29 20:57:16,315:validator.py:160 -             evaluate(): BLEU = 6.41, 29.1/9.6/3.8/1.6 (BP=1.000, ratio=1.135, hyp_len=51399, ref_len=45274)

2017-11-29 20:57:16,317:validator.py:161 -             evaluate(): Validation took: 14.6107629498 minutes
2017-11-29 20:57:16,320:validator.py:196 -           maybe_save(): Current best bleus: 0.71
2017-11-29 20:57:16,320:validator.py:197 -           maybe_save(): Delete 0.71 & use 6.41 instead
2017-11-29 20:57:16,320:validator.py:207 -           maybe_save(): Delete ./nmt/saved_models/de2en/de2en-0.71.cpkt.data-00000-of-00001 & ./nmt/saved_models/de2en/de2en-0.71.cpkt.meta & ./nmt/saved_models/de2en/de2en-0.71.cpkt.index
2017-11-29 20:57:16,334:validator.py:213 -           maybe_save(): Save 6.41 to list of best bleu scores
2017-11-29 20:57:16,808:validator.py:217 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en/de2en-6.41.cpkt
2017-11-29 20:57:16,808:validator.py:218 -           maybe_save(): Best bleu scores so far: 6.41
2017-11-29 20:57:46,570:train.py:188 -         run_log_save(): Batch 2495, epoch 4/20:
2017-11-29 20:57:46,570:train.py:189 -         run_log_save():    avg word perp:   26.07
2017-11-29 20:57:46,570:train.py:190 -         run_log_save():    acc trg words/s: 5506
2017-11-29 20:57:46,570:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:57:59,107:train.py:116 -         report_epoch(): Finish epoch 4
2017-11-29 20:57:59,107:train.py:117 -         report_epoch():     It takes 0:12:21.216684
2017-11-29 20:57:59,107:train.py:118 -         report_epoch():     Avergage # words/second    5505.44137787
2017-11-29 20:57:59,107:train.py:119 -         report_epoch():     Average seconds/batch    0.292393169083
2017-11-29 20:57:59,107:train.py:130 -         report_epoch():     train perplexity: 30.9428937837
2017-11-29 20:57:59,556:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.448899030685 seconds
2017-11-29 20:58:17,177:train.py:188 -         run_log_save(): Batch 60, epoch 5/20:
2017-11-29 20:58:17,177:train.py:189 -         run_log_save():    avg word perp:   23.98
2017-11-29 20:58:17,177:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-29 20:58:17,177:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:58:47,076:train.py:188 -         run_log_save(): Batch 160, epoch 5/20:
2017-11-29 20:58:47,076:train.py:189 -         run_log_save():    avg word perp:   22.60
2017-11-29 20:58:47,076:train.py:190 -         run_log_save():    acc trg words/s: 5469
2017-11-29 20:58:47,076:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:59:16,482:train.py:188 -         run_log_save(): Batch 260, epoch 5/20:
2017-11-29 20:59:16,482:train.py:189 -         run_log_save():    avg word perp:   22.63
2017-11-29 20:59:16,482:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-29 20:59:16,482:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 20:59:45,891:train.py:188 -         run_log_save(): Batch 360, epoch 5/20:
2017-11-29 20:59:45,891:train.py:189 -         run_log_save():    avg word perp:   22.04
2017-11-29 20:59:45,892:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-29 20:59:45,892:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:00:15,364:train.py:188 -         run_log_save(): Batch 460, epoch 5/20:
2017-11-29 21:00:15,364:train.py:189 -         run_log_save():    avg word perp:   22.14
2017-11-29 21:00:15,364:train.py:190 -         run_log_save():    acc trg words/s: 5506
2017-11-29 21:00:15,364:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:00:44,886:train.py:188 -         run_log_save(): Batch 560, epoch 5/20:
2017-11-29 21:00:44,886:train.py:189 -         run_log_save():    avg word perp:   22.10
2017-11-29 21:00:44,886:train.py:190 -         run_log_save():    acc trg words/s: 5513
2017-11-29 21:00:44,886:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:01:14,340:train.py:188 -         run_log_save(): Batch 660, epoch 5/20:
2017-11-29 21:01:14,340:train.py:189 -         run_log_save():    avg word perp:   22.42
2017-11-29 21:01:14,340:train.py:190 -         run_log_save():    acc trg words/s: 5519
2017-11-29 21:01:14,340:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:01:44,499:train.py:188 -         run_log_save(): Batch 760, epoch 5/20:
2017-11-29 21:01:44,500:train.py:189 -         run_log_save():    avg word perp:   22.08
2017-11-29 21:01:44,500:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-29 21:01:44,500:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:02:13,955:train.py:148 -         sample_input(): Sample input data:
2017-11-29 21:02:13,955:train.py:149 -         sample_input(): Src: . haben Saatgut das auf - Monopol ein somit und - schutz Patent@@ die , geraten to san@@ Mon@@ wie stellern ther@@ gu@@ Saat@@ großen von Abhängigkeit in , wird erlaubt ten Sor@@ veränderten gentechnisch von Anbau der denen , Bauern dass , einige behaupten schließlich _PAD _PAD _PAD _PAD
2017-11-29 21:02:13,955:train.py:150 -         sample_input(): Src len: 46
2017-11-29 21:02:13,955:train.py:151 -         sample_input(): Trg: _BOS Last@@ ly , some argue that if farmers are permitted to sow GM varieties , they become dependent on large seed producers such as Mon@@ san@@ to , which have patent protection - and thus a monopoly - on the seed . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:02:13,955:train.py:152 -         sample_input(): Tar: Last@@ ly , some argue that if farmers are permitted to sow GM varieties , they become dependent on large seed producers such as Mon@@ san@@ to , which have patent protection - and thus a monopoly - on the seed . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:02:13,955:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 21:02:13,956:train.py:188 -         run_log_save(): Batch 860, epoch 5/20:
2017-11-29 21:02:13,956:train.py:189 -         run_log_save():    avg word perp:   21.76
2017-11-29 21:02:13,956:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-29 21:02:13,956:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:02:43,263:train.py:188 -         run_log_save(): Batch 960, epoch 5/20:
2017-11-29 21:02:43,264:train.py:189 -         run_log_save():    avg word perp:   21.64
2017-11-29 21:02:43,264:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-29 21:02:43,264:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:03:12,776:train.py:188 -         run_log_save(): Batch 1060, epoch 5/20:
2017-11-29 21:03:12,777:train.py:189 -         run_log_save():    avg word perp:   21.29
2017-11-29 21:03:12,777:train.py:190 -         run_log_save():    acc trg words/s: 5504
2017-11-29 21:03:12,777:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:03:42,576:train.py:188 -         run_log_save(): Batch 1160, epoch 5/20:
2017-11-29 21:03:42,576:train.py:189 -         run_log_save():    avg word perp:   21.38
2017-11-29 21:03:42,576:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-29 21:03:42,576:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:04:12,207:train.py:188 -         run_log_save(): Batch 1260, epoch 5/20:
2017-11-29 21:04:12,209:train.py:189 -         run_log_save():    avg word perp:   21.55
2017-11-29 21:04:12,209:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 21:04:12,209:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:04:41,907:train.py:188 -         run_log_save(): Batch 1360, epoch 5/20:
2017-11-29 21:04:41,907:train.py:189 -         run_log_save():    avg word perp:   21.38
2017-11-29 21:04:41,907:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 21:04:41,907:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:05:11,780:train.py:188 -         run_log_save(): Batch 1460, epoch 5/20:
2017-11-29 21:05:11,780:train.py:189 -         run_log_save():    avg word perp:   21.38
2017-11-29 21:05:11,780:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-29 21:05:11,780:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:05:41,383:train.py:188 -         run_log_save(): Batch 1560, epoch 5/20:
2017-11-29 21:05:41,383:train.py:189 -         run_log_save():    avg word perp:   20.96
2017-11-29 21:05:41,383:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-29 21:05:41,383:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:06:11,232:train.py:188 -         run_log_save(): Batch 1660, epoch 5/20:
2017-11-29 21:06:11,232:train.py:189 -         run_log_save():    avg word perp:   20.56
2017-11-29 21:06:11,232:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-29 21:06:11,232:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:06:40,484:train.py:188 -         run_log_save(): Batch 1760, epoch 5/20:
2017-11-29 21:06:40,485:train.py:189 -         run_log_save():    avg word perp:   20.73
2017-11-29 21:06:40,485:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 21:06:40,485:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:07:10,132:train.py:148 -         sample_input(): Sample input data:
2017-11-29 21:07:10,132:train.py:149 -         sample_input(): Src: . folgen nach Wahrscheinlichkeit aller dürften Phasen ähnliche und , entwickeln gut relativ sich sie denen in , weg vor@@ 1998 @-@ 1988 und 1988 @-@ 1978 wie Phasen gingen , entwickeln schlecht relativ Aktien sich denen in , 2008 @-@ 1998 wie träumen Zei@@ _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:07:10,132:train.py:150 -         sample_input(): Src len: 45
2017-11-29 21:07:10,132:train.py:151 -         sample_input(): Trg: _BOS periods like 1998 @-@ 2008 , in which stocks do relatively badly , are preceded by periods - like 1978 @-@ 1988 and 1988 @-@ 1998 - in which they do relatively well , and are in all likelihood followed by similar periods . _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:07:10,132:train.py:152 -         sample_input(): Tar: periods like 1998 @-@ 2008 , in which stocks do relatively badly , are preceded by periods - like 1978 @-@ 1988 and 1988 @-@ 1998 - in which they do relatively well , and are in all likelihood followed by similar periods . _EOS _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:07:10,132:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 21:07:10,132:train.py:188 -         run_log_save(): Batch 1860, epoch 5/20:
2017-11-29 21:07:10,132:train.py:189 -         run_log_save():    avg word perp:   20.56
2017-11-29 21:07:10,132:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 21:07:10,132:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:07:12,426:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.293763
2017-11-29 21:07:41,767:train.py:188 -         run_log_save(): Batch 1960, epoch 5/20:
2017-11-29 21:07:41,767:train.py:189 -         run_log_save():    avg word perp:   20.15
2017-11-29 21:07:41,767:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-29 21:07:41,767:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:08:11,242:train.py:188 -         run_log_save(): Batch 2060, epoch 5/20:
2017-11-29 21:08:11,242:train.py:189 -         run_log_save():    avg word perp:   20.17
2017-11-29 21:08:11,242:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-29 21:08:11,242:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:08:41,314:train.py:188 -         run_log_save(): Batch 2160, epoch 5/20:
2017-11-29 21:08:41,314:train.py:189 -         run_log_save():    avg word perp:   20.18
2017-11-29 21:08:41,314:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-29 21:08:41,314:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:09:10,662:train.py:188 -         run_log_save(): Batch 2260, epoch 5/20:
2017-11-29 21:09:10,662:train.py:189 -         run_log_save():    avg word perp:   20.08
2017-11-29 21:09:10,662:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-29 21:09:10,662:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:09:39,977:train.py:188 -         run_log_save(): Batch 2360, epoch 5/20:
2017-11-29 21:09:39,977:train.py:189 -         run_log_save():    avg word perp:   19.80
2017-11-29 21:09:39,977:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-29 21:09:39,977:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:10:09,267:train.py:188 -         run_log_save(): Batch 2460, epoch 5/20:
2017-11-29 21:10:09,267:train.py:189 -         run_log_save():    avg word perp:   19.36
2017-11-29 21:10:09,267:train.py:190 -         run_log_save():    acc trg words/s: 5503
2017-11-29 21:10:09,267:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:10:31,490:train.py:116 -         report_epoch(): Finish epoch 5
2017-11-29 21:10:31,490:train.py:117 -         report_epoch():     It takes 0:12:21.830661
2017-11-29 21:10:31,490:train.py:118 -         report_epoch():     Avergage # words/second    5500.97780114
2017-11-29 21:10:31,490:train.py:119 -         report_epoch():     Average seconds/batch    0.292635369348
2017-11-29 21:10:31,490:train.py:130 -         report_epoch():     train perplexity: 21.152871559
2017-11-29 21:10:31,921:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.430600881577 seconds
2017-11-29 21:10:38,568:train.py:188 -         run_log_save(): Batch 25, epoch 6/20:
2017-11-29 21:10:38,568:train.py:189 -         run_log_save():    avg word perp:   18.61
2017-11-29 21:10:38,568:train.py:190 -         run_log_save():    acc trg words/s: 5555
2017-11-29 21:10:38,568:train.py:191 -         run_log_save():    acc sec/batch:   0.26
2017-11-29 21:11:08,045:train.py:188 -         run_log_save(): Batch 125, epoch 6/20:
2017-11-29 21:11:08,046:train.py:189 -         run_log_save():    avg word perp:   16.99
2017-11-29 21:11:08,046:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-29 21:11:08,046:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:11:37,799:train.py:188 -         run_log_save(): Batch 225, epoch 6/20:
2017-11-29 21:11:37,799:train.py:189 -         run_log_save():    avg word perp:   17.05
2017-11-29 21:11:37,799:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 21:11:37,799:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:12:07,538:train.py:148 -         sample_input(): Sample input data:
2017-11-29 21:12:07,538:train.py:149 -         sample_input(): Src: . erfüllen zu Euroeinführung die für kriterien Konvergenz@@ die , erhöhen Schwierigkeit die wird sie _PAD _PAD
2017-11-29 21:12:07,538:train.py:150 -         sample_input(): Src len: 15
2017-11-29 21:12:07,538:train.py:151 -         sample_input(): Trg: _BOS it will heighten the difficulty of meeting the convergence criteria for euro adoption . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:12:07,538:train.py:152 -         sample_input(): Tar: it will heighten the difficulty of meeting the convergence criteria for euro adoption . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:12:07,538:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 21:12:07,538:train.py:188 -         run_log_save(): Batch 325, epoch 6/20:
2017-11-29 21:12:07,538:train.py:189 -         run_log_save():    avg word perp:   17.28
2017-11-29 21:12:07,538:train.py:190 -         run_log_save():    acc trg words/s: 5481
2017-11-29 21:12:07,538:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:12:36,702:train.py:188 -         run_log_save(): Batch 425, epoch 6/20:
2017-11-29 21:12:36,703:train.py:189 -         run_log_save():    avg word perp:   16.94
2017-11-29 21:12:36,703:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-29 21:12:36,703:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:13:06,381:train.py:188 -         run_log_save(): Batch 525, epoch 6/20:
2017-11-29 21:13:06,381:train.py:189 -         run_log_save():    avg word perp:   17.00
2017-11-29 21:13:06,381:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-29 21:13:06,381:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:13:35,396:train.py:188 -         run_log_save(): Batch 625, epoch 6/20:
2017-11-29 21:13:35,396:train.py:189 -         run_log_save():    avg word perp:   16.97
2017-11-29 21:13:35,396:train.py:190 -         run_log_save():    acc trg words/s: 5517
2017-11-29 21:13:35,397:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:14:04,871:train.py:188 -         run_log_save(): Batch 725, epoch 6/20:
2017-11-29 21:14:04,871:train.py:189 -         run_log_save():    avg word perp:   16.88
2017-11-29 21:14:04,871:train.py:190 -         run_log_save():    acc trg words/s: 5515
2017-11-29 21:14:04,871:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:14:34,081:train.py:188 -         run_log_save(): Batch 825, epoch 6/20:
2017-11-29 21:14:34,081:train.py:189 -         run_log_save():    avg word perp:   17.24
2017-11-29 21:14:34,081:train.py:190 -         run_log_save():    acc trg words/s: 5519
2017-11-29 21:14:34,081:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:15:03,876:train.py:188 -         run_log_save(): Batch 925, epoch 6/20:
2017-11-29 21:15:03,876:train.py:189 -         run_log_save():    avg word perp:   17.10
2017-11-29 21:15:03,876:train.py:190 -         run_log_save():    acc trg words/s: 5515
2017-11-29 21:15:03,876:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:15:33,465:train.py:188 -         run_log_save(): Batch 1025, epoch 6/20:
2017-11-29 21:15:33,465:train.py:189 -         run_log_save():    avg word perp:   16.74
2017-11-29 21:15:33,466:train.py:190 -         run_log_save():    acc trg words/s: 5517
2017-11-29 21:15:33,466:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:16:02,837:train.py:188 -         run_log_save(): Batch 1125, epoch 6/20:
2017-11-29 21:16:02,837:train.py:189 -         run_log_save():    avg word perp:   16.70
2017-11-29 21:16:02,837:train.py:190 -         run_log_save():    acc trg words/s: 5517
2017-11-29 21:16:02,837:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:16:32,636:train.py:188 -         run_log_save(): Batch 1225, epoch 6/20:
2017-11-29 21:16:32,637:train.py:189 -         run_log_save():    avg word perp:   17.14
2017-11-29 21:16:32,637:train.py:190 -         run_log_save():    acc trg words/s: 5513
2017-11-29 21:16:32,637:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:17:02,470:train.py:148 -         sample_input(): Sample input data:
2017-11-29 21:17:02,470:train.py:149 -         sample_input(): Src: . krise Identitäts@@ großen einer vor sie steht , verliert Schwerpunkt geographischen ihren NATO die da _PAD
2017-11-29 21:17:02,470:train.py:150 -         sample_input(): Src len: 16
2017-11-29 21:17:02,471:train.py:151 -         sample_input(): Trg: _BOS by losing its geographic focus , NATO is now confronted with a major identity challenge . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:17:02,471:train.py:152 -         sample_input(): Tar: by losing its geographic focus , NATO is now confronted with a major identity challenge . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:17:02,471:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 21:17:02,471:train.py:188 -         run_log_save(): Batch 1325, epoch 6/20:
2017-11-29 21:17:02,471:train.py:189 -         run_log_save():    avg word perp:   16.80
2017-11-29 21:17:02,471:train.py:190 -         run_log_save():    acc trg words/s: 5509
2017-11-29 21:17:02,471:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:17:04,640:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.169421
2017-11-29 21:17:33,783:train.py:188 -         run_log_save(): Batch 1425, epoch 6/20:
2017-11-29 21:17:33,783:train.py:189 -         run_log_save():    avg word perp:   16.92
2017-11-29 21:17:33,783:train.py:190 -         run_log_save():    acc trg words/s: 5511
2017-11-29 21:17:33,783:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:18:03,243:train.py:188 -         run_log_save(): Batch 1525, epoch 6/20:
2017-11-29 21:18:03,243:train.py:189 -         run_log_save():    avg word perp:   16.71
2017-11-29 21:18:03,243:train.py:190 -         run_log_save():    acc trg words/s: 5511
2017-11-29 21:18:03,243:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:18:32,886:train.py:188 -         run_log_save(): Batch 1625, epoch 6/20:
2017-11-29 21:18:32,886:train.py:189 -         run_log_save():    avg word perp:   17.16
2017-11-29 21:18:32,886:train.py:190 -         run_log_save():    acc trg words/s: 5509
2017-11-29 21:18:32,887:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:19:02,707:train.py:188 -         run_log_save(): Batch 1725, epoch 6/20:
2017-11-29 21:19:02,707:train.py:189 -         run_log_save():    avg word perp:   16.58
2017-11-29 21:19:02,707:train.py:190 -         run_log_save():    acc trg words/s: 5508
2017-11-29 21:19:02,708:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:19:32,366:train.py:188 -         run_log_save(): Batch 1825, epoch 6/20:
2017-11-29 21:19:32,366:train.py:189 -         run_log_save():    avg word perp:   16.51
2017-11-29 21:19:32,366:train.py:190 -         run_log_save():    acc trg words/s: 5506
2017-11-29 21:19:32,366:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:20:02,255:train.py:188 -         run_log_save(): Batch 1925, epoch 6/20:
2017-11-29 21:20:02,256:train.py:189 -         run_log_save():    avg word perp:   16.81
2017-11-29 21:20:02,256:train.py:190 -         run_log_save():    acc trg words/s: 5505
2017-11-29 21:20:02,256:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:20:32,067:train.py:188 -         run_log_save(): Batch 2025, epoch 6/20:
2017-11-29 21:20:32,067:train.py:189 -         run_log_save():    avg word perp:   16.52
2017-11-29 21:20:32,067:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-29 21:20:32,067:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:21:02,125:train.py:188 -         run_log_save(): Batch 2125, epoch 6/20:
2017-11-29 21:21:02,126:train.py:189 -         run_log_save():    avg word perp:   16.19
2017-11-29 21:21:02,126:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-29 21:21:02,126:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:21:31,831:train.py:188 -         run_log_save(): Batch 2225, epoch 6/20:
2017-11-29 21:21:31,831:train.py:189 -         run_log_save():    avg word perp:   16.57
2017-11-29 21:21:31,831:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 21:21:31,831:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:22:01,401:train.py:148 -         sample_input(): Sample input data:
2017-11-29 21:22:01,401:train.py:149 -         sample_input(): Src: . anywhere sense business good make longer no will censorship , perhaps , day One _PAD _PAD
2017-11-29 21:22:01,401:train.py:150 -         sample_input(): Src len: 15
2017-11-29 21:22:01,401:train.py:151 -         sample_input(): Trg: _BOS one day , perhaps , censorship will no longer make good business sense anywhere . _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:22:01,401:train.py:152 -         sample_input(): Tar: one day , perhaps , censorship will no longer make good business sense anywhere . _EOS _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:22:01,402:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 21:22:01,402:train.py:188 -         run_log_save(): Batch 2325, epoch 6/20:
2017-11-29 21:22:01,402:train.py:189 -         run_log_save():    avg word perp:   16.35
2017-11-29 21:22:01,402:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-29 21:22:01,402:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:22:01,402:validator.py:225 -    validate_and_save(): Start validation
2017-11-29 21:22:01,402:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 21:22:44,135:validator.py:144 -             evaluate():   Translating line 100, average 0.425988099575 seconds/sent
2017-11-29 21:23:28,819:validator.py:144 -             evaluate():   Translating line 200, average 0.43641438961 seconds/sent
2017-11-29 21:24:10,189:validator.py:144 -             evaluate():   Translating line 300, average 0.428841892878 seconds/sent
2017-11-29 21:24:46,283:validator.py:144 -             evaluate():   Translating line 400, average 0.411866790056 seconds/sent
2017-11-29 21:25:32,346:validator.py:144 -             evaluate():   Translating line 500, average 0.421620103836 seconds/sent
2017-11-29 21:26:09,700:validator.py:144 -             evaluate():   Translating line 600, average 0.413605564833 seconds/sent
2017-11-29 21:26:47,768:validator.py:144 -             evaluate():   Translating line 700, average 0.408902108329 seconds/sent
2017-11-29 21:27:25,003:validator.py:144 -             evaluate():   Translating line 800, average 0.404333918691 seconds/sent
2017-11-29 21:27:56,165:validator.py:144 -             evaluate():   Translating line 900, average 0.39403226667 seconds/sent
2017-11-29 21:28:32,943:validator.py:144 -             evaluate():   Translating line 1000, average 0.391406697035 seconds/sent
2017-11-29 21:29:06,461:validator.py:144 -             evaluate():   Translating line 1100, average 0.386295264417 seconds/sent
2017-11-29 21:29:41,213:validator.py:144 -             evaluate():   Translating line 1200, average 0.383063847423 seconds/sent
2017-11-29 21:30:26,916:validator.py:144 -             evaluate():   Translating line 1300, average 0.388753830653 seconds/sent
2017-11-29 21:31:11,783:validator.py:144 -             evaluate():   Translating line 1400, average 0.39303321072 seconds/sent
2017-11-29 21:31:55,407:validator.py:144 -             evaluate():   Translating line 1500, average 0.395913965225 seconds/sent
2017-11-29 21:32:36,520:validator.py:144 -             evaluate():   Translating line 1600, average 0.396864785552 seconds/sent
2017-11-29 21:33:19,842:validator.py:144 -             evaluate():   Translating line 1700, average 0.399003371772 seconds/sent
2017-11-29 21:34:09,736:validator.py:144 -             evaluate():   Translating line 1800, average 0.404555190007 seconds/sent
2017-11-29 21:34:54,711:validator.py:144 -             evaluate():   Translating line 1900, average 0.406934020017 seconds/sent
2017-11-29 21:35:19,634:validator.py:153 -             evaluate(): Done translating.
2017-11-29 21:35:19,635:validator.py:154 -             evaluate(): dev perplexity: 108.653
2017-11-29 21:35:20,125:validator.py:160 -             evaluate(): BLEU = 9.46, 38.0/14.3/6.3/2.9 (BP=0.952, ratio=0.953, hyp_len=43148, ref_len=45274)

2017-11-29 21:35:20,126:validator.py:161 -             evaluate(): Validation took: 13.3098258972 minutes
2017-11-29 21:35:20,129:validator.py:196 -           maybe_save(): Current best bleus: 6.41
2017-11-29 21:35:20,129:validator.py:197 -           maybe_save(): Delete 6.41 & use 9.46 instead
2017-11-29 21:35:20,129:validator.py:207 -           maybe_save(): Delete ./nmt/saved_models/de2en/de2en-6.41.cpkt.data-00000-of-00001 & ./nmt/saved_models/de2en/de2en-6.41.cpkt.meta & ./nmt/saved_models/de2en/de2en-6.41.cpkt.index
2017-11-29 21:35:20,143:validator.py:213 -           maybe_save(): Save 9.46 to list of best bleu scores
2017-11-29 21:35:20,547:validator.py:217 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en/de2en-9.46.cpkt
2017-11-29 21:35:20,547:validator.py:218 -           maybe_save(): Best bleu scores so far: 9.46
2017-11-29 21:35:49,871:train.py:188 -         run_log_save(): Batch 2425, epoch 6/20:
2017-11-29 21:35:49,871:train.py:189 -         run_log_save():    avg word perp:   16.30
2017-11-29 21:35:49,871:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-29 21:35:49,871:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:36:19,477:train.py:188 -         run_log_save(): Batch 2525, epoch 6/20:
2017-11-29 21:36:19,477:train.py:189 -         run_log_save():    avg word perp:   16.09
2017-11-29 21:36:19,477:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-29 21:36:19,477:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:36:22,898:train.py:116 -         report_epoch(): Finish epoch 6
2017-11-29 21:36:22,898:train.py:117 -         report_epoch():     It takes 0:12:21.733847
2017-11-29 21:36:22,898:train.py:118 -         report_epoch():     Avergage # words/second    5501.62840356
2017-11-29 21:36:22,898:train.py:119 -         report_epoch():     Average seconds/batch    0.292597178265
2017-11-29 21:36:22,899:train.py:130 -         report_epoch():     train perplexity: 16.7779364006
2017-11-29 21:36:23,341:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.442667007446 seconds
2017-11-29 21:36:49,166:train.py:188 -         run_log_save(): Batch 90, epoch 7/20:
2017-11-29 21:36:49,167:train.py:189 -         run_log_save():    avg word perp:   14.01
2017-11-29 21:36:49,167:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 21:36:49,167:train.py:191 -         run_log_save():    acc sec/batch:   0.28
2017-11-29 21:37:18,967:train.py:188 -         run_log_save(): Batch 190, epoch 7/20:
2017-11-29 21:37:18,967:train.py:189 -         run_log_save():    avg word perp:   13.94
2017-11-29 21:37:18,967:train.py:190 -         run_log_save():    acc trg words/s: 5464
2017-11-29 21:37:18,967:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:37:48,105:train.py:188 -         run_log_save(): Batch 290, epoch 7/20:
2017-11-29 21:37:48,105:train.py:189 -         run_log_save():    avg word perp:   14.14
2017-11-29 21:37:48,105:train.py:190 -         run_log_save():    acc trg words/s: 5510
2017-11-29 21:37:48,105:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:38:17,605:train.py:188 -         run_log_save(): Batch 390, epoch 7/20:
2017-11-29 21:38:17,605:train.py:189 -         run_log_save():    avg word perp:   14.21
2017-11-29 21:38:17,605:train.py:190 -         run_log_save():    acc trg words/s: 5512
2017-11-29 21:38:17,606:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:38:47,559:train.py:188 -         run_log_save(): Batch 490, epoch 7/20:
2017-11-29 21:38:47,559:train.py:189 -         run_log_save():    avg word perp:   14.15
2017-11-29 21:38:47,559:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-29 21:38:47,559:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:39:17,237:train.py:188 -         run_log_save(): Batch 590, epoch 7/20:
2017-11-29 21:39:17,237:train.py:189 -         run_log_save():    avg word perp:   14.18
2017-11-29 21:39:17,237:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-29 21:39:17,237:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:39:46,530:train.py:188 -         run_log_save(): Batch 690, epoch 7/20:
2017-11-29 21:39:46,530:train.py:189 -         run_log_save():    avg word perp:   14.28
2017-11-29 21:39:46,530:train.py:190 -         run_log_save():    acc trg words/s: 5512
2017-11-29 21:39:46,530:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:40:15,874:train.py:148 -         sample_input(): Sample input data:
2017-11-29 21:40:15,874:train.py:149 -         sample_input(): Src: . anzuregen len müh@@ Textil@@ neuer Bau zum um , Jahrhunderts 20. des Anfang reichten % 8 @-@ 6 nur von raten Gewinn@@ _PAD
2017-11-29 21:40:15,874:train.py:150 -         sample_input(): Src len: 23
2017-11-29 21:40:15,874:train.py:151 -         sample_input(): Trg: _BOS profit rates of only 6 @-@ 8 % in the early twentieth century were enough to induce construction of new mills . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:40:15,875:train.py:152 -         sample_input(): Tar: profit rates of only 6 @-@ 8 % in the early twentieth century were enough to induce construction of new mills . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:40:15,875:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 21:40:15,875:train.py:188 -         run_log_save(): Batch 790, epoch 7/20:
2017-11-29 21:40:15,875:train.py:189 -         run_log_save():    avg word perp:   14.01
2017-11-29 21:40:15,875:train.py:190 -         run_log_save():    acc trg words/s: 5514
2017-11-29 21:40:15,875:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:40:18,063:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.187790
2017-11-29 21:40:47,719:train.py:188 -         run_log_save(): Batch 890, epoch 7/20:
2017-11-29 21:40:47,719:train.py:189 -         run_log_save():    avg word perp:   14.51
2017-11-29 21:40:47,719:train.py:190 -         run_log_save():    acc trg words/s: 5513
2017-11-29 21:40:47,719:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:41:17,327:train.py:188 -         run_log_save(): Batch 990, epoch 7/20:
2017-11-29 21:41:17,327:train.py:189 -         run_log_save():    avg word perp:   14.31
2017-11-29 21:41:17,327:train.py:190 -         run_log_save():    acc trg words/s: 5514
2017-11-29 21:41:17,327:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:41:46,627:train.py:188 -         run_log_save(): Batch 1090, epoch 7/20:
2017-11-29 21:41:46,627:train.py:189 -         run_log_save():    avg word perp:   14.35
2017-11-29 21:41:46,627:train.py:190 -         run_log_save():    acc trg words/s: 5516
2017-11-29 21:41:46,628:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:42:16,068:train.py:188 -         run_log_save(): Batch 1190, epoch 7/20:
2017-11-29 21:42:16,068:train.py:189 -         run_log_save():    avg word perp:   14.22
2017-11-29 21:42:16,068:train.py:190 -         run_log_save():    acc trg words/s: 5516
2017-11-29 21:42:16,068:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:42:45,561:train.py:188 -         run_log_save(): Batch 1290, epoch 7/20:
2017-11-29 21:42:45,562:train.py:189 -         run_log_save():    avg word perp:   14.08
2017-11-29 21:42:45,562:train.py:190 -         run_log_save():    acc trg words/s: 5513
2017-11-29 21:42:45,562:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:43:15,601:train.py:188 -         run_log_save(): Batch 1390, epoch 7/20:
2017-11-29 21:43:15,601:train.py:189 -         run_log_save():    avg word perp:   14.24
2017-11-29 21:43:15,602:train.py:190 -         run_log_save():    acc trg words/s: 5505
2017-11-29 21:43:15,602:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:43:44,772:train.py:188 -         run_log_save(): Batch 1490, epoch 7/20:
2017-11-29 21:43:44,772:train.py:189 -         run_log_save():    avg word perp:   14.29
2017-11-29 21:43:44,772:train.py:190 -         run_log_save():    acc trg words/s: 5506
2017-11-29 21:43:44,772:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:44:14,512:train.py:188 -         run_log_save(): Batch 1590, epoch 7/20:
2017-11-29 21:44:14,512:train.py:189 -         run_log_save():    avg word perp:   14.35
2017-11-29 21:44:14,512:train.py:190 -         run_log_save():    acc trg words/s: 5503
2017-11-29 21:44:14,512:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:44:44,298:train.py:188 -         run_log_save(): Batch 1690, epoch 7/20:
2017-11-29 21:44:44,298:train.py:189 -         run_log_save():    avg word perp:   14.63
2017-11-29 21:44:44,298:train.py:190 -         run_log_save():    acc trg words/s: 5505
2017-11-29 21:44:44,298:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:45:13,863:train.py:148 -         sample_input(): Sample input data:
2017-11-29 21:45:13,863:train.py:149 -         sample_input(): Src: . sind informiert unzureichend sie dass , liegen daran nur das kann , verleihen Ausdruck keinen Ungerechtigkeit diese über Empörung ihrer sie wenn _PAD
2017-11-29 21:45:13,863:train.py:150 -         sample_input(): Src len: 23
2017-11-29 21:45:13,863:train.py:151 -         sample_input(): Trg: _BOS if they are not expressing their outrage over the injustice of it all , it can only be because they are in@@ adequately informed . _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:45:13,863:train.py:152 -         sample_input(): Tar: if they are not expressing their outrage over the injustice of it all , it can only be because they are in@@ adequately informed . _EOS _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:45:13,863:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 21:45:13,863:train.py:188 -         run_log_save(): Batch 1790, epoch 7/20:
2017-11-29 21:45:13,863:train.py:189 -         run_log_save():    avg word perp:   14.17
2017-11-29 21:45:13,863:train.py:190 -         run_log_save():    acc trg words/s: 5503
2017-11-29 21:45:13,863:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:45:43,581:train.py:188 -         run_log_save(): Batch 1890, epoch 7/20:
2017-11-29 21:45:43,581:train.py:189 -         run_log_save():    avg word perp:   14.40
2017-11-29 21:45:43,581:train.py:190 -         run_log_save():    acc trg words/s: 5504
2017-11-29 21:45:43,581:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:46:13,042:train.py:188 -         run_log_save(): Batch 1990, epoch 7/20:
2017-11-29 21:46:13,042:train.py:189 -         run_log_save():    avg word perp:   14.39
2017-11-29 21:46:13,042:train.py:190 -         run_log_save():    acc trg words/s: 5505
2017-11-29 21:46:13,042:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:46:42,761:train.py:188 -         run_log_save(): Batch 2090, epoch 7/20:
2017-11-29 21:46:42,761:train.py:189 -         run_log_save():    avg word perp:   14.56
2017-11-29 21:46:42,761:train.py:190 -         run_log_save():    acc trg words/s: 5503
2017-11-29 21:46:42,761:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:47:12,776:train.py:188 -         run_log_save(): Batch 2190, epoch 7/20:
2017-11-29 21:47:12,781:train.py:189 -         run_log_save():    avg word perp:   14.18
2017-11-29 21:47:12,781:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-29 21:47:12,781:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:47:42,007:train.py:188 -         run_log_save(): Batch 2290, epoch 7/20:
2017-11-29 21:47:42,007:train.py:189 -         run_log_save():    avg word perp:   13.91
2017-11-29 21:47:42,007:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-29 21:47:42,007:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:48:11,603:train.py:188 -         run_log_save(): Batch 2390, epoch 7/20:
2017-11-29 21:48:11,604:train.py:189 -         run_log_save():    avg word perp:   13.96
2017-11-29 21:48:11,604:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-29 21:48:11,604:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:48:40,949:train.py:188 -         run_log_save(): Batch 2490, epoch 7/20:
2017-11-29 21:48:40,949:train.py:189 -         run_log_save():    avg word perp:   14.19
2017-11-29 21:48:40,949:train.py:190 -         run_log_save():    acc trg words/s: 5503
2017-11-29 21:48:40,949:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:48:54,972:train.py:116 -         report_epoch(): Finish epoch 7
2017-11-29 21:48:54,972:train.py:117 -         report_epoch():     It takes 0:12:21.511697
2017-11-29 21:48:54,972:train.py:118 -         report_epoch():     Avergage # words/second    5503.28877998
2017-11-29 21:48:54,972:train.py:119 -         report_epoch():     Average seconds/batch    0.292509545001
2017-11-29 21:48:54,972:train.py:130 -         report_epoch():     train perplexity: 14.2138361463
2017-11-29 21:48:55,405:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.432461023331 seconds
2017-11-29 21:49:11,037:train.py:188 -         run_log_save(): Batch 55, epoch 8/20:
2017-11-29 21:49:11,037:train.py:189 -         run_log_save():    avg word perp:   12.65
2017-11-29 21:49:11,037:train.py:190 -         run_log_save():    acc trg words/s: 5423
2017-11-29 21:49:11,038:train.py:191 -         run_log_save():    acc sec/batch:   0.28
2017-11-29 21:49:40,765:train.py:188 -         run_log_save(): Batch 155, epoch 8/20:
2017-11-29 21:49:40,765:train.py:189 -         run_log_save():    avg word perp:   11.94
2017-11-29 21:49:40,766:train.py:190 -         run_log_save():    acc trg words/s: 5439
2017-11-29 21:49:40,766:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:50:10,347:train.py:148 -         sample_input(): Sample input data:
2017-11-29 21:50:10,348:train.py:149 -         sample_input(): Src: . kümmern zu darum wenig sich , Wähler die für Gründe weitere eiten ein@@ ner@@ ld@@ ö@@ S@@ und - Staatsbürger @-@ Nicht vieler einschließlich - Soldaten freiwillige sind anderen zum und _PAD _PAD
2017-11-29 21:50:10,348:train.py:150 -         sample_input(): Src len: 32
2017-11-29 21:50:10,348:train.py:151 -         sample_input(): Trg: _BOS volunteer soldiers - including many non @-@ citizens - and mer@@ cen@@ ary units for manpower reduce even further the reasons for voters to care . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:50:10,348:train.py:152 -         sample_input(): Tar: volunteer soldiers - including many non @-@ citizens - and mer@@ cen@@ ary units for manpower reduce even further the reasons for voters to care . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:50:10,348:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 21:50:10,348:train.py:188 -         run_log_save(): Batch 255, epoch 8/20:
2017-11-29 21:50:10,348:train.py:189 -         run_log_save():    avg word perp:   12.10
2017-11-29 21:50:10,348:train.py:190 -         run_log_save():    acc trg words/s: 5469
2017-11-29 21:50:10,348:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:50:12,601:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.252633
2017-11-29 21:50:42,410:train.py:188 -         run_log_save(): Batch 355, epoch 8/20:
2017-11-29 21:50:42,410:train.py:189 -         run_log_save():    avg word perp:   12.31
2017-11-29 21:50:42,410:train.py:190 -         run_log_save():    acc trg words/s: 5478
2017-11-29 21:50:42,410:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:51:12,335:train.py:188 -         run_log_save(): Batch 455, epoch 8/20:
2017-11-29 21:51:12,336:train.py:189 -         run_log_save():    avg word perp:   12.73
2017-11-29 21:51:12,336:train.py:190 -         run_log_save():    acc trg words/s: 5478
2017-11-29 21:51:12,336:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:51:42,231:train.py:188 -         run_log_save(): Batch 555, epoch 8/20:
2017-11-29 21:51:42,231:train.py:189 -         run_log_save():    avg word perp:   12.46
2017-11-29 21:51:42,231:train.py:190 -         run_log_save():    acc trg words/s: 5471
2017-11-29 21:51:42,231:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:52:11,674:train.py:188 -         run_log_save(): Batch 655, epoch 8/20:
2017-11-29 21:52:11,674:train.py:189 -         run_log_save():    avg word perp:   12.42
2017-11-29 21:52:11,675:train.py:190 -         run_log_save():    acc trg words/s: 5475
2017-11-29 21:52:11,675:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:52:41,325:train.py:188 -         run_log_save(): Batch 755, epoch 8/20:
2017-11-29 21:52:41,325:train.py:189 -         run_log_save():    avg word perp:   12.51
2017-11-29 21:52:41,325:train.py:190 -         run_log_save():    acc trg words/s: 5480
2017-11-29 21:52:41,325:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:53:10,574:train.py:188 -         run_log_save(): Batch 855, epoch 8/20:
2017-11-29 21:53:10,574:train.py:189 -         run_log_save():    avg word perp:   12.49
2017-11-29 21:53:10,574:train.py:190 -         run_log_save():    acc trg words/s: 5486
2017-11-29 21:53:10,574:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:53:40,503:train.py:188 -         run_log_save(): Batch 955, epoch 8/20:
2017-11-29 21:53:40,504:train.py:189 -         run_log_save():    avg word perp:   12.38
2017-11-29 21:53:40,504:train.py:190 -         run_log_save():    acc trg words/s: 5481
2017-11-29 21:53:40,504:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:54:10,180:train.py:188 -         run_log_save(): Batch 1055, epoch 8/20:
2017-11-29 21:54:10,180:train.py:189 -         run_log_save():    avg word perp:   12.26
2017-11-29 21:54:10,180:train.py:190 -         run_log_save():    acc trg words/s: 5479
2017-11-29 21:54:10,180:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:54:39,479:train.py:188 -         run_log_save(): Batch 1155, epoch 8/20:
2017-11-29 21:54:39,479:train.py:189 -         run_log_save():    avg word perp:   12.65
2017-11-29 21:54:39,479:train.py:190 -         run_log_save():    acc trg words/s: 5486
2017-11-29 21:54:39,479:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:55:09,202:train.py:148 -         sample_input(): Sample input data:
2017-11-29 21:55:09,202:train.py:149 -         sample_input(): Src: . erzielen zu Wirkung diese um , müssten werden ausgewiesen zonen verbots@@ ang@@ F@@ als mes rau@@ Lebens@@ verfügbaren des % 50 @-@ 30 dass , wir wissen Forschung wissenschaftlichen der aus _PAD _PAD
2017-11-29 21:55:09,202:train.py:150 -         sample_input(): Src len: 32
2017-11-29 21:55:09,202:train.py:151 -         sample_input(): Trg: _BOS scientific evidence indicates that , to be effective , 30 @-@ 50 % of available habitat should be set aside as no @-@ take zones . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:55:09,203:train.py:152 -         sample_input(): Tar: scientific evidence indicates that , to be effective , 30 @-@ 50 % of available habitat should be set aside as no @-@ take zones . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 21:55:09,203:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 21:55:09,203:train.py:188 -         run_log_save(): Batch 1255, epoch 8/20:
2017-11-29 21:55:09,203:train.py:189 -         run_log_save():    avg word perp:   12.77
2017-11-29 21:55:09,203:train.py:190 -         run_log_save():    acc trg words/s: 5488
2017-11-29 21:55:09,203:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:55:38,790:train.py:188 -         run_log_save(): Batch 1355, epoch 8/20:
2017-11-29 21:55:38,790:train.py:189 -         run_log_save():    avg word perp:   12.68
2017-11-29 21:55:38,790:train.py:190 -         run_log_save():    acc trg words/s: 5492
2017-11-29 21:55:38,790:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:56:07,994:train.py:188 -         run_log_save(): Batch 1455, epoch 8/20:
2017-11-29 21:56:07,994:train.py:189 -         run_log_save():    avg word perp:   12.56
2017-11-29 21:56:07,994:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-29 21:56:07,994:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:56:37,921:train.py:188 -         run_log_save(): Batch 1555, epoch 8/20:
2017-11-29 21:56:37,921:train.py:189 -         run_log_save():    avg word perp:   12.71
2017-11-29 21:56:37,921:train.py:190 -         run_log_save():    acc trg words/s: 5493
2017-11-29 21:56:37,922:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:57:07,100:train.py:188 -         run_log_save(): Batch 1655, epoch 8/20:
2017-11-29 21:57:07,100:train.py:189 -         run_log_save():    avg word perp:   12.71
2017-11-29 21:57:07,100:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 21:57:07,100:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:57:36,721:train.py:188 -         run_log_save(): Batch 1755, epoch 8/20:
2017-11-29 21:57:36,721:train.py:189 -         run_log_save():    avg word perp:   12.72
2017-11-29 21:57:36,722:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 21:57:36,722:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:58:05,898:train.py:188 -         run_log_save(): Batch 1855, epoch 8/20:
2017-11-29 21:58:05,898:train.py:189 -         run_log_save():    avg word perp:   12.38
2017-11-29 21:58:05,898:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-29 21:58:05,898:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:58:35,222:train.py:188 -         run_log_save(): Batch 1955, epoch 8/20:
2017-11-29 21:58:35,222:train.py:189 -         run_log_save():    avg word perp:   12.55
2017-11-29 21:58:35,222:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-29 21:58:35,222:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:59:04,787:train.py:188 -         run_log_save(): Batch 2055, epoch 8/20:
2017-11-29 21:59:04,787:train.py:189 -         run_log_save():    avg word perp:   12.61
2017-11-29 21:59:04,787:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-29 21:59:04,787:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 21:59:34,500:train.py:188 -         run_log_save(): Batch 2155, epoch 8/20:
2017-11-29 21:59:34,500:train.py:189 -         run_log_save():    avg word perp:   12.52
2017-11-29 21:59:34,500:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-29 21:59:34,500:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:00:04,317:train.py:148 -         sample_input(): Sample input data:
2017-11-29 22:00:04,317:train.py:149 -         sample_input(): Src: . Jahre ziger zwan@@ der Beginn zu Stalin wie , können stehen s Staat@@ des Spitze der an plötzlich tiere Last@@ politischen losen anspruchs@@ diese daß , jedoch weiß Bevölkerung russische die _PAD _PAD
2017-11-29 22:00:04,317:train.py:150 -         sample_input(): Src len: 32
2017-11-29 22:00:04,317:train.py:151 -         sample_input(): Trg: _BOS Russians know that , one day , these un@@ assuming political be@@ asts of burden suddenly come out on top , as Stalin did in the early 19@@ 20@@ s . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:00:04,317:train.py:152 -         sample_input(): Tar: Russians know that , one day , these un@@ assuming political be@@ asts of burden suddenly come out on top , as Stalin did in the early 19@@ 20@@ s . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:00:04,317:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 22:00:04,317:train.py:188 -         run_log_save(): Batch 2255, epoch 8/20:
2017-11-29 22:00:04,317:train.py:189 -         run_log_save():    avg word perp:   12.73
2017-11-29 22:00:04,317:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-29 22:00:04,317:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:00:06,557:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.239545
2017-11-29 22:00:06,557:validator.py:225 -    validate_and_save(): Start validation
2017-11-29 22:00:06,557:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 22:00:48,981:validator.py:144 -             evaluate():   Translating line 100, average 0.42370909214 seconds/sent
2017-11-29 22:01:33,008:validator.py:144 -             evaluate():   Translating line 200, average 0.431990445852 seconds/sent
2017-11-29 22:02:10,144:validator.py:144 -             evaluate():   Translating line 300, average 0.411779616674 seconds/sent
2017-11-29 22:02:47,019:validator.py:144 -             evaluate():   Translating line 400, average 0.401021937728 seconds/sent
2017-11-29 22:03:30,653:validator.py:144 -             evaluate():   Translating line 500, average 0.40808671999 seconds/sent
2017-11-29 22:04:05,775:validator.py:144 -             evaluate():   Translating line 600, average 0.398607935111 seconds/sent
2017-11-29 22:04:42,607:validator.py:144 -             evaluate():   Translating line 700, average 0.394281207153 seconds/sent
2017-11-29 22:05:17,714:validator.py:144 -             evaluate():   Translating line 800, average 0.388880426288 seconds/sent
2017-11-29 22:05:47,749:validator.py:144 -             evaluate():   Translating line 900, average 0.379043215646 seconds/sent
2017-11-29 22:06:24,048:validator.py:144 -             evaluate():   Translating line 1000, average 0.377437535048 seconds/sent
2017-11-29 22:06:57,306:validator.py:144 -             evaluate():   Translating line 1100, average 0.373360242844 seconds/sent
2017-11-29 22:07:30,235:validator.py:144 -             evaluate():   Translating line 1200, average 0.369687820872 seconds/sent
2017-11-29 22:08:13,184:validator.py:144 -             evaluate():   Translating line 1300, average 0.374287370168 seconds/sent
2017-11-29 22:08:59,457:validator.py:144 -             evaluate():   Translating line 1400, average 0.380604832172 seconds/sent
2017-11-29 22:09:47,994:validator.py:144 -             evaluate():   Translating line 1500, average 0.387589117368 seconds/sent
2017-11-29 22:10:34,941:validator.py:144 -             evaluate():   Translating line 1600, average 0.392707130015 seconds/sent
2017-11-29 22:11:17,056:validator.py:144 -             evaluate():   Translating line 1700, average 0.394380104121 seconds/sent
2017-11-29 22:12:08,936:validator.py:144 -             evaluate():   Translating line 1800, average 0.401292316119 seconds/sent
2017-11-29 22:12:55,229:validator.py:144 -             evaluate():   Translating line 1900, average 0.404536230062 seconds/sent
2017-11-29 22:13:22,030:validator.py:153 -             evaluate(): Done translating.
2017-11-29 22:13:22,031:validator.py:154 -             evaluate(): dev perplexity: 89.493
2017-11-29 22:13:22,526:validator.py:160 -             evaluate(): BLEU = 10.64, 38.6/15.2/7.0/3.3 (BP=0.983, ratio=0.983, hyp_len=44520, ref_len=45274)

2017-11-29 22:13:22,526:validator.py:161 -             evaluate(): Validation took: 13.2652713339 minutes
2017-11-29 22:13:22,529:validator.py:196 -           maybe_save(): Current best bleus: 9.46
2017-11-29 22:13:22,529:validator.py:197 -           maybe_save(): Delete 9.46 & use 10.64 instead
2017-11-29 22:13:22,529:validator.py:207 -           maybe_save(): Delete ./nmt/saved_models/de2en/de2en-9.46.cpkt.data-00000-of-00001 & ./nmt/saved_models/de2en/de2en-9.46.cpkt.meta & ./nmt/saved_models/de2en/de2en-9.46.cpkt.index
2017-11-29 22:13:22,544:validator.py:213 -           maybe_save(): Save 10.64 to list of best bleu scores
2017-11-29 22:13:22,935:validator.py:217 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en/de2en-10.64.cpkt
2017-11-29 22:13:22,936:validator.py:218 -           maybe_save(): Best bleu scores so far: 10.64
2017-11-29 22:13:52,162:train.py:188 -         run_log_save(): Batch 2355, epoch 8/20:
2017-11-29 22:13:52,162:train.py:189 -         run_log_save():    avg word perp:   12.62
2017-11-29 22:13:52,162:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-29 22:13:52,162:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:14:21,779:train.py:188 -         run_log_save(): Batch 2455, epoch 8/20:
2017-11-29 22:14:21,779:train.py:189 -         run_log_save():    avg word perp:   12.59
2017-11-29 22:14:21,779:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-29 22:14:21,779:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:14:45,940:train.py:116 -         report_epoch(): Finish epoch 8
2017-11-29 22:14:45,941:train.py:117 -         report_epoch():     It takes 0:12:21.757022
2017-11-29 22:14:45,941:train.py:118 -         report_epoch():     Avergage # words/second    5501.51853074
2017-11-29 22:14:45,941:train.py:119 -         report_epoch():     Average seconds/batch    0.292606320184
2017-11-29 22:14:45,941:train.py:130 -         report_epoch():     train perplexity: 12.4943187942
2017-11-29 22:14:46,381:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.439548969269 seconds
2017-11-29 22:14:52,399:train.py:188 -         run_log_save(): Batch 20, epoch 9/20:
2017-11-29 22:14:52,399:train.py:189 -         run_log_save():    avg word perp:   12.29
2017-11-29 22:14:52,399:train.py:190 -         run_log_save():    acc trg words/s: 5393
2017-11-29 22:14:52,400:train.py:191 -         run_log_save():    acc sec/batch:   0.30
2017-11-29 22:15:21,667:train.py:188 -         run_log_save(): Batch 120, epoch 9/20:
2017-11-29 22:15:21,668:train.py:189 -         run_log_save():    avg word perp:   10.69
2017-11-29 22:15:21,668:train.py:190 -         run_log_save():    acc trg words/s: 5526
2017-11-29 22:15:21,668:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:15:51,476:train.py:188 -         run_log_save(): Batch 220, epoch 9/20:
2017-11-29 22:15:51,476:train.py:189 -         run_log_save():    avg word perp:   11.01
2017-11-29 22:15:51,476:train.py:190 -         run_log_save():    acc trg words/s: 5515
2017-11-29 22:15:51,476:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:16:20,964:train.py:188 -         run_log_save(): Batch 320, epoch 9/20:
2017-11-29 22:16:20,964:train.py:189 -         run_log_save():    avg word perp:   11.21
2017-11-29 22:16:20,964:train.py:190 -         run_log_save():    acc trg words/s: 5523
2017-11-29 22:16:20,964:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:16:50,194:train.py:188 -         run_log_save(): Batch 420, epoch 9/20:
2017-11-29 22:16:50,194:train.py:189 -         run_log_save():    avg word perp:   11.10
2017-11-29 22:16:50,194:train.py:190 -         run_log_save():    acc trg words/s: 5523
2017-11-29 22:16:50,194:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:17:19,730:train.py:188 -         run_log_save(): Batch 520, epoch 9/20:
2017-11-29 22:17:19,731:train.py:189 -         run_log_save():    avg word perp:   11.14
2017-11-29 22:17:19,731:train.py:190 -         run_log_save():    acc trg words/s: 5523
2017-11-29 22:17:19,731:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:17:49,475:train.py:188 -         run_log_save(): Batch 620, epoch 9/20:
2017-11-29 22:17:49,475:train.py:189 -         run_log_save():    avg word perp:   11.10
2017-11-29 22:17:49,475:train.py:190 -         run_log_save():    acc trg words/s: 5515
2017-11-29 22:17:49,475:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:18:19,072:train.py:148 -         sample_input(): Sample input data:
2017-11-29 22:18:19,072:train.py:149 -         sample_input(): Src: . haben tragen zu schwersten am jetzt bereits Unterernährung und Konflikte bewaffnete , Armut , Krankheiten durch die , &quot; Milliarde ste unter@@ &quot; die : geht schlechtesten am schon ohnehin es denen , treffen härtesten am Planeten unserem auf jene eindeutig werden Auswirkungen diese _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:18:19,072:train.py:150 -         sample_input(): Src len: 45
2017-11-29 22:18:19,072:train.py:151 -         sample_input(): Trg: _BOS these impacts will clearly hit the planet &apos;s worst @-@ off inhabitants hardest : the &quot; bottom billion &quot; who already bear the heavi@@ est burden of disease , poverty , conflict and malnutrition . &amp; # 160 ; _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:18:19,072:train.py:152 -         sample_input(): Tar: these impacts will clearly hit the planet &apos;s worst @-@ off inhabitants hardest : the &quot; bottom billion &quot; who already bear the heavi@@ est burden of disease , poverty , conflict and malnutrition . &amp; # 160 ; _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:18:19,073:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 22:18:19,073:train.py:188 -         run_log_save(): Batch 720, epoch 9/20:
2017-11-29 22:18:19,073:train.py:189 -         run_log_save():    avg word perp:   11.14
2017-11-29 22:18:19,073:train.py:190 -         run_log_save():    acc trg words/s: 5510
2017-11-29 22:18:19,073:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:18:48,535:train.py:188 -         run_log_save(): Batch 820, epoch 9/20:
2017-11-29 22:18:48,536:train.py:189 -         run_log_save():    avg word perp:   11.35
2017-11-29 22:18:48,536:train.py:190 -         run_log_save():    acc trg words/s: 5515
2017-11-29 22:18:48,536:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:19:17,886:train.py:188 -         run_log_save(): Batch 920, epoch 9/20:
2017-11-29 22:19:17,887:train.py:189 -         run_log_save():    avg word perp:   11.14
2017-11-29 22:19:17,887:train.py:190 -         run_log_save():    acc trg words/s: 5518
2017-11-29 22:19:17,887:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:19:47,169:train.py:188 -         run_log_save(): Batch 1020, epoch 9/20:
2017-11-29 22:19:47,169:train.py:189 -         run_log_save():    avg word perp:   11.32
2017-11-29 22:19:47,169:train.py:190 -         run_log_save():    acc trg words/s: 5522
2017-11-29 22:19:47,169:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:20:16,539:train.py:188 -         run_log_save(): Batch 1120, epoch 9/20:
2017-11-29 22:20:16,539:train.py:189 -         run_log_save():    avg word perp:   10.99
2017-11-29 22:20:16,539:train.py:190 -         run_log_save():    acc trg words/s: 5523
2017-11-29 22:20:16,539:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:20:46,061:train.py:188 -         run_log_save(): Batch 1220, epoch 9/20:
2017-11-29 22:20:46,061:train.py:189 -         run_log_save():    avg word perp:   11.18
2017-11-29 22:20:46,061:train.py:190 -         run_log_save():    acc trg words/s: 5523
2017-11-29 22:20:46,061:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:21:15,335:train.py:188 -         run_log_save(): Batch 1320, epoch 9/20:
2017-11-29 22:21:15,335:train.py:189 -         run_log_save():    avg word perp:   11.14
2017-11-29 22:21:15,335:train.py:190 -         run_log_save():    acc trg words/s: 5524
2017-11-29 22:21:15,335:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:21:44,758:train.py:188 -         run_log_save(): Batch 1420, epoch 9/20:
2017-11-29 22:21:44,759:train.py:189 -         run_log_save():    avg word perp:   11.44
2017-11-29 22:21:44,759:train.py:190 -         run_log_save():    acc trg words/s: 5524
2017-11-29 22:21:44,759:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:22:14,398:train.py:188 -         run_log_save(): Batch 1520, epoch 9/20:
2017-11-29 22:22:14,398:train.py:189 -         run_log_save():    avg word perp:   11.44
2017-11-29 22:22:14,398:train.py:190 -         run_log_save():    acc trg words/s: 5520
2017-11-29 22:22:14,398:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:22:44,014:train.py:188 -         run_log_save(): Batch 1620, epoch 9/20:
2017-11-29 22:22:44,014:train.py:189 -         run_log_save():    avg word perp:   11.44
2017-11-29 22:22:44,015:train.py:190 -         run_log_save():    acc trg words/s: 5517
2017-11-29 22:22:44,015:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:23:13,741:train.py:148 -         sample_input(): Sample input data:
2017-11-29 22:23:13,741:train.py:149 -         sample_input(): Src: . wird einschlagen Präsident amerikanische nächste der die , nehmen weg@@ vor@@ Richtung die , definiert Brown Gordon Premierminister neue der sie wie , Linie politische gegenwärtige seine könnte , darstellt dilemma chts@@ ma@@ Groß@@ Amerikas von version atur@@ Mini@@ eine lediglich Lage Großbritanniens obwohl _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:23:13,741:train.py:150 -         sample_input(): Src len: 45
2017-11-29 22:23:13,741:train.py:151 -         sample_input(): Trg: _BOS though only a mini@@ ature version of America &apos;s imperial predicament , Britain &apos;s current policy , as its new prime minister , Gordon Brown , is defining it , may anticipate the direction taken by the next American president . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:23:13,742:train.py:152 -         sample_input(): Tar: though only a mini@@ ature version of America &apos;s imperial predicament , Britain &apos;s current policy , as its new prime minister , Gordon Brown , is defining it , may anticipate the direction taken by the next American president . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:23:13,742:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 22:23:13,742:train.py:188 -         run_log_save(): Batch 1720, epoch 9/20:
2017-11-29 22:23:13,742:train.py:189 -         run_log_save():    avg word perp:   11.29
2017-11-29 22:23:13,742:train.py:190 -         run_log_save():    acc trg words/s: 5514
2017-11-29 22:23:13,742:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:23:15,904:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.161966
2017-11-29 22:23:45,608:train.py:188 -         run_log_save(): Batch 1820, epoch 9/20:
2017-11-29 22:23:45,608:train.py:189 -         run_log_save():    avg word perp:   11.52
2017-11-29 22:23:45,608:train.py:190 -         run_log_save():    acc trg words/s: 5513
2017-11-29 22:23:45,608:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:24:15,241:train.py:188 -         run_log_save(): Batch 1920, epoch 9/20:
2017-11-29 22:24:15,241:train.py:189 -         run_log_save():    avg word perp:   11.22
2017-11-29 22:24:15,241:train.py:190 -         run_log_save():    acc trg words/s: 5513
2017-11-29 22:24:15,241:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:24:44,815:train.py:188 -         run_log_save(): Batch 2020, epoch 9/20:
2017-11-29 22:24:44,815:train.py:189 -         run_log_save():    avg word perp:   11.70
2017-11-29 22:24:44,815:train.py:190 -         run_log_save():    acc trg words/s: 5512
2017-11-29 22:24:44,815:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:25:14,832:train.py:188 -         run_log_save(): Batch 2120, epoch 9/20:
2017-11-29 22:25:14,832:train.py:189 -         run_log_save():    avg word perp:   11.37
2017-11-29 22:25:14,832:train.py:190 -         run_log_save():    acc trg words/s: 5510
2017-11-29 22:25:14,832:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:25:44,459:train.py:188 -         run_log_save(): Batch 2220, epoch 9/20:
2017-11-29 22:25:44,459:train.py:189 -         run_log_save():    avg word perp:   11.41
2017-11-29 22:25:44,459:train.py:190 -         run_log_save():    acc trg words/s: 5509
2017-11-29 22:25:44,459:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:26:13,546:train.py:188 -         run_log_save(): Batch 2320, epoch 9/20:
2017-11-29 22:26:13,546:train.py:189 -         run_log_save():    avg word perp:   11.53
2017-11-29 22:26:13,546:train.py:190 -         run_log_save():    acc trg words/s: 5510
2017-11-29 22:26:13,546:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:26:43,644:train.py:188 -         run_log_save(): Batch 2420, epoch 9/20:
2017-11-29 22:26:43,644:train.py:189 -         run_log_save():    avg word perp:   11.52
2017-11-29 22:26:43,644:train.py:190 -         run_log_save():    acc trg words/s: 5506
2017-11-29 22:26:43,644:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:27:13,389:train.py:188 -         run_log_save(): Batch 2520, epoch 9/20:
2017-11-29 22:27:13,390:train.py:189 -         run_log_save():    avg word perp:   11.39
2017-11-29 22:27:13,390:train.py:190 -         run_log_save():    acc trg words/s: 5506
2017-11-29 22:27:13,390:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:27:17,495:train.py:116 -         report_epoch(): Finish epoch 9
2017-11-29 22:27:17,495:train.py:117 -         report_epoch():     It takes 0:12:21.055073
2017-11-29 22:27:17,495:train.py:118 -         report_epoch():     Avergage # words/second    5506.73647774
2017-11-29 22:27:17,495:train.py:119 -         report_epoch():     Average seconds/batch    0.292329417178
2017-11-29 22:27:17,495:train.py:130 -         report_epoch():     train perplexity: 11.2578947206
2017-11-29 22:27:17,921:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.425508022308 seconds
2017-11-29 22:27:42,579:train.py:188 -         run_log_save(): Batch 85, epoch 10/20:
2017-11-29 22:27:42,579:train.py:189 -         run_log_save():    avg word perp:   9.58
2017-11-29 22:27:42,579:train.py:190 -         run_log_save():    acc trg words/s: 5390
2017-11-29 22:27:42,579:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:28:12,293:train.py:148 -         sample_input(): Sample input data:
2017-11-29 22:28:12,293:train.py:149 -         sample_input(): Src: . aus IWF dem mit Rettungsmaßnahmen finanzielle Länder die handelten , melden anzu@@ Zahlungsunfähigkeit statt _PAD _PAD
2017-11-29 22:28:12,293:train.py:150 -         sample_input(): Src len: 15
2017-11-29 22:28:12,293:train.py:151 -         sample_input(): Trg: _BOS instead of defaulting , countries arranged rescue packages with the IMF . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:28:12,293:train.py:152 -         sample_input(): Tar: instead of defaulting , countries arranged rescue packages with the IMF . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:28:12,293:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 22:28:12,294:train.py:188 -         run_log_save(): Batch 185, epoch 10/20:
2017-11-29 22:28:12,294:train.py:189 -         run_log_save():    avg word perp:   9.86
2017-11-29 22:28:12,294:train.py:190 -         run_log_save():    acc trg words/s: 5447
2017-11-29 22:28:12,294:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:28:41,884:train.py:188 -         run_log_save(): Batch 285, epoch 10/20:
2017-11-29 22:28:41,884:train.py:189 -         run_log_save():    avg word perp:   9.74
2017-11-29 22:28:41,884:train.py:190 -         run_log_save():    acc trg words/s: 5478
2017-11-29 22:28:41,884:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:29:10,997:train.py:188 -         run_log_save(): Batch 385, epoch 10/20:
2017-11-29 22:29:10,997:train.py:189 -         run_log_save():    avg word perp:   9.70
2017-11-29 22:29:10,997:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 22:29:10,997:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:29:40,926:train.py:188 -         run_log_save(): Batch 485, epoch 10/20:
2017-11-29 22:29:40,927:train.py:189 -         run_log_save():    avg word perp:   9.92
2017-11-29 22:29:40,927:train.py:190 -         run_log_save():    acc trg words/s: 5478
2017-11-29 22:29:40,927:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:30:10,303:train.py:188 -         run_log_save(): Batch 585, epoch 10/20:
2017-11-29 22:30:10,304:train.py:189 -         run_log_save():    avg word perp:   10.17
2017-11-29 22:30:10,304:train.py:190 -         run_log_save():    acc trg words/s: 5482
2017-11-29 22:30:10,304:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:30:40,253:train.py:188 -         run_log_save(): Batch 685, epoch 10/20:
2017-11-29 22:30:40,254:train.py:189 -         run_log_save():    avg word perp:   10.29
2017-11-29 22:30:40,254:train.py:190 -         run_log_save():    acc trg words/s: 5472
2017-11-29 22:30:40,254:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:31:09,422:train.py:188 -         run_log_save(): Batch 785, epoch 10/20:
2017-11-29 22:31:09,422:train.py:189 -         run_log_save():    avg word perp:   10.17
2017-11-29 22:31:09,423:train.py:190 -         run_log_save():    acc trg words/s: 5481
2017-11-29 22:31:09,423:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:31:38,897:train.py:188 -         run_log_save(): Batch 885, epoch 10/20:
2017-11-29 22:31:38,898:train.py:189 -         run_log_save():    avg word perp:   10.10
2017-11-29 22:31:38,898:train.py:190 -         run_log_save():    acc trg words/s: 5481
2017-11-29 22:31:38,898:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:32:08,581:train.py:188 -         run_log_save(): Batch 985, epoch 10/20:
2017-11-29 22:32:08,581:train.py:189 -         run_log_save():    avg word perp:   10.23
2017-11-29 22:32:08,581:train.py:190 -         run_log_save():    acc trg words/s: 5482
2017-11-29 22:32:08,581:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:32:37,981:train.py:188 -         run_log_save(): Batch 1085, epoch 10/20:
2017-11-29 22:32:37,982:train.py:189 -         run_log_save():    avg word perp:   10.09
2017-11-29 22:32:37,982:train.py:190 -         run_log_save():    acc trg words/s: 5488
2017-11-29 22:32:37,982:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:33:07,956:train.py:148 -         sample_input(): Sample input data:
2017-11-29 22:33:07,956:train.py:149 -         sample_input(): Src: ? fällt der , ein Dominost@@ arabische autoritäre erste der nur Tunesien ist : Paris _PAD _PAD
2017-11-29 22:33:07,956:train.py:150 -         sample_input(): Src len: 15
2017-11-29 22:33:07,956:train.py:151 -         sample_input(): Trg: _BOS Paris - Is Tunisia the first Arab authoritarian domino to fall ? _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:33:07,956:train.py:152 -         sample_input(): Tar: Paris - Is Tunisia the first Arab authoritarian domino to fall ? _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:33:07,956:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 22:33:07,956:train.py:188 -         run_log_save(): Batch 1185, epoch 10/20:
2017-11-29 22:33:07,956:train.py:189 -         run_log_save():    avg word perp:   10.52
2017-11-29 22:33:07,956:train.py:190 -         run_log_save():    acc trg words/s: 5482
2017-11-29 22:33:07,957:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:33:10,119:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.162142
2017-11-29 22:33:39,173:train.py:188 -         run_log_save(): Batch 1285, epoch 10/20:
2017-11-29 22:33:39,173:train.py:189 -         run_log_save():    avg word perp:   10.33
2017-11-29 22:33:39,173:train.py:190 -         run_log_save():    acc trg words/s: 5491
2017-11-29 22:33:39,174:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:34:08,767:train.py:188 -         run_log_save(): Batch 1385, epoch 10/20:
2017-11-29 22:34:08,767:train.py:189 -         run_log_save():    avg word perp:   10.60
2017-11-29 22:34:08,767:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-29 22:34:08,767:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:34:38,315:train.py:188 -         run_log_save(): Batch 1485, epoch 10/20:
2017-11-29 22:34:38,315:train.py:189 -         run_log_save():    avg word perp:   10.36
2017-11-29 22:34:38,315:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 22:34:38,315:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:35:07,850:train.py:188 -         run_log_save(): Batch 1585, epoch 10/20:
2017-11-29 22:35:07,850:train.py:189 -         run_log_save():    avg word perp:   10.26
2017-11-29 22:35:07,851:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 22:35:07,851:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:35:37,534:train.py:188 -         run_log_save(): Batch 1685, epoch 10/20:
2017-11-29 22:35:37,534:train.py:189 -         run_log_save():    avg word perp:   10.47
2017-11-29 22:35:37,535:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 22:35:37,535:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:36:07,405:train.py:188 -         run_log_save(): Batch 1785, epoch 10/20:
2017-11-29 22:36:07,405:train.py:189 -         run_log_save():    avg word perp:   10.46
2017-11-29 22:36:07,405:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-29 22:36:07,405:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:36:36,574:train.py:188 -         run_log_save(): Batch 1885, epoch 10/20:
2017-11-29 22:36:36,574:train.py:189 -         run_log_save():    avg word perp:   10.57
2017-11-29 22:36:36,574:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 22:36:36,574:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:37:06,500:train.py:188 -         run_log_save(): Batch 1985, epoch 10/20:
2017-11-29 22:37:06,500:train.py:189 -         run_log_save():    avg word perp:   10.68
2017-11-29 22:37:06,501:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 22:37:06,501:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:37:35,774:train.py:188 -         run_log_save(): Batch 2085, epoch 10/20:
2017-11-29 22:37:35,774:train.py:189 -         run_log_save():    avg word perp:   10.59
2017-11-29 22:37:35,774:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-29 22:37:35,775:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:38:05,401:train.py:148 -         sample_input(): Sample input data:
2017-11-29 22:38:05,402:train.py:149 -         sample_input(): Src: . befreien Risiken bestehenden von China USA die müssen , kann werden toleriert das damit aber _PAD _PAD
2017-11-29 22:38:05,402:train.py:150 -         sample_input(): Src len: 16
2017-11-29 22:38:05,402:train.py:151 -         sample_input(): Trg: _BOS but for this to be tolerable , the US needs to relieve China of existing risks . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:38:05,402:train.py:152 -         sample_input(): Tar: but for this to be tolerable , the US needs to relieve China of existing risks . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:38:05,402:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 22:38:05,402:train.py:188 -         run_log_save(): Batch 2185, epoch 10/20:
2017-11-29 22:38:05,402:train.py:189 -         run_log_save():    avg word perp:   10.68
2017-11-29 22:38:05,402:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-29 22:38:05,402:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:38:05,402:validator.py:225 -    validate_and_save(): Start validation
2017-11-29 22:38:05,402:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 22:38:45,992:validator.py:144 -             evaluate():   Translating line 100, average 0.4046104002 seconds/sent
2017-11-29 22:39:27,295:validator.py:144 -             evaluate():   Translating line 200, average 0.408824549913 seconds/sent
2017-11-29 22:40:01,377:validator.py:144 -             evaluate():   Translating line 300, average 0.386153919697 seconds/sent
2017-11-29 22:40:34,166:validator.py:144 -             evaluate():   Translating line 400, average 0.37158901751 seconds/sent
2017-11-29 22:41:16,791:validator.py:144 -             evaluate():   Translating line 500, average 0.382520175934 seconds/sent
2017-11-29 22:41:51,178:validator.py:144 -             evaluate():   Translating line 600, average 0.376078428427 seconds/sent
2017-11-29 22:42:28,888:validator.py:144 -             evaluate():   Translating line 700, average 0.376224637032 seconds/sent
2017-11-29 22:43:04,721:validator.py:144 -             evaluate():   Translating line 800, average 0.373987533748 seconds/sent
2017-11-29 22:43:35,097:validator.py:144 -             evaluate():   Translating line 900, average 0.366184752252 seconds/sent
2017-11-29 22:44:10,714:validator.py:144 -             evaluate():   Translating line 1000, average 0.365183691025 seconds/sent
2017-11-29 22:44:45,748:validator.py:144 -             evaluate():   Translating line 1100, average 0.363834181916 seconds/sent
2017-11-29 22:45:19,765:validator.py:144 -             evaluate():   Translating line 1200, average 0.361861933271 seconds/sent
2017-11-29 22:46:03,266:validator.py:144 -             evaluate():   Translating line 1300, average 0.367488611478 seconds/sent
2017-11-29 22:46:45,338:validator.py:144 -             evaluate():   Translating line 1400, average 0.371291186469 seconds/sent
2017-11-29 22:47:26,370:validator.py:144 -             evaluate():   Translating line 1500, average 0.373892876625 seconds/sent
2017-11-29 22:48:06,258:validator.py:144 -             evaluate():   Translating line 1600, average 0.37545455128 seconds/sent
2017-11-29 22:48:45,868:validator.py:144 -             evaluate():   Translating line 1700, average 0.376669197644 seconds/sent
2017-11-29 22:49:32,087:validator.py:144 -             evaluate():   Translating line 1800, average 0.381420296695 seconds/sent
2017-11-29 22:50:17,808:validator.py:144 -             evaluate():   Translating line 1900, average 0.38540920107 seconds/sent
2017-11-29 22:50:42,535:validator.py:153 -             evaluate(): Done translating.
2017-11-29 22:50:42,536:validator.py:154 -             evaluate(): dev perplexity: 86.573
2017-11-29 22:50:43,037:validator.py:160 -             evaluate(): BLEU = 11.51, 42.1/17.3/8.2/4.1 (BP=0.921, ratio=0.924, hyp_len=41852, ref_len=45274)

2017-11-29 22:50:43,037:validator.py:161 -             evaluate(): Validation took: 12.6251169006 minutes
2017-11-29 22:50:43,040:validator.py:196 -           maybe_save(): Current best bleus: 10.64
2017-11-29 22:50:43,040:validator.py:197 -           maybe_save(): Delete 10.64 & use 11.51 instead
2017-11-29 22:50:43,041:validator.py:207 -           maybe_save(): Delete ./nmt/saved_models/de2en/de2en-10.64.cpkt.data-00000-of-00001 & ./nmt/saved_models/de2en/de2en-10.64.cpkt.meta & ./nmt/saved_models/de2en/de2en-10.64.cpkt.index
2017-11-29 22:50:43,055:validator.py:213 -           maybe_save(): Save 11.51 to list of best bleu scores
2017-11-29 22:50:43,450:validator.py:217 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en/de2en-11.51.cpkt
2017-11-29 22:50:43,451:validator.py:218 -           maybe_save(): Best bleu scores so far: 11.51
2017-11-29 22:51:13,446:train.py:188 -         run_log_save(): Batch 2285, epoch 10/20:
2017-11-29 22:51:13,446:train.py:189 -         run_log_save():    avg word perp:   10.63
2017-11-29 22:51:13,446:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-29 22:51:13,446:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:51:43,280:train.py:188 -         run_log_save(): Batch 2385, epoch 10/20:
2017-11-29 22:51:43,281:train.py:189 -         run_log_save():    avg word perp:   10.74
2017-11-29 22:51:43,281:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 22:51:43,281:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:52:13,038:train.py:188 -         run_log_save(): Batch 2485, epoch 10/20:
2017-11-29 22:52:13,038:train.py:189 -         run_log_save():    avg word perp:   10.58
2017-11-29 22:52:13,038:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 22:52:13,038:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:52:28,470:train.py:116 -         report_epoch(): Finish epoch 10
2017-11-29 22:52:28,470:train.py:117 -         report_epoch():     It takes 0:12:22.452694
2017-11-29 22:52:28,470:train.py:118 -         report_epoch():     Avergage # words/second    5496.25320509
2017-11-29 22:52:28,470:train.py:119 -         report_epoch():     Average seconds/batch    0.29288074721
2017-11-29 22:52:28,470:train.py:130 -         report_epoch():     train perplexity: 10.2964653484
2017-11-29 22:52:28,849:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.378380060196 seconds
2017-11-29 22:52:42,684:train.py:188 -         run_log_save(): Batch 50, epoch 11/20:
2017-11-29 22:52:42,684:train.py:189 -         run_log_save():    avg word perp:   9.45
2017-11-29 22:52:42,684:train.py:190 -         run_log_save():    acc trg words/s: 5517
2017-11-29 22:52:42,684:train.py:191 -         run_log_save():    acc sec/batch:   0.27
2017-11-29 22:53:12,151:train.py:188 -         run_log_save(): Batch 150, epoch 11/20:
2017-11-29 22:53:12,151:train.py:189 -         run_log_save():    avg word perp:   9.10
2017-11-29 22:53:12,151:train.py:190 -         run_log_save():    acc trg words/s: 5526
2017-11-29 22:53:12,151:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:53:42,144:train.py:188 -         run_log_save(): Batch 250, epoch 11/20:
2017-11-29 22:53:42,145:train.py:189 -         run_log_save():    avg word perp:   8.93
2017-11-29 22:53:42,145:train.py:190 -         run_log_save():    acc trg words/s: 5481
2017-11-29 22:53:42,145:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:54:12,037:train.py:188 -         run_log_save(): Batch 350, epoch 11/20:
2017-11-29 22:54:12,037:train.py:189 -         run_log_save():    avg word perp:   9.41
2017-11-29 22:54:12,037:train.py:190 -         run_log_save():    acc trg words/s: 5475
2017-11-29 22:54:12,037:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:54:41,582:train.py:188 -         run_log_save(): Batch 450, epoch 11/20:
2017-11-29 22:54:41,582:train.py:189 -         run_log_save():    avg word perp:   9.34
2017-11-29 22:54:41,582:train.py:190 -         run_log_save():    acc trg words/s: 5481
2017-11-29 22:54:41,582:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:55:11,255:train.py:188 -         run_log_save(): Batch 550, epoch 11/20:
2017-11-29 22:55:11,255:train.py:189 -         run_log_save():    avg word perp:   9.09
2017-11-29 22:55:11,255:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-29 22:55:11,255:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:55:40,355:train.py:148 -         sample_input(): Sample input data:
2017-11-29 22:55:40,355:train.py:149 -         sample_input(): Src: . sind verbunden Türkei der Beitritt @-@ EU dem mit die , nutzen zu regelungen Übergangs@@ die , sein konstruktiv ebenfalls könnte es _PAD
2017-11-29 22:55:40,355:train.py:150 -         sample_input(): Src len: 23
2017-11-29 22:55:40,355:train.py:151 -         sample_input(): Trg: _BOS it may also be constructive to take advantage of transitional provisions linked to Turkey &apos;s EU accession . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:55:40,355:train.py:152 -         sample_input(): Tar: it may also be constructive to take advantage of transitional provisions linked to Turkey &apos;s EU accession . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 22:55:40,355:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 22:55:40,356:train.py:188 -         run_log_save(): Batch 650, epoch 11/20:
2017-11-29 22:55:40,356:train.py:189 -         run_log_save():    avg word perp:   9.43
2017-11-29 22:55:40,356:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-29 22:55:40,356:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:55:42,547:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.190774
2017-11-29 22:56:12,113:train.py:188 -         run_log_save(): Batch 750, epoch 11/20:
2017-11-29 22:56:12,113:train.py:189 -         run_log_save():    avg word perp:   9.57
2017-11-29 22:56:12,113:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-29 22:56:12,114:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:56:41,786:train.py:188 -         run_log_save(): Batch 850, epoch 11/20:
2017-11-29 22:56:41,786:train.py:189 -         run_log_save():    avg word perp:   9.39
2017-11-29 22:56:41,786:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-29 22:56:41,786:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:57:11,621:train.py:188 -         run_log_save(): Batch 950, epoch 11/20:
2017-11-29 22:57:11,622:train.py:189 -         run_log_save():    avg word perp:   9.59
2017-11-29 22:57:11,622:train.py:190 -         run_log_save():    acc trg words/s: 5491
2017-11-29 22:57:11,622:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:57:41,366:train.py:188 -         run_log_save(): Batch 1050, epoch 11/20:
2017-11-29 22:57:41,367:train.py:189 -         run_log_save():    avg word perp:   9.59
2017-11-29 22:57:41,367:train.py:190 -         run_log_save():    acc trg words/s: 5489
2017-11-29 22:57:41,367:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:58:11,352:train.py:188 -         run_log_save(): Batch 1150, epoch 11/20:
2017-11-29 22:58:11,352:train.py:189 -         run_log_save():    avg word perp:   9.73
2017-11-29 22:58:11,352:train.py:190 -         run_log_save():    acc trg words/s: 5486
2017-11-29 22:58:11,352:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:58:40,721:train.py:188 -         run_log_save(): Batch 1250, epoch 11/20:
2017-11-29 22:58:40,721:train.py:189 -         run_log_save():    avg word perp:   9.73
2017-11-29 22:58:40,721:train.py:190 -         run_log_save():    acc trg words/s: 5488
2017-11-29 22:58:40,721:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:59:10,430:train.py:188 -         run_log_save(): Batch 1350, epoch 11/20:
2017-11-29 22:59:10,430:train.py:189 -         run_log_save():    avg word perp:   9.54
2017-11-29 22:59:10,430:train.py:190 -         run_log_save():    acc trg words/s: 5487
2017-11-29 22:59:10,430:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 22:59:40,296:train.py:188 -         run_log_save(): Batch 1450, epoch 11/20:
2017-11-29 22:59:40,296:train.py:189 -         run_log_save():    avg word perp:   9.65
2017-11-29 22:59:40,296:train.py:190 -         run_log_save():    acc trg words/s: 5484
2017-11-29 22:59:40,296:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:00:09,910:train.py:188 -         run_log_save(): Batch 1550, epoch 11/20:
2017-11-29 23:00:09,911:train.py:189 -         run_log_save():    avg word perp:   9.59
2017-11-29 23:00:09,911:train.py:190 -         run_log_save():    acc trg words/s: 5484
2017-11-29 23:00:09,911:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:00:39,544:train.py:148 -         sample_input(): Sample input data:
2017-11-29 23:00:39,544:train.py:149 -         sample_input(): Src: . machen tt ö@@ Gesp@@ zum sich würde , &quot; Orange starken der Politik &quot; eine an glaubt er sagt der , jeder _PAD _PAD
2017-11-29 23:00:39,545:train.py:150 -         sample_input(): Src len: 23
2017-11-29 23:00:39,545:train.py:151 -         sample_input(): Trg: _BOS anyone who says he believes in a &quot; strong orange policy &quot; would be ridi@@ cul@@ ed . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:00:39,545:train.py:152 -         sample_input(): Tar: anyone who says he believes in a &quot; strong orange policy &quot; would be ridi@@ cul@@ ed . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:00:39,545:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 23:00:39,545:train.py:188 -         run_log_save(): Batch 1650, epoch 11/20:
2017-11-29 23:00:39,545:train.py:189 -         run_log_save():    avg word perp:   9.56
2017-11-29 23:00:39,545:train.py:190 -         run_log_save():    acc trg words/s: 5482
2017-11-29 23:00:39,545:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:01:09,047:train.py:188 -         run_log_save(): Batch 1750, epoch 11/20:
2017-11-29 23:01:09,047:train.py:189 -         run_log_save():    avg word perp:   9.75
2017-11-29 23:01:09,047:train.py:190 -         run_log_save():    acc trg words/s: 5485
2017-11-29 23:01:09,048:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:01:38,043:train.py:188 -         run_log_save(): Batch 1850, epoch 11/20:
2017-11-29 23:01:38,044:train.py:189 -         run_log_save():    avg word perp:   9.85
2017-11-29 23:01:38,044:train.py:190 -         run_log_save():    acc trg words/s: 5491
2017-11-29 23:01:38,044:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:02:07,244:train.py:188 -         run_log_save(): Batch 1950, epoch 11/20:
2017-11-29 23:02:07,244:train.py:189 -         run_log_save():    avg word perp:   9.83
2017-11-29 23:02:07,244:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 23:02:07,244:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:02:37,062:train.py:188 -         run_log_save(): Batch 2050, epoch 11/20:
2017-11-29 23:02:37,062:train.py:189 -         run_log_save():    avg word perp:   9.89
2017-11-29 23:02:37,063:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 23:02:37,063:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:03:06,754:train.py:188 -         run_log_save(): Batch 2150, epoch 11/20:
2017-11-29 23:03:06,755:train.py:189 -         run_log_save():    avg word perp:   9.94
2017-11-29 23:03:06,755:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-29 23:03:06,755:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:03:36,174:train.py:188 -         run_log_save(): Batch 2250, epoch 11/20:
2017-11-29 23:03:36,175:train.py:189 -         run_log_save():    avg word perp:   9.71
2017-11-29 23:03:36,175:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 23:03:36,175:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:04:05,587:train.py:188 -         run_log_save(): Batch 2350, epoch 11/20:
2017-11-29 23:04:05,588:train.py:189 -         run_log_save():    avg word perp:   9.73
2017-11-29 23:04:05,588:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 23:04:05,588:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:04:35,406:train.py:188 -         run_log_save(): Batch 2450, epoch 11/20:
2017-11-29 23:04:35,406:train.py:189 -         run_log_save():    avg word perp:   9.86
2017-11-29 23:04:35,406:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 23:04:35,406:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:05:01,148:train.py:116 -         report_epoch(): Finish epoch 11
2017-11-29 23:05:01,148:train.py:117 -         report_epoch():     It takes 0:12:22.125299
2017-11-29 23:05:01,148:train.py:118 -         report_epoch():     Avergage # words/second    5498.74934453
2017-11-29 23:05:01,148:train.py:119 -         report_epoch():     Average seconds/batch    0.292751597135
2017-11-29 23:05:01,149:train.py:130 -         report_epoch():     train perplexity: 9.5591003961
2017-11-29 23:05:01,589:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.439865112305 seconds
2017-11-29 23:05:05,524:train.py:188 -         run_log_save(): Batch 15, epoch 12/20:
2017-11-29 23:05:05,524:train.py:189 -         run_log_save():    avg word perp:   9.58
2017-11-29 23:05:05,524:train.py:190 -         run_log_save():    acc trg words/s: 5278
2017-11-29 23:05:05,524:train.py:191 -         run_log_save():    acc sec/batch:   0.26
2017-11-29 23:05:34,855:train.py:148 -         sample_input(): Sample input data:
2017-11-29 23:05:34,855:train.py:149 -         sample_input(): Src: . Krieg dem vor nicht zumindest - gab Kaida @-@ Al der und Irak dem zwischen Verbindung keine gar bis wenig es dass , vor dafür Beweise ende erdrück@@ liegen außerdem _PAD _PAD
2017-11-29 23:05:34,855:train.py:150 -         sample_input(): Src len: 31
2017-11-29 23:05:34,855:train.py:151 -         sample_input(): Trg: _BOS similarly , the evidence is overwhelming that there was little if any link between Iraq and Al @-@ Qaeda - at least before the war . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:05:34,855:train.py:152 -         sample_input(): Tar: similarly , the evidence is overwhelming that there was little if any link between Iraq and Al @-@ Qaeda - at least before the war . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:05:34,855:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 23:05:34,855:train.py:188 -         run_log_save(): Batch 115, epoch 12/20:
2017-11-29 23:05:34,855:train.py:189 -         run_log_save():    avg word perp:   8.40
2017-11-29 23:05:34,855:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-29 23:05:34,855:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:05:37,092:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.236868
2017-11-29 23:06:06,578:train.py:188 -         run_log_save(): Batch 215, epoch 12/20:
2017-11-29 23:06:06,578:train.py:189 -         run_log_save():    avg word perp:   8.51
2017-11-29 23:06:06,578:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-29 23:06:06,578:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:06:36,550:train.py:188 -         run_log_save(): Batch 315, epoch 12/20:
2017-11-29 23:06:36,550:train.py:189 -         run_log_save():    avg word perp:   8.55
2017-11-29 23:06:36,550:train.py:190 -         run_log_save():    acc trg words/s: 5489
2017-11-29 23:06:36,550:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:07:06,121:train.py:188 -         run_log_save(): Batch 415, epoch 12/20:
2017-11-29 23:07:06,121:train.py:189 -         run_log_save():    avg word perp:   8.65
2017-11-29 23:07:06,121:train.py:190 -         run_log_save():    acc trg words/s: 5492
2017-11-29 23:07:06,121:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:07:35,807:train.py:188 -         run_log_save(): Batch 515, epoch 12/20:
2017-11-29 23:07:35,807:train.py:189 -         run_log_save():    avg word perp:   8.78
2017-11-29 23:07:35,808:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 23:07:35,808:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:08:05,066:train.py:188 -         run_log_save(): Batch 615, epoch 12/20:
2017-11-29 23:08:05,066:train.py:189 -         run_log_save():    avg word perp:   8.90
2017-11-29 23:08:05,066:train.py:190 -         run_log_save():    acc trg words/s: 5505
2017-11-29 23:08:05,066:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:08:34,429:train.py:188 -         run_log_save(): Batch 715, epoch 12/20:
2017-11-29 23:08:34,430:train.py:189 -         run_log_save():    avg word perp:   8.65
2017-11-29 23:08:34,430:train.py:190 -         run_log_save():    acc trg words/s: 5508
2017-11-29 23:08:34,430:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:09:04,155:train.py:188 -         run_log_save(): Batch 815, epoch 12/20:
2017-11-29 23:09:04,156:train.py:189 -         run_log_save():    avg word perp:   8.81
2017-11-29 23:09:04,156:train.py:190 -         run_log_save():    acc trg words/s: 5505
2017-11-29 23:09:04,156:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:09:34,179:train.py:188 -         run_log_save(): Batch 915, epoch 12/20:
2017-11-29 23:09:34,180:train.py:189 -         run_log_save():    avg word perp:   9.05
2017-11-29 23:09:34,180:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 23:09:34,180:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:10:03,617:train.py:188 -         run_log_save(): Batch 1015, epoch 12/20:
2017-11-29 23:10:03,617:train.py:189 -         run_log_save():    avg word perp:   8.93
2017-11-29 23:10:03,617:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 23:10:03,617:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:10:33,137:train.py:148 -         sample_input(): Sample input data:
2017-11-29 23:10:33,137:train.py:149 -         sample_input(): Src: . waren Staates unabhängigen eines Gründung die und Besatzung israelischen der Ende ein bislang Prioritäten oberste deren , Politik palästinensischen der in Verschiebung dramatische eine kennzeichnet Fatah und Hamas zwischen Konfrontation die _PAD
2017-11-29 23:10:33,137:train.py:150 -         sample_input(): Src len: 32
2017-11-29 23:10:33,137:train.py:151 -         sample_input(): Trg: _BOS the Hamas / Fatah face @-@ off marks a dramatic shift in Palestinian politics , whose top priorities until now has been an end to the Israeli occupation and the establishment of an independent state . _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:10:33,137:train.py:152 -         sample_input(): Tar: the Hamas / Fatah face @-@ off marks a dramatic shift in Palestinian politics , whose top priorities until now has been an end to the Israeli occupation and the establishment of an independent state . _EOS _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:10:33,138:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 23:10:33,138:train.py:188 -         run_log_save(): Batch 1115, epoch 12/20:
2017-11-29 23:10:33,138:train.py:189 -         run_log_save():    avg word perp:   8.92
2017-11-29 23:10:33,138:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-29 23:10:33,138:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:11:03,105:train.py:188 -         run_log_save(): Batch 1215, epoch 12/20:
2017-11-29 23:11:03,105:train.py:189 -         run_log_save():    avg word perp:   8.91
2017-11-29 23:11:03,105:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 23:11:03,105:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:11:32,888:train.py:188 -         run_log_save(): Batch 1315, epoch 12/20:
2017-11-29 23:11:32,888:train.py:189 -         run_log_save():    avg word perp:   9.00
2017-11-29 23:11:32,888:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-29 23:11:32,888:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:12:02,449:train.py:188 -         run_log_save(): Batch 1415, epoch 12/20:
2017-11-29 23:12:02,449:train.py:189 -         run_log_save():    avg word perp:   8.99
2017-11-29 23:12:02,450:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-29 23:12:02,450:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:12:32,265:train.py:188 -         run_log_save(): Batch 1515, epoch 12/20:
2017-11-29 23:12:32,265:train.py:189 -         run_log_save():    avg word perp:   9.17
2017-11-29 23:12:32,265:train.py:190 -         run_log_save():    acc trg words/s: 5491
2017-11-29 23:12:32,265:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:13:01,830:train.py:188 -         run_log_save(): Batch 1615, epoch 12/20:
2017-11-29 23:13:01,831:train.py:189 -         run_log_save():    avg word perp:   9.17
2017-11-29 23:13:01,831:train.py:190 -         run_log_save():    acc trg words/s: 5492
2017-11-29 23:13:01,831:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:13:31,090:train.py:188 -         run_log_save(): Batch 1715, epoch 12/20:
2017-11-29 23:13:31,090:train.py:189 -         run_log_save():    avg word perp:   9.19
2017-11-29 23:13:31,090:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 23:13:31,090:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:14:00,450:train.py:188 -         run_log_save(): Batch 1815, epoch 12/20:
2017-11-29 23:14:00,450:train.py:189 -         run_log_save():    avg word perp:   9.09
2017-11-29 23:14:00,450:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 23:14:00,450:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:14:30,475:train.py:188 -         run_log_save(): Batch 1915, epoch 12/20:
2017-11-29 23:14:30,475:train.py:189 -         run_log_save():    avg word perp:   9.39
2017-11-29 23:14:30,475:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 23:14:30,475:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:15:00,027:train.py:188 -         run_log_save(): Batch 2015, epoch 12/20:
2017-11-29 23:15:00,027:train.py:189 -         run_log_save():    avg word perp:   9.15
2017-11-29 23:15:00,027:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 23:15:00,027:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:15:29,550:train.py:148 -         sample_input(): Sample input data:
2017-11-29 23:15:29,550:train.py:149 -         sample_input(): Src: . Zögern stem beeinflus@@ &quot; es fall@@ Präzedenz@@ eines Schaffung &quot; der vor Warnungen russischen die durch eindeutig , lichem deut@@ mit debatte vo@@ Koso@@ der in nun agieren Länder diese all _PAD
2017-11-29 23:15:29,550:train.py:150 -         sample_input(): Src len: 32
2017-11-29 23:15:29,550:train.py:151 -         sample_input(): Trg: _BOS all of these countries are now acting with great hesitation in the debate about Kosovo , clearly influenced by Russian warnings about &quot; setting a precedent . &quot; _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:15:29,550:train.py:152 -         sample_input(): Tar: all of these countries are now acting with great hesitation in the debate about Kosovo , clearly influenced by Russian warnings about &quot; setting a precedent . &quot; _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:15:29,550:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 23:15:29,550:train.py:188 -         run_log_save(): Batch 2115, epoch 12/20:
2017-11-29 23:15:29,550:train.py:189 -         run_log_save():    avg word perp:   9.28
2017-11-29 23:15:29,550:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 23:15:29,551:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:15:31,704:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.153607
2017-11-29 23:15:31,704:validator.py:225 -    validate_and_save(): Start validation
2017-11-29 23:15:31,705:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 23:16:13,076:validator.py:144 -             evaluate():   Translating line 100, average 0.413201141357 seconds/sent
2017-11-29 23:16:56,213:validator.py:144 -             evaluate():   Translating line 200, average 0.422281199694 seconds/sent
2017-11-29 23:17:34,400:validator.py:144 -             evaluate():   Translating line 300, average 0.408812513351 seconds/sent
2017-11-29 23:18:09,910:validator.py:144 -             evaluate():   Translating line 400, average 0.395385200381 seconds/sent
2017-11-29 23:18:54,561:validator.py:144 -             evaluate():   Translating line 500, average 0.405609116077 seconds/sent
2017-11-29 23:19:32,197:validator.py:144 -             evaluate():   Translating line 600, average 0.400734643539 seconds/sent
2017-11-29 23:20:12,538:validator.py:144 -             evaluate():   Translating line 700, average 0.401116133077 seconds/sent
2017-11-29 23:20:45,963:validator.py:144 -             evaluate():   Translating line 800, average 0.392757970095 seconds/sent
2017-11-29 23:21:16,674:validator.py:144 -             evaluate():   Translating line 900, average 0.383241860072 seconds/sent
2017-11-29 23:21:54,831:validator.py:144 -             evaluate():   Translating line 1000, average 0.383075091124 seconds/sent
2017-11-29 23:22:31,358:validator.py:144 -             evaluate():   Translating line 1100, average 0.381456077316 seconds/sent
2017-11-29 23:23:07,716:validator.py:144 -             evaluate():   Translating line 1200, average 0.379966438413 seconds/sent
2017-11-29 23:23:55,854:validator.py:144 -             evaluate():   Translating line 1300, average 0.387767633842 seconds/sent
2017-11-29 23:24:42,944:validator.py:144 -             evaluate():   Translating line 1400, average 0.393705530678 seconds/sent
2017-11-29 23:25:29,410:validator.py:144 -             evaluate():   Translating line 1500, average 0.398435796102 seconds/sent
2017-11-29 23:26:17,955:validator.py:144 -             evaluate():   Translating line 1600, average 0.403874285668 seconds/sent
2017-11-29 23:27:02,185:validator.py:144 -             evaluate():   Translating line 1700, average 0.406134318324 seconds/sent
2017-11-29 23:27:53,127:validator.py:144 -             evaluate():   Translating line 1800, average 0.41187250389 seconds/sent
2017-11-29 23:28:39,142:validator.py:144 -             evaluate():   Translating line 1900, average 0.414413712652 seconds/sent
2017-11-29 23:29:07,122:validator.py:153 -             evaluate(): Done translating.
2017-11-29 23:29:07,123:validator.py:154 -             evaluate(): dev perplexity: 83.948
2017-11-29 23:29:07,630:validator.py:160 -             evaluate(): BLEU = 11.82, 38.7/16.2/7.8/4.0 (BP=1.000, ratio=1.027, hyp_len=46514, ref_len=45274)

2017-11-29 23:29:07,631:validator.py:161 -             evaluate(): Validation took: 13.5979058822 minutes
2017-11-29 23:29:07,634:validator.py:196 -           maybe_save(): Current best bleus: 11.51
2017-11-29 23:29:07,634:validator.py:197 -           maybe_save(): Delete 11.51 & use 11.82 instead
2017-11-29 23:29:07,634:validator.py:207 -           maybe_save(): Delete ./nmt/saved_models/de2en/de2en-11.51.cpkt.data-00000-of-00001 & ./nmt/saved_models/de2en/de2en-11.51.cpkt.meta & ./nmt/saved_models/de2en/de2en-11.51.cpkt.index
2017-11-29 23:29:07,649:validator.py:213 -           maybe_save(): Save 11.82 to list of best bleu scores
2017-11-29 23:29:08,124:validator.py:217 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en/de2en-11.82.cpkt
2017-11-29 23:29:08,124:validator.py:218 -           maybe_save(): Best bleu scores so far: 11.82
2017-11-29 23:29:38,018:train.py:188 -         run_log_save(): Batch 2215, epoch 12/20:
2017-11-29 23:29:38,018:train.py:189 -         run_log_save():    avg word perp:   9.36
2017-11-29 23:29:38,018:train.py:190 -         run_log_save():    acc trg words/s: 5493
2017-11-29 23:29:38,018:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:30:07,127:train.py:188 -         run_log_save(): Batch 2315, epoch 12/20:
2017-11-29 23:30:07,127:train.py:189 -         run_log_save():    avg word perp:   9.19
2017-11-29 23:30:07,127:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 23:30:07,127:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:30:36,792:train.py:188 -         run_log_save(): Batch 2415, epoch 12/20:
2017-11-29 23:30:36,793:train.py:189 -         run_log_save():    avg word perp:   9.30
2017-11-29 23:30:36,793:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 23:30:36,793:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:31:05,964:train.py:188 -         run_log_save(): Batch 2515, epoch 12/20:
2017-11-29 23:31:05,964:train.py:189 -         run_log_save():    avg word perp:   9.19
2017-11-29 23:31:05,964:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-29 23:31:05,964:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:31:12,412:train.py:116 -         report_epoch(): Finish epoch 12
2017-11-29 23:31:12,412:train.py:117 -         report_epoch():     It takes 0:12:22.018331
2017-11-29 23:31:12,412:train.py:118 -         report_epoch():     Avergage # words/second    5499.5433795
2017-11-29 23:31:12,412:train.py:119 -         report_epoch():     Average seconds/batch    0.292709400809
2017-11-29 23:31:12,412:train.py:130 -         report_epoch():     train perplexity: 8.97546214473
2017-11-29 23:31:12,857:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.444307088852 seconds
2017-11-29 23:31:36,601:train.py:188 -         run_log_save(): Batch 80, epoch 13/20:
2017-11-29 23:31:36,601:train.py:189 -         run_log_save():    avg word perp:   8.47
2017-11-29 23:31:36,601:train.py:190 -         run_log_save():    acc trg words/s: 5484
2017-11-29 23:31:36,601:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:32:06,402:train.py:188 -         run_log_save(): Batch 180, epoch 13/20:
2017-11-29 23:32:06,402:train.py:189 -         run_log_save():    avg word perp:   8.09
2017-11-29 23:32:06,402:train.py:190 -         run_log_save():    acc trg words/s: 5493
2017-11-29 23:32:06,402:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:32:35,681:train.py:188 -         run_log_save(): Batch 280, epoch 13/20:
2017-11-29 23:32:35,682:train.py:189 -         run_log_save():    avg word perp:   7.99
2017-11-29 23:32:35,682:train.py:190 -         run_log_save():    acc trg words/s: 5517
2017-11-29 23:32:35,682:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:33:05,512:train.py:188 -         run_log_save(): Batch 380, epoch 13/20:
2017-11-29 23:33:05,513:train.py:189 -         run_log_save():    avg word perp:   8.14
2017-11-29 23:33:05,513:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-29 23:33:05,513:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:33:35,195:train.py:188 -         run_log_save(): Batch 480, epoch 13/20:
2017-11-29 23:33:35,195:train.py:189 -         run_log_save():    avg word perp:   8.16
2017-11-29 23:33:35,195:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-29 23:33:35,195:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:34:05,049:train.py:148 -         sample_input(): Sample input data:
2017-11-29 23:34:05,049:train.py:149 -         sample_input(): Src: . beschaffen ate tifik@@ zer@@ Emissions@@ CO2 tierten emit@@ Tonne pro sich muss , stößt aus@@ CO2 das , Unternehmen jedes und festgesetzt Ausstoß @-@ CO2 jährlichen den für Obergrenzen Ebene nationaler auf werden Systems @-@ Trade @-@ and @-@ ap C@@ dieses Rahmen im _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:34:05,049:train.py:150 -         sample_input(): Src len: 45
2017-11-29 23:34:05,049:train.py:151 -         sample_input(): Trg: _BOS in a cap @-@ and @-@ trade system , the government sets total allow@@ able national emissions of CO2 per year and requires any firm that causes CO2 emissions to have a permit per ton of CO2 emitted . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:34:05,049:train.py:152 -         sample_input(): Tar: in a cap @-@ and @-@ trade system , the government sets total allow@@ able national emissions of CO2 per year and requires any firm that causes CO2 emissions to have a permit per ton of CO2 emitted . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:34:05,049:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 23:34:05,050:train.py:188 -         run_log_save(): Batch 580, epoch 13/20:
2017-11-29 23:34:05,050:train.py:189 -         run_log_save():    avg word perp:   8.38
2017-11-29 23:34:05,050:train.py:190 -         run_log_save():    acc trg words/s: 5492
2017-11-29 23:34:05,050:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:34:34,457:train.py:188 -         run_log_save(): Batch 680, epoch 13/20:
2017-11-29 23:34:34,457:train.py:189 -         run_log_save():    avg word perp:   8.16
2017-11-29 23:34:34,457:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-29 23:34:34,457:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:35:04,154:train.py:188 -         run_log_save(): Batch 780, epoch 13/20:
2017-11-29 23:35:04,154:train.py:189 -         run_log_save():    avg word perp:   8.41
2017-11-29 23:35:04,154:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-29 23:35:04,154:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:35:34,100:train.py:188 -         run_log_save(): Batch 880, epoch 13/20:
2017-11-29 23:35:34,100:train.py:189 -         run_log_save():    avg word perp:   8.37
2017-11-29 23:35:34,100:train.py:190 -         run_log_save():    acc trg words/s: 5483
2017-11-29 23:35:34,100:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:36:03,503:train.py:188 -         run_log_save(): Batch 980, epoch 13/20:
2017-11-29 23:36:03,503:train.py:189 -         run_log_save():    avg word perp:   8.28
2017-11-29 23:36:03,503:train.py:190 -         run_log_save():    acc trg words/s: 5487
2017-11-29 23:36:03,503:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:36:32,969:train.py:188 -         run_log_save(): Batch 1080, epoch 13/20:
2017-11-29 23:36:32,969:train.py:189 -         run_log_save():    avg word perp:   8.59
2017-11-29 23:36:32,970:train.py:190 -         run_log_save():    acc trg words/s: 5492
2017-11-29 23:36:32,970:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:37:02,726:train.py:188 -         run_log_save(): Batch 1180, epoch 13/20:
2017-11-29 23:37:02,726:train.py:189 -         run_log_save():    avg word perp:   8.37
2017-11-29 23:37:02,726:train.py:190 -         run_log_save():    acc trg words/s: 5491
2017-11-29 23:37:02,726:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:37:32,044:train.py:188 -         run_log_save(): Batch 1280, epoch 13/20:
2017-11-29 23:37:32,045:train.py:189 -         run_log_save():    avg word perp:   8.43
2017-11-29 23:37:32,045:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 23:37:32,045:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:38:01,394:train.py:188 -         run_log_save(): Batch 1380, epoch 13/20:
2017-11-29 23:38:01,394:train.py:189 -         run_log_save():    avg word perp:   8.46
2017-11-29 23:38:01,394:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 23:38:01,394:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:38:31,030:train.py:188 -         run_log_save(): Batch 1480, epoch 13/20:
2017-11-29 23:38:31,030:train.py:189 -         run_log_save():    avg word perp:   8.54
2017-11-29 23:38:31,030:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 23:38:31,030:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:39:01,147:train.py:148 -         sample_input(): Sample input data:
2017-11-29 23:39:01,147:train.py:149 -         sample_input(): Src: . versuchen erst nicht gar meist es Gläubiger die dass , tiv restrik@@ derart z solven@@ in@@ Privat@@ zur Gesetze die sind , haben Arbeitseinkommen das auf oder stände gegen@@ Vermögens@@ andere auf spruch Rechtsan@@ einen Gläubiger die denen in , Bundesstaaten den in sogar _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:39:01,147:train.py:150 -         sample_input(): Src len: 45
2017-11-29 23:39:01,147:train.py:151 -         sample_input(): Trg: _BOS even in those states where creditors have the legal authority to take other assets or wage income , the personal bankruptcy laws are so restrictive that creditors don &apos;t bother to try . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:39:01,147:train.py:152 -         sample_input(): Tar: even in those states where creditors have the legal authority to take other assets or wage income , the personal bankruptcy laws are so restrictive that creditors don &apos;t bother to try . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:39:01,147:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 23:39:01,147:train.py:188 -         run_log_save(): Batch 1580, epoch 13/20:
2017-11-29 23:39:01,147:train.py:189 -         run_log_save():    avg word perp:   8.55
2017-11-29 23:39:01,147:train.py:190 -         run_log_save():    acc trg words/s: 5491
2017-11-29 23:39:01,147:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:39:03,315:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.167190
2017-11-29 23:39:33,175:train.py:188 -         run_log_save(): Batch 1680, epoch 13/20:
2017-11-29 23:39:33,176:train.py:189 -         run_log_save():    avg word perp:   8.71
2017-11-29 23:39:33,176:train.py:190 -         run_log_save():    acc trg words/s: 5491
2017-11-29 23:39:33,176:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:40:02,405:train.py:188 -         run_log_save(): Batch 1780, epoch 13/20:
2017-11-29 23:40:02,405:train.py:189 -         run_log_save():    avg word perp:   8.74
2017-11-29 23:40:02,405:train.py:190 -         run_log_save():    acc trg words/s: 5491
2017-11-29 23:40:02,405:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:40:31,209:train.py:188 -         run_log_save(): Batch 1880, epoch 13/20:
2017-11-29 23:40:31,209:train.py:189 -         run_log_save():    avg word perp:   8.62
2017-11-29 23:40:31,209:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 23:40:31,209:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:41:00,740:train.py:188 -         run_log_save(): Batch 1980, epoch 13/20:
2017-11-29 23:41:00,741:train.py:189 -         run_log_save():    avg word perp:   8.80
2017-11-29 23:41:00,741:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-29 23:41:00,741:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:41:30,151:train.py:188 -         run_log_save(): Batch 2080, epoch 13/20:
2017-11-29 23:41:30,151:train.py:189 -         run_log_save():    avg word perp:   8.71
2017-11-29 23:41:30,151:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-29 23:41:30,151:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:42:00,322:train.py:188 -         run_log_save(): Batch 2180, epoch 13/20:
2017-11-29 23:42:00,323:train.py:189 -         run_log_save():    avg word perp:   8.86
2017-11-29 23:42:00,323:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 23:42:00,323:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:42:29,699:train.py:188 -         run_log_save(): Batch 2280, epoch 13/20:
2017-11-29 23:42:29,699:train.py:189 -         run_log_save():    avg word perp:   8.76
2017-11-29 23:42:29,699:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-29 23:42:29,699:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:42:59,424:train.py:188 -         run_log_save(): Batch 2380, epoch 13/20:
2017-11-29 23:42:59,424:train.py:189 -         run_log_save():    avg word perp:   8.68
2017-11-29 23:42:59,424:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-29 23:42:59,424:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:43:29,580:train.py:188 -         run_log_save(): Batch 2480, epoch 13/20:
2017-11-29 23:43:29,580:train.py:189 -         run_log_save():    avg word perp:   8.98
2017-11-29 23:43:29,580:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-29 23:43:29,580:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:43:45,526:train.py:116 -         report_epoch(): Finish epoch 13
2017-11-29 23:43:45,526:train.py:117 -         report_epoch():     It takes 0:12:22.602251
2017-11-29 23:43:45,527:train.py:118 -         report_epoch():     Avergage # words/second    5495.20418976
2017-11-29 23:43:45,527:train.py:119 -         report_epoch():     Average seconds/batch    0.292939743911
2017-11-29 23:43:45,527:train.py:130 -         report_epoch():     train perplexity: 8.47672448785
2017-11-29 23:43:45,957:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.429785013199 seconds
2017-11-29 23:43:58,514:train.py:148 -         sample_input(): Sample input data:
2017-11-29 23:43:58,514:train.py:149 -         sample_input(): Src: . reduzieren Mindestmaß ein auf Fehler derartige können Ausbildung bessere sowie Verfahren und Regeln neue _PAD _PAD
2017-11-29 23:43:58,514:train.py:150 -         sample_input(): Src len: 15
2017-11-29 23:43:58,514:train.py:151 -         sample_input(): Trg: _BOS new rules and procedures , as well as better training , can minimize such failings . _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:43:58,515:train.py:152 -         sample_input(): Tar: new rules and procedures , as well as better training , can minimize such failings . _EOS _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:43:58,515:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 23:43:58,515:train.py:188 -         run_log_save(): Batch 45, epoch 14/20:
2017-11-29 23:43:58,515:train.py:189 -         run_log_save():    avg word perp:   7.95
2017-11-29 23:43:58,515:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-29 23:43:58,515:train.py:191 -         run_log_save():    acc sec/batch:   0.27
2017-11-29 23:44:28,411:train.py:188 -         run_log_save(): Batch 145, epoch 14/20:
2017-11-29 23:44:28,411:train.py:189 -         run_log_save():    avg word perp:   7.70
2017-11-29 23:44:28,411:train.py:190 -         run_log_save():    acc trg words/s: 5466
2017-11-29 23:44:28,411:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:44:58,059:train.py:188 -         run_log_save(): Batch 245, epoch 14/20:
2017-11-29 23:44:58,059:train.py:189 -         run_log_save():    avg word perp:   7.57
2017-11-29 23:44:58,059:train.py:190 -         run_log_save():    acc trg words/s: 5473
2017-11-29 23:44:58,059:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:45:27,734:train.py:188 -         run_log_save(): Batch 345, epoch 14/20:
2017-11-29 23:45:27,734:train.py:189 -         run_log_save():    avg word perp:   7.75
2017-11-29 23:45:27,734:train.py:190 -         run_log_save():    acc trg words/s: 5482
2017-11-29 23:45:27,734:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:45:57,441:train.py:188 -         run_log_save(): Batch 445, epoch 14/20:
2017-11-29 23:45:57,441:train.py:189 -         run_log_save():    avg word perp:   7.59
2017-11-29 23:45:57,441:train.py:190 -         run_log_save():    acc trg words/s: 5481
2017-11-29 23:45:57,441:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:46:26,477:train.py:188 -         run_log_save(): Batch 545, epoch 14/20:
2017-11-29 23:46:26,478:train.py:189 -         run_log_save():    avg word perp:   7.77
2017-11-29 23:46:26,478:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-29 23:46:26,478:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:46:56,191:train.py:188 -         run_log_save(): Batch 645, epoch 14/20:
2017-11-29 23:46:56,192:train.py:189 -         run_log_save():    avg word perp:   7.86
2017-11-29 23:46:56,192:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-29 23:46:56,192:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:47:26,190:train.py:188 -         run_log_save(): Batch 745, epoch 14/20:
2017-11-29 23:47:26,190:train.py:189 -         run_log_save():    avg word perp:   7.96
2017-11-29 23:47:26,190:train.py:190 -         run_log_save():    acc trg words/s: 5488
2017-11-29 23:47:26,190:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:47:55,947:train.py:188 -         run_log_save(): Batch 845, epoch 14/20:
2017-11-29 23:47:55,947:train.py:189 -         run_log_save():    avg word perp:   7.96
2017-11-29 23:47:55,947:train.py:190 -         run_log_save():    acc trg words/s: 5491
2017-11-29 23:47:55,947:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:48:25,580:train.py:188 -         run_log_save(): Batch 945, epoch 14/20:
2017-11-29 23:48:25,580:train.py:189 -         run_log_save():    avg word perp:   7.98
2017-11-29 23:48:25,580:train.py:190 -         run_log_save():    acc trg words/s: 5488
2017-11-29 23:48:25,580:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:48:54,978:train.py:148 -         sample_input(): Sample input data:
2017-11-29 23:48:54,978:train.py:149 -         sample_input(): Src: . halbieren letztlich vermutlich Schulden Griechenlands Gläubiger ihre und Regierung die würden Verhandlungen harten nach _PAD _PAD
2017-11-29 23:48:54,978:train.py:150 -         sample_input(): Src len: 15
2017-11-29 23:48:54,978:train.py:151 -         sample_input(): Trg: _BOS after tough negotiations , the government and its creditors would probably eventually slash Greece &apos;s debt in half . _PAD _PAD _PAD _PAD
2017-11-29 23:48:54,978:train.py:152 -         sample_input(): Tar: after tough negotiations , the government and its creditors would probably eventually slash Greece &apos;s debt in half . _EOS _PAD _PAD _PAD _PAD
2017-11-29 23:48:54,979:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0
2017-11-29 23:48:54,979:train.py:188 -         run_log_save(): Batch 1045, epoch 14/20:
2017-11-29 23:48:54,979:train.py:189 -         run_log_save():    avg word perp:   8.11
2017-11-29 23:48:54,979:train.py:190 -         run_log_save():    acc trg words/s: 5493
2017-11-29 23:48:54,979:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:48:57,140:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.160725
2017-11-29 23:49:26,295:train.py:188 -         run_log_save(): Batch 1145, epoch 14/20:
2017-11-29 23:49:26,295:train.py:189 -         run_log_save():    avg word perp:   7.98
2017-11-29 23:49:26,295:train.py:190 -         run_log_save():    acc trg words/s: 5503
2017-11-29 23:49:26,295:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:49:55,560:train.py:188 -         run_log_save(): Batch 1245, epoch 14/20:
2017-11-29 23:49:55,560:train.py:189 -         run_log_save():    avg word perp:   7.98
2017-11-29 23:49:55,560:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-29 23:49:55,560:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:50:25,225:train.py:188 -         run_log_save(): Batch 1345, epoch 14/20:
2017-11-29 23:50:25,225:train.py:189 -         run_log_save():    avg word perp:   8.05
2017-11-29 23:50:25,225:train.py:190 -         run_log_save():    acc trg words/s: 5505
2017-11-29 23:50:25,225:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:50:55,239:train.py:188 -         run_log_save(): Batch 1445, epoch 14/20:
2017-11-29 23:50:55,239:train.py:189 -         run_log_save():    avg word perp:   8.16
2017-11-29 23:50:55,239:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-29 23:50:55,239:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:51:25,243:train.py:188 -         run_log_save(): Batch 1545, epoch 14/20:
2017-11-29 23:51:25,243:train.py:189 -         run_log_save():    avg word perp:   8.17
2017-11-29 23:51:25,244:train.py:190 -         run_log_save():    acc trg words/s: 5493
2017-11-29 23:51:25,244:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:51:54,456:train.py:188 -         run_log_save(): Batch 1645, epoch 14/20:
2017-11-29 23:51:54,456:train.py:189 -         run_log_save():    avg word perp:   8.35
2017-11-29 23:51:54,457:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-29 23:51:54,457:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:52:24,246:train.py:188 -         run_log_save(): Batch 1745, epoch 14/20:
2017-11-29 23:52:24,246:train.py:189 -         run_log_save():    avg word perp:   8.09
2017-11-29 23:52:24,246:train.py:190 -         run_log_save():    acc trg words/s: 5491
2017-11-29 23:52:24,246:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:52:53,644:train.py:188 -         run_log_save(): Batch 1845, epoch 14/20:
2017-11-29 23:52:53,645:train.py:189 -         run_log_save():    avg word perp:   8.38
2017-11-29 23:52:53,645:train.py:190 -         run_log_save():    acc trg words/s: 5492
2017-11-29 23:52:53,645:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:53:23,593:train.py:188 -         run_log_save(): Batch 1945, epoch 14/20:
2017-11-29 23:53:23,594:train.py:189 -         run_log_save():    avg word perp:   8.34
2017-11-29 23:53:23,594:train.py:190 -         run_log_save():    acc trg words/s: 5491
2017-11-29 23:53:23,594:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:53:52,798:train.py:148 -         sample_input(): Sample input data:
2017-11-29 23:53:52,798:train.py:149 -         sample_input(): Src: ? verfügen macht Markt@@ über oder folgen Trend dem die , Investoren mit ist was doch _PAD
2017-11-29 23:53:52,798:train.py:150 -         sample_input(): Src len: 16
2017-11-29 23:53:52,798:train.py:151 -         sample_input(): Trg: _BOS but what about trend @-@ following investors , or those with market power ? _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:53:52,798:train.py:152 -         sample_input(): Tar: but what about trend @-@ following investors , or those with market power ? _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-29 23:53:52,798:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-29 23:53:52,798:train.py:188 -         run_log_save(): Batch 2045, epoch 14/20:
2017-11-29 23:53:52,798:train.py:189 -         run_log_save():    avg word perp:   8.27
2017-11-29 23:53:52,798:train.py:190 -         run_log_save():    acc trg words/s: 5493
2017-11-29 23:53:52,799:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-29 23:53:52,799:validator.py:225 -    validate_and_save(): Start validation
2017-11-29 23:53:52,799:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-29 23:54:33,553:validator.py:144 -             evaluate():   Translating line 100, average 0.406246140003 seconds/sent
2017-11-29 23:55:16,385:validator.py:144 -             evaluate():   Translating line 200, average 0.417282140255 seconds/sent
2017-11-29 23:55:51,046:validator.py:144 -             evaluate():   Translating line 300, average 0.393722720146 seconds/sent
2017-11-29 23:56:24,754:validator.py:144 -             evaluate():   Translating line 400, average 0.379561982155 seconds/sent
2017-11-29 23:57:05,046:validator.py:144 -             evaluate():   Translating line 500, average 0.384235147953 seconds/sent
2017-11-29 23:57:35,875:validator.py:144 -             evaluate():   Translating line 600, average 0.371577731371 seconds/sent
2017-11-29 23:58:10,901:validator.py:144 -             evaluate():   Translating line 700, average 0.368532095637 seconds/sent
2017-11-29 23:58:42,841:validator.py:144 -             evaluate():   Translating line 800, average 0.362390084863 seconds/sent
2017-11-29 23:59:09,722:validator.py:144 -             evaluate():   Translating line 900, average 0.351992153327 seconds/sent
2017-11-29 23:59:42,562:validator.py:144 -             evaluate():   Translating line 1000, average 0.349633651972 seconds/sent
2017-11-30 00:00:15,658:validator.py:144 -             evaluate():   Translating line 1100, average 0.347935701717 seconds/sent
2017-11-30 00:00:47,915:validator.py:144 -             evaluate():   Translating line 1200, average 0.345822147528 seconds/sent
2017-11-30 00:01:28,730:validator.py:144 -             evaluate():   Translating line 1300, average 0.350616338436 seconds/sent
2017-11-30 00:02:08,110:validator.py:144 -             evaluate():   Translating line 1400, average 0.35370103785 seconds/sent
2017-11-30 00:02:47,072:validator.py:144 -             evaluate():   Translating line 1500, average 0.35609535869 seconds/sent
2017-11-30 00:03:24,999:validator.py:144 -             evaluate():   Translating line 1600, average 0.35754369244 seconds/sent
2017-11-30 00:04:02,426:validator.py:144 -             evaluate():   Translating line 1700, average 0.358527998223 seconds/sent
2017-11-30 00:04:44,022:validator.py:144 -             evaluate():   Translating line 1800, average 0.361718627744 seconds/sent
2017-11-30 00:05:25,828:validator.py:144 -             evaluate():   Translating line 1900, average 0.364683686307 seconds/sent
2017-11-30 00:05:46,697:validator.py:153 -             evaluate(): Done translating.
2017-11-30 00:05:46,698:validator.py:154 -             evaluate(): dev perplexity: 84.073
2017-11-30 00:05:47,195:validator.py:160 -             evaluate(): BLEU = 12.09, 43.0/18.1/8.7/4.4 (BP=0.923, ratio=0.925, hyp_len=41900, ref_len=45274)

2017-11-30 00:05:47,195:validator.py:161 -             evaluate(): Validation took: 11.9044383486 minutes
2017-11-30 00:05:47,198:validator.py:196 -           maybe_save(): Current best bleus: 11.82
2017-11-30 00:05:47,198:validator.py:197 -           maybe_save(): Delete 11.82 & use 12.09 instead
2017-11-30 00:05:47,198:validator.py:207 -           maybe_save(): Delete ./nmt/saved_models/de2en/de2en-11.82.cpkt.data-00000-of-00001 & ./nmt/saved_models/de2en/de2en-11.82.cpkt.meta & ./nmt/saved_models/de2en/de2en-11.82.cpkt.index
2017-11-30 00:05:47,212:validator.py:213 -           maybe_save(): Save 12.09 to list of best bleu scores
2017-11-30 00:05:47,617:validator.py:217 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en/de2en-12.09.cpkt
2017-11-30 00:05:47,618:validator.py:218 -           maybe_save(): Best bleu scores so far: 12.09
2017-11-30 00:06:16,874:train.py:188 -         run_log_save(): Batch 2145, epoch 14/20:
2017-11-30 00:06:16,874:train.py:189 -         run_log_save():    avg word perp:   8.29
2017-11-30 00:06:16,874:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-30 00:06:16,874:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:06:46,364:train.py:188 -         run_log_save(): Batch 2245, epoch 14/20:
2017-11-30 00:06:46,364:train.py:189 -         run_log_save():    avg word perp:   8.39
2017-11-30 00:06:46,364:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-30 00:06:46,364:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:07:15,761:train.py:188 -         run_log_save(): Batch 2345, epoch 14/20:
2017-11-30 00:07:15,761:train.py:189 -         run_log_save():    avg word perp:   8.32
2017-11-30 00:07:15,761:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-30 00:07:15,761:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:07:45,216:train.py:188 -         run_log_save(): Batch 2445, epoch 14/20:
2017-11-30 00:07:45,216:train.py:189 -         run_log_save():    avg word perp:   8.44
2017-11-30 00:07:45,216:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-30 00:07:45,216:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:08:12,244:train.py:116 -         report_epoch(): Finish epoch 14
2017-11-30 00:08:12,244:train.py:117 -         report_epoch():     It takes 0:12:21.470388
2017-11-30 00:08:12,244:train.py:118 -         report_epoch():     Avergage # words/second    5503.63583996
2017-11-30 00:08:12,245:train.py:119 -         report_epoch():     Average seconds/batch    0.292493249585
2017-11-30 00:08:12,245:train.py:130 -         report_epoch():     train perplexity: 8.05315420167
2017-11-30 00:08:12,685:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.439868927002 seconds
2017-11-30 00:08:14,705:train.py:188 -         run_log_save(): Batch 10, epoch 15/20:
2017-11-30 00:08:14,705:train.py:189 -         run_log_save():    avg word perp:   8.06
2017-11-30 00:08:14,705:train.py:190 -         run_log_save():    acc trg words/s: 5614
2017-11-30 00:08:14,705:train.py:191 -         run_log_save():    acc sec/batch:   0.20
2017-11-30 00:08:44,165:train.py:188 -         run_log_save(): Batch 110, epoch 15/20:
2017-11-30 00:08:44,165:train.py:189 -         run_log_save():    avg word perp:   7.07
2017-11-30 00:08:44,165:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-30 00:08:44,165:train.py:191 -         run_log_save():    acc sec/batch:   0.28
2017-11-30 00:09:13,879:train.py:188 -         run_log_save(): Batch 210, epoch 15/20:
2017-11-30 00:09:13,879:train.py:189 -         run_log_save():    avg word perp:   7.19
2017-11-30 00:09:13,879:train.py:190 -         run_log_save():    acc trg words/s: 5503
2017-11-30 00:09:13,879:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:09:43,040:train.py:188 -         run_log_save(): Batch 310, epoch 15/20:
2017-11-30 00:09:43,040:train.py:189 -         run_log_save():    avg word perp:   7.34
2017-11-30 00:09:43,040:train.py:190 -         run_log_save():    acc trg words/s: 5520
2017-11-30 00:09:43,040:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:10:12,192:train.py:188 -         run_log_save(): Batch 410, epoch 15/20:
2017-11-30 00:10:12,192:train.py:189 -         run_log_save():    avg word perp:   7.41
2017-11-30 00:10:12,193:train.py:190 -         run_log_save():    acc trg words/s: 5528
2017-11-30 00:10:12,193:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:10:41,680:train.py:148 -         sample_input(): Sample input data:
2017-11-30 00:10:41,680:train.py:149 -         sample_input(): Src: . ist Terrors des Opfer ein auch selbst Pakistan dass , erkennen Indien muss D Ju@@ die gegen Maßnahmen drastischen nach Forderung der trotz _PAD
2017-11-30 00:10:41,680:train.py:150 -         sample_input(): Src len: 24
2017-11-30 00:10:41,680:train.py:151 -         sample_input(): Trg: _BOS even while demanding strong action against Ju@@ D , India must recognize that Pakistan is itself a victim of terror . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:10:41,680:train.py:152 -         sample_input(): Tar: even while demanding strong action against Ju@@ D , India must recognize that Pakistan is itself a victim of terror . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:10:41,680:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-30 00:10:41,680:train.py:188 -         run_log_save(): Batch 510, epoch 15/20:
2017-11-30 00:10:41,680:train.py:189 -         run_log_save():    avg word perp:   7.54
2017-11-30 00:10:41,680:train.py:190 -         run_log_save():    acc trg words/s: 5525
2017-11-30 00:10:41,680:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:10:43,917:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.236451
2017-11-30 00:11:13,542:train.py:188 -         run_log_save(): Batch 610, epoch 15/20:
2017-11-30 00:11:13,542:train.py:189 -         run_log_save():    avg word perp:   7.43
2017-11-30 00:11:13,542:train.py:190 -         run_log_save():    acc trg words/s: 5524
2017-11-30 00:11:13,543:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:11:42,961:train.py:188 -         run_log_save(): Batch 710, epoch 15/20:
2017-11-30 00:11:42,961:train.py:189 -         run_log_save():    avg word perp:   7.59
2017-11-30 00:11:42,961:train.py:190 -         run_log_save():    acc trg words/s: 5528
2017-11-30 00:11:42,961:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:12:12,806:train.py:188 -         run_log_save(): Batch 810, epoch 15/20:
2017-11-30 00:12:12,806:train.py:189 -         run_log_save():    avg word perp:   7.58
2017-11-30 00:12:12,806:train.py:190 -         run_log_save():    acc trg words/s: 5518
2017-11-30 00:12:12,806:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:12:42,465:train.py:188 -         run_log_save(): Batch 910, epoch 15/20:
2017-11-30 00:12:42,465:train.py:189 -         run_log_save():    avg word perp:   7.63
2017-11-30 00:12:42,465:train.py:190 -         run_log_save():    acc trg words/s: 5520
2017-11-30 00:12:42,465:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:13:12,239:train.py:188 -         run_log_save(): Batch 1010, epoch 15/20:
2017-11-30 00:13:12,239:train.py:189 -         run_log_save():    avg word perp:   7.67
2017-11-30 00:13:12,239:train.py:190 -         run_log_save():    acc trg words/s: 5516
2017-11-30 00:13:12,239:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:13:41,994:train.py:188 -         run_log_save(): Batch 1110, epoch 15/20:
2017-11-30 00:13:41,995:train.py:189 -         run_log_save():    avg word perp:   7.60
2017-11-30 00:13:41,995:train.py:190 -         run_log_save():    acc trg words/s: 5510
2017-11-30 00:13:41,995:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:14:11,637:train.py:188 -         run_log_save(): Batch 1210, epoch 15/20:
2017-11-30 00:14:11,637:train.py:189 -         run_log_save():    avg word perp:   7.68
2017-11-30 00:14:11,637:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-30 00:14:11,637:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:14:40,981:train.py:188 -         run_log_save(): Batch 1310, epoch 15/20:
2017-11-30 00:14:40,982:train.py:189 -         run_log_save():    avg word perp:   7.77
2017-11-30 00:14:40,982:train.py:190 -         run_log_save():    acc trg words/s: 5509
2017-11-30 00:14:40,982:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:15:09,948:train.py:188 -         run_log_save(): Batch 1410, epoch 15/20:
2017-11-30 00:15:09,948:train.py:189 -         run_log_save():    avg word perp:   7.75
2017-11-30 00:15:09,948:train.py:190 -         run_log_save():    acc trg words/s: 5513
2017-11-30 00:15:09,949:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:15:39,882:train.py:148 -         sample_input(): Sample input data:
2017-11-30 00:15:39,882:train.py:149 -         sample_input(): Src: . beitrug Risikoprämie der Anstieg weiteren einem zu was , ein niedriger Regierung argentinischen der Schulden die ften stu@@ Agenturen Rating @-@ Bond _PAD
2017-11-30 00:15:39,882:train.py:150 -         sample_input(): Src len: 23
2017-11-30 00:15:39,882:train.py:151 -         sample_input(): Trg: _BOS bond rating agencies downgraded Argentina &apos;s government debt , which contributed to a further rise in the risk premium . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:15:39,882:train.py:152 -         sample_input(): Tar: bond rating agencies downgraded Argentina &apos;s government debt , which contributed to a further rise in the risk premium . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:15:39,882:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-30 00:15:39,882:train.py:188 -         run_log_save(): Batch 1510, epoch 15/20:
2017-11-30 00:15:39,883:train.py:189 -         run_log_save():    avg word perp:   7.77
2017-11-30 00:15:39,883:train.py:190 -         run_log_save():    acc trg words/s: 5508
2017-11-30 00:15:39,883:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:16:09,509:train.py:188 -         run_log_save(): Batch 1610, epoch 15/20:
2017-11-30 00:16:09,509:train.py:189 -         run_log_save():    avg word perp:   7.82
2017-11-30 00:16:09,509:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-30 00:16:09,509:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:16:39,620:train.py:188 -         run_log_save(): Batch 1710, epoch 15/20:
2017-11-30 00:16:39,620:train.py:189 -         run_log_save():    avg word perp:   7.99
2017-11-30 00:16:39,620:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-30 00:16:39,620:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:17:09,228:train.py:188 -         run_log_save(): Batch 1810, epoch 15/20:
2017-11-30 00:17:09,229:train.py:189 -         run_log_save():    avg word perp:   7.75
2017-11-30 00:17:09,229:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-30 00:17:09,229:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:17:38,838:train.py:188 -         run_log_save(): Batch 1910, epoch 15/20:
2017-11-30 00:17:38,838:train.py:189 -         run_log_save():    avg word perp:   7.95
2017-11-30 00:17:38,839:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-30 00:17:38,839:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:18:08,105:train.py:188 -         run_log_save(): Batch 2010, epoch 15/20:
2017-11-30 00:18:08,106:train.py:189 -         run_log_save():    avg word perp:   7.94
2017-11-30 00:18:08,106:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-30 00:18:08,106:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:18:37,783:train.py:188 -         run_log_save(): Batch 2110, epoch 15/20:
2017-11-30 00:18:37,783:train.py:189 -         run_log_save():    avg word perp:   7.97
2017-11-30 00:18:37,783:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-30 00:18:37,783:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:19:07,315:train.py:188 -         run_log_save(): Batch 2210, epoch 15/20:
2017-11-30 00:19:07,315:train.py:189 -         run_log_save():    avg word perp:   7.99
2017-11-30 00:19:07,315:train.py:190 -         run_log_save():    acc trg words/s: 5503
2017-11-30 00:19:07,315:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:19:37,080:train.py:188 -         run_log_save(): Batch 2310, epoch 15/20:
2017-11-30 00:19:37,080:train.py:189 -         run_log_save():    avg word perp:   7.96
2017-11-30 00:19:37,080:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-30 00:19:37,080:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:20:06,898:train.py:188 -         run_log_save(): Batch 2410, epoch 15/20:
2017-11-30 00:20:06,898:train.py:189 -         run_log_save():    avg word perp:   8.01
2017-11-30 00:20:06,898:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-30 00:20:06,898:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:20:36,731:train.py:148 -         sample_input(): Sample input data:
2017-11-30 00:20:36,732:train.py:149 -         sample_input(): Src: . bewegen zu Mitte reichen men@@ stim@@ der in sich , sollte bestehen Anreiz ein sie für da , verwirrend zunächst erscheint dies _PAD _PAD
2017-11-30 00:20:36,732:train.py:150 -         sample_input(): Src len: 23
2017-11-30 00:20:36,732:train.py:151 -         sample_input(): Trg: _BOS at first , this seems puzzling , because they should have an incentive to move to the vote @-@ rich middle . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:20:36,732:train.py:152 -         sample_input(): Tar: at first , this seems puzzling , because they should have an incentive to move to the vote @-@ rich middle . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:20:36,732:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-30 00:20:36,732:train.py:188 -         run_log_save(): Batch 2510, epoch 15/20:
2017-11-30 00:20:36,732:train.py:189 -         run_log_save():    avg word perp:   8.02
2017-11-30 00:20:36,732:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-30 00:20:36,732:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:20:38,901:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.168626
2017-11-30 00:20:46,821:train.py:116 -         report_epoch(): Finish epoch 15
2017-11-30 00:20:46,821:train.py:117 -         report_epoch():     It takes 0:12:21.832970
2017-11-30 00:20:46,822:train.py:118 -         report_epoch():     Avergage # words/second    5500.88654125
2017-11-30 00:20:46,822:train.py:119 -         report_epoch():     Average seconds/batch    0.292636280041
2017-11-30 00:20:46,822:train.py:130 -         report_epoch():     train perplexity: 7.68943867424
2017-11-30 00:20:47,261:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.439118862152 seconds
2017-11-30 00:21:08,904:train.py:188 -         run_log_save(): Batch 75, epoch 16/20:
2017-11-30 00:21:08,904:train.py:189 -         run_log_save():    avg word perp:   7.04
2017-11-30 00:21:08,904:train.py:190 -         run_log_save():    acc trg words/s: 5447
2017-11-30 00:21:08,904:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:21:38,420:train.py:188 -         run_log_save(): Batch 175, epoch 16/20:
2017-11-30 00:21:38,420:train.py:189 -         run_log_save():    avg word perp:   6.93
2017-11-30 00:21:38,420:train.py:190 -         run_log_save():    acc trg words/s: 5469
2017-11-30 00:21:38,420:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:22:08,404:train.py:188 -         run_log_save(): Batch 275, epoch 16/20:
2017-11-30 00:22:08,404:train.py:189 -         run_log_save():    avg word perp:   7.04
2017-11-30 00:22:08,404:train.py:190 -         run_log_save():    acc trg words/s: 5459
2017-11-30 00:22:08,404:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:22:38,357:train.py:188 -         run_log_save(): Batch 375, epoch 16/20:
2017-11-30 00:22:38,357:train.py:189 -         run_log_save():    avg word perp:   7.07
2017-11-30 00:22:38,358:train.py:190 -         run_log_save():    acc trg words/s: 5455
2017-11-30 00:22:38,358:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:23:08,598:train.py:188 -         run_log_save(): Batch 475, epoch 16/20:
2017-11-30 00:23:08,598:train.py:189 -         run_log_save():    avg word perp:   7.18
2017-11-30 00:23:08,598:train.py:190 -         run_log_save():    acc trg words/s: 5452
2017-11-30 00:23:08,598:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:23:38,328:train.py:188 -         run_log_save(): Batch 575, epoch 16/20:
2017-11-30 00:23:38,329:train.py:189 -         run_log_save():    avg word perp:   7.13
2017-11-30 00:23:38,329:train.py:190 -         run_log_save():    acc trg words/s: 5458
2017-11-30 00:23:38,329:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:24:07,217:train.py:188 -         run_log_save(): Batch 675, epoch 16/20:
2017-11-30 00:24:07,218:train.py:189 -         run_log_save():    avg word perp:   7.17
2017-11-30 00:24:07,218:train.py:190 -         run_log_save():    acc trg words/s: 5476
2017-11-30 00:24:07,218:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:24:37,081:train.py:188 -         run_log_save(): Batch 775, epoch 16/20:
2017-11-30 00:24:37,082:train.py:189 -         run_log_save():    avg word perp:   7.21
2017-11-30 00:24:37,082:train.py:190 -         run_log_save():    acc trg words/s: 5469
2017-11-30 00:24:37,082:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:25:06,535:train.py:188 -         run_log_save(): Batch 875, epoch 16/20:
2017-11-30 00:25:06,535:train.py:189 -         run_log_save():    avg word perp:   7.23
2017-11-30 00:25:06,535:train.py:190 -         run_log_save():    acc trg words/s: 5476
2017-11-30 00:25:06,535:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:25:36,480:train.py:148 -         sample_input(): Sample input data:
2017-11-30 00:25:36,481:train.py:149 -         sample_input(): Src: ? werden zu licht west@@ ver@@ ohne , werden modernisiert Osten der kann : offen fragen Haupt@@ drei bleiben , annehmen Denkweise als Westens des Definition genannte oben die wir wenn _PAD _PAD
2017-11-30 00:25:36,481:train.py:150 -         sample_input(): Src len: 31
2017-11-30 00:25:36,481:train.py:151 -         sample_input(): Trg: _BOS if we accept the above definition of the West as a mindset , this leaves open three major questions : can the East be modernized without being Westerni@@ zed ? _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:25:36,481:train.py:152 -         sample_input(): Tar: if we accept the above definition of the West as a mindset , this leaves open three major questions : can the East be modernized without being Westerni@@ zed ? _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:25:36,481:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-30 00:25:36,481:train.py:188 -         run_log_save(): Batch 975, epoch 16/20:
2017-11-30 00:25:36,481:train.py:189 -         run_log_save():    avg word perp:   7.40
2017-11-30 00:25:36,481:train.py:190 -         run_log_save():    acc trg words/s: 5469
2017-11-30 00:25:36,481:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:26:06,558:train.py:188 -         run_log_save(): Batch 1075, epoch 16/20:
2017-11-30 00:26:06,558:train.py:189 -         run_log_save():    avg word perp:   7.40
2017-11-30 00:26:06,558:train.py:190 -         run_log_save():    acc trg words/s: 5470
2017-11-30 00:26:06,558:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:26:36,069:train.py:188 -         run_log_save(): Batch 1175, epoch 16/20:
2017-11-30 00:26:36,069:train.py:189 -         run_log_save():    avg word perp:   7.38
2017-11-30 00:26:36,069:train.py:190 -         run_log_save():    acc trg words/s: 5478
2017-11-30 00:26:36,069:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:27:05,260:train.py:188 -         run_log_save(): Batch 1275, epoch 16/20:
2017-11-30 00:27:05,261:train.py:189 -         run_log_save():    avg word perp:   7.39
2017-11-30 00:27:05,261:train.py:190 -         run_log_save():    acc trg words/s: 5483
2017-11-30 00:27:05,261:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:27:35,319:train.py:188 -         run_log_save(): Batch 1375, epoch 16/20:
2017-11-30 00:27:35,319:train.py:189 -         run_log_save():    avg word perp:   7.54
2017-11-30 00:27:35,319:train.py:190 -         run_log_save():    acc trg words/s: 5478
2017-11-30 00:27:35,319:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:28:04,508:train.py:188 -         run_log_save(): Batch 1475, epoch 16/20:
2017-11-30 00:28:04,508:train.py:189 -         run_log_save():    avg word perp:   7.40
2017-11-30 00:28:04,508:train.py:190 -         run_log_save():    acc trg words/s: 5484
2017-11-30 00:28:04,508:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:28:33,966:train.py:188 -         run_log_save(): Batch 1575, epoch 16/20:
2017-11-30 00:28:33,966:train.py:189 -         run_log_save():    avg word perp:   7.45
2017-11-30 00:28:33,967:train.py:190 -         run_log_save():    acc trg words/s: 5486
2017-11-30 00:28:33,967:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:29:03,152:train.py:188 -         run_log_save(): Batch 1675, epoch 16/20:
2017-11-30 00:29:03,152:train.py:189 -         run_log_save():    avg word perp:   7.50
2017-11-30 00:29:03,152:train.py:190 -         run_log_save():    acc trg words/s: 5489
2017-11-30 00:29:03,152:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:29:32,331:train.py:188 -         run_log_save(): Batch 1775, epoch 16/20:
2017-11-30 00:29:32,331:train.py:189 -         run_log_save():    avg word perp:   7.47
2017-11-30 00:29:32,331:train.py:190 -         run_log_save():    acc trg words/s: 5492
2017-11-30 00:29:32,331:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:30:01,831:train.py:188 -         run_log_save(): Batch 1875, epoch 16/20:
2017-11-30 00:30:01,831:train.py:189 -         run_log_save():    avg word perp:   7.48
2017-11-30 00:30:01,831:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-30 00:30:01,831:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:30:30,951:train.py:148 -         sample_input(): Sample input data:
2017-11-30 00:30:30,951:train.py:149 -         sample_input(): Src: . wollen &quot; lieren assimi@@ &quot; schnell sich sie müssten , möchten haben Erfolg Stil @-@ US im sie wenn . bleiben religiös Einwanderer ärmeren diese warum , nicht das erklärt doch _PAD _PAD
2017-11-30 00:30:30,951:train.py:150 -         sample_input(): Src len: 32
2017-11-30 00:30:30,952:train.py:151 -         sample_input(): Trg: _BOS yet this doesn &apos;t explain why these poorer immigrants remain religious ; wanting to succeed US @-@ style , they should want to be quick to &quot; assimi@@ late . &quot; _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:30:30,952:train.py:152 -         sample_input(): Tar: yet this doesn &apos;t explain why these poorer immigrants remain religious ; wanting to succeed US @-@ style , they should want to be quick to &quot; assimi@@ late . &quot; _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:30:30,952:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-30 00:30:30,952:train.py:188 -         run_log_save(): Batch 1975, epoch 16/20:
2017-11-30 00:30:30,952:train.py:189 -         run_log_save():    avg word perp:   7.50
2017-11-30 00:30:30,952:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-30 00:30:30,952:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:30:33,106:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.154058
2017-11-30 00:30:33,106:validator.py:225 -    validate_and_save(): Start validation
2017-11-30 00:30:33,106:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-30 00:31:14,596:validator.py:144 -             evaluate():   Translating line 100, average 0.414360129833 seconds/sent
2017-11-30 00:31:57,208:validator.py:144 -             evaluate():   Translating line 200, average 0.420241980553 seconds/sent
2017-11-30 00:32:32,148:validator.py:144 -             evaluate():   Translating line 300, average 0.39662744681 seconds/sent
2017-11-30 00:33:05,398:validator.py:144 -             evaluate():   Translating line 400, average 0.380595115423 seconds/sent
2017-11-30 00:33:47,690:validator.py:144 -             evaluate():   Translating line 500, average 0.389060394287 seconds/sent
2017-11-30 00:34:20,210:validator.py:144 -             evaluate():   Translating line 600, average 0.378416578372 seconds/sent
2017-11-30 00:35:00,214:validator.py:144 -             evaluate():   Translating line 700, average 0.38150575161 seconds/sent
2017-11-30 00:35:32,877:validator.py:144 -             evaluate():   Translating line 800, average 0.374646448791 seconds/sent
2017-11-30 00:36:02,138:validator.py:144 -             evaluate():   Translating line 900, average 0.36553155899 seconds/sent
2017-11-30 00:36:40,173:validator.py:144 -             evaluate():   Translating line 1000, average 0.367012691975 seconds/sent
2017-11-30 00:37:12,734:validator.py:144 -             evaluate():   Translating line 1100, average 0.363248747262 seconds/sent
2017-11-30 00:37:49,821:validator.py:144 -             evaluate():   Translating line 1200, average 0.36388397336 seconds/sent
2017-11-30 00:38:36,867:validator.py:144 -             evaluate():   Translating line 1300, average 0.3720820139 seconds/sent
2017-11-30 00:39:21,356:validator.py:144 -             evaluate():   Translating line 1400, average 0.377282670736 seconds/sent
2017-11-30 00:40:03,662:validator.py:144 -             evaluate():   Translating line 1500, average 0.380334857305 seconds/sent
2017-11-30 00:40:43,710:validator.py:144 -             evaluate():   Translating line 1600, average 0.381593659371 seconds/sent
2017-11-30 00:41:22,559:validator.py:144 -             evaluate():   Translating line 1700, average 0.381999537664 seconds/sent
2017-11-30 00:42:07,392:validator.py:144 -             evaluate():   Translating line 1800, average 0.385684275627 seconds/sent
2017-11-30 00:42:51,653:validator.py:144 -             evaluate():   Translating line 1900, average 0.38868062584 seconds/sent
2017-11-30 00:43:11,535:validator.py:153 -             evaluate(): Done translating.
2017-11-30 00:43:11,535:validator.py:154 -             evaluate(): dev perplexity: 83.791
2017-11-30 00:43:12,019:validator.py:160 -             evaluate(): BLEU = 12.39, 42.9/18.0/8.8/4.5 (BP=0.939, ratio=0.941, hyp_len=42585, ref_len=45274)

2017-11-30 00:43:12,020:validator.py:161 -             evaluate(): Validation took: 12.6476611495 minutes
2017-11-30 00:43:12,023:validator.py:196 -           maybe_save(): Current best bleus: 12.09
2017-11-30 00:43:12,023:validator.py:197 -           maybe_save(): Delete 12.09 & use 12.39 instead
2017-11-30 00:43:12,023:validator.py:207 -           maybe_save(): Delete ./nmt/saved_models/de2en/de2en-12.09.cpkt.data-00000-of-00001 & ./nmt/saved_models/de2en/de2en-12.09.cpkt.meta & ./nmt/saved_models/de2en/de2en-12.09.cpkt.index
2017-11-30 00:43:12,037:validator.py:213 -           maybe_save(): Save 12.39 to list of best bleu scores
2017-11-30 00:43:12,507:validator.py:217 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en/de2en-12.39.cpkt
2017-11-30 00:43:12,507:validator.py:218 -           maybe_save(): Best bleu scores so far: 12.39
2017-11-30 00:43:42,140:train.py:188 -         run_log_save(): Batch 2075, epoch 16/20:
2017-11-30 00:43:42,141:train.py:189 -         run_log_save():    avg word perp:   7.55
2017-11-30 00:43:42,141:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-30 00:43:42,141:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:44:11,637:train.py:188 -         run_log_save(): Batch 2175, epoch 16/20:
2017-11-30 00:44:11,637:train.py:189 -         run_log_save():    avg word perp:   7.78
2017-11-30 00:44:11,638:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-30 00:44:11,638:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:44:40,804:train.py:188 -         run_log_save(): Batch 2275, epoch 16/20:
2017-11-30 00:44:40,804:train.py:189 -         run_log_save():    avg word perp:   7.60
2017-11-30 00:44:40,804:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-30 00:44:40,804:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:45:10,666:train.py:188 -         run_log_save(): Batch 2375, epoch 16/20:
2017-11-30 00:45:10,666:train.py:189 -         run_log_save():    avg word perp:   7.57
2017-11-30 00:45:10,666:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-30 00:45:10,666:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:45:40,303:train.py:188 -         run_log_save(): Batch 2475, epoch 16/20:
2017-11-30 00:45:40,303:train.py:189 -         run_log_save():    avg word perp:   7.80
2017-11-30 00:45:40,303:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-30 00:45:40,303:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:45:58,828:train.py:116 -         report_epoch(): Finish epoch 16
2017-11-30 00:45:58,828:train.py:117 -         report_epoch():     It takes 0:12:22.073801
2017-11-30 00:45:58,828:train.py:118 -         report_epoch():     Avergage # words/second    5499.13094303
2017-11-30 00:45:58,828:train.py:119 -         report_epoch():     Average seconds/batch    0.292731282368
2017-11-30 00:45:58,828:train.py:130 -         report_epoch():     train perplexity: 7.36619314171
2017-11-30 00:45:59,257:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.428507804871 seconds
2017-11-30 00:46:11,254:train.py:188 -         run_log_save(): Batch 40, epoch 17/20:
2017-11-30 00:46:11,254:train.py:189 -         run_log_save():    avg word perp:   7.31
2017-11-30 00:46:11,254:train.py:190 -         run_log_save():    acc trg words/s: 5419
2017-11-30 00:46:11,254:train.py:191 -         run_log_save():    acc sec/batch:   0.30
2017-11-30 00:46:40,123:train.py:188 -         run_log_save(): Batch 140, epoch 17/20:
2017-11-30 00:46:40,124:train.py:189 -         run_log_save():    avg word perp:   6.46
2017-11-30 00:46:40,124:train.py:190 -         run_log_save():    acc trg words/s: 5518
2017-11-30 00:46:40,124:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:47:09,939:train.py:188 -         run_log_save(): Batch 240, epoch 17/20:
2017-11-30 00:47:09,939:train.py:189 -         run_log_save():    avg word perp:   6.83
2017-11-30 00:47:09,939:train.py:190 -         run_log_save():    acc trg words/s: 5511
2017-11-30 00:47:09,939:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:47:39,560:train.py:188 -         run_log_save(): Batch 340, epoch 17/20:
2017-11-30 00:47:39,560:train.py:189 -         run_log_save():    avg word perp:   6.83
2017-11-30 00:47:39,560:train.py:190 -         run_log_save():    acc trg words/s: 5508
2017-11-30 00:47:39,560:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:48:08,967:train.py:148 -         sample_input(): Sample input data:
2017-11-30 00:48:08,967:train.py:149 -         sample_input(): Src: . Kosovo den über Herrschaft seiner Aufrechterhaltung um Serbiens Bemühungen die offen unterstützt und Nationen Vereinten der lan tsp@@ gkei@@ Unabhängi@@ den gegen Einwände Sicherheitsrat @-@ UN im erhebt es . spielen Muskeln die Kosovo des Zukunft die über Frage der in außerdem lässt Russland _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:48:08,967:train.py:150 -         sample_input(): Src len: 45
2017-11-30 00:48:08,967:train.py:151 -         sample_input(): Trg: _BOS Russia is also f@@ lexing its muscles over the question of Kosovo &apos;s future , raising objections in the United Nations Security Council to the UN &apos;s plan for independence and openly supporting Serbia &apos;s quest to maintain its supremacy over Kosovo . _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:48:08,967:train.py:152 -         sample_input(): Tar: Russia is also f@@ lexing its muscles over the question of Kosovo &apos;s future , raising objections in the United Nations Security Council to the UN &apos;s plan for independence and openly supporting Serbia &apos;s quest to maintain its supremacy over Kosovo . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:48:08,968:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-30 00:48:08,968:train.py:188 -         run_log_save(): Batch 440, epoch 17/20:
2017-11-30 00:48:08,968:train.py:189 -         run_log_save():    avg word perp:   6.80
2017-11-30 00:48:08,968:train.py:190 -         run_log_save():    acc trg words/s: 5514
2017-11-30 00:48:08,968:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:48:39,046:train.py:188 -         run_log_save(): Batch 540, epoch 17/20:
2017-11-30 00:48:39,046:train.py:189 -         run_log_save():    avg word perp:   6.93
2017-11-30 00:48:39,047:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-30 00:48:39,047:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:49:08,617:train.py:188 -         run_log_save(): Batch 640, epoch 17/20:
2017-11-30 00:49:08,618:train.py:189 -         run_log_save():    avg word perp:   6.85
2017-11-30 00:49:08,618:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-30 00:49:08,618:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:49:38,035:train.py:188 -         run_log_save(): Batch 740, epoch 17/20:
2017-11-30 00:49:38,035:train.py:189 -         run_log_save():    avg word perp:   7.06
2017-11-30 00:49:38,035:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-30 00:49:38,035:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:50:07,436:train.py:188 -         run_log_save(): Batch 840, epoch 17/20:
2017-11-30 00:50:07,436:train.py:189 -         run_log_save():    avg word perp:   7.00
2017-11-30 00:50:07,436:train.py:190 -         run_log_save():    acc trg words/s: 5505
2017-11-30 00:50:07,436:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:50:36,691:train.py:188 -         run_log_save(): Batch 940, epoch 17/20:
2017-11-30 00:50:36,692:train.py:189 -         run_log_save():    avg word perp:   7.09
2017-11-30 00:50:36,692:train.py:190 -         run_log_save():    acc trg words/s: 5510
2017-11-30 00:50:36,692:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:51:06,360:train.py:188 -         run_log_save(): Batch 1040, epoch 17/20:
2017-11-30 00:51:06,360:train.py:189 -         run_log_save():    avg word perp:   7.01
2017-11-30 00:51:06,360:train.py:190 -         run_log_save():    acc trg words/s: 5509
2017-11-30 00:51:06,360:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:51:35,987:train.py:188 -         run_log_save(): Batch 1140, epoch 17/20:
2017-11-30 00:51:35,987:train.py:189 -         run_log_save():    avg word perp:   7.08
2017-11-30 00:51:35,987:train.py:190 -         run_log_save():    acc trg words/s: 5510
2017-11-30 00:51:35,987:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:52:05,657:train.py:188 -         run_log_save(): Batch 1240, epoch 17/20:
2017-11-30 00:52:05,657:train.py:189 -         run_log_save():    avg word perp:   7.08
2017-11-30 00:52:05,657:train.py:190 -         run_log_save():    acc trg words/s: 5511
2017-11-30 00:52:05,657:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:52:35,163:train.py:188 -         run_log_save(): Batch 1340, epoch 17/20:
2017-11-30 00:52:35,163:train.py:189 -         run_log_save():    avg word perp:   7.21
2017-11-30 00:52:35,163:train.py:190 -         run_log_save():    acc trg words/s: 5509
2017-11-30 00:52:35,163:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:53:04,853:train.py:148 -         sample_input(): Sample input data:
2017-11-30 00:53:04,853:train.py:149 -         sample_input(): Src: . zusammen Wohnungsbau und Gesundheit , Bildung für posten Haushalts@@ die als höher sind , zahlt redite sk@@ Ausland@@ seine auf Land das die , Zinsen die : Tatsache rende ö@@ verst@@ eine zeigt Finanzen öffentliche Ägyptens auf Blick ein : YORK New _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:53:04,853:train.py:150 -         sample_input(): Src len: 43
2017-11-30 00:53:04,853:train.py:151 -         sample_input(): Trg: _BOS new YORK - A glance at Egypt &apos;s public finances reveals a disturbing fact : the interest that the country pays on its foreign loans is larger than its budget for education , healthcare , and housing combined . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:53:04,853:train.py:152 -         sample_input(): Tar: new YORK - A glance at Egypt &apos;s public finances reveals a disturbing fact : the interest that the country pays on its foreign loans is larger than its budget for education , healthcare , and housing combined . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:53:04,853:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-30 00:53:04,854:train.py:188 -         run_log_save(): Batch 1440, epoch 17/20:
2017-11-30 00:53:04,854:train.py:189 -         run_log_save():    avg word perp:   7.18
2017-11-30 00:53:04,854:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-30 00:53:04,854:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:53:07,114:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.259853
2017-11-30 00:53:36,756:train.py:188 -         run_log_save(): Batch 1540, epoch 17/20:
2017-11-30 00:53:36,757:train.py:189 -         run_log_save():    avg word perp:   7.08
2017-11-30 00:53:36,757:train.py:190 -         run_log_save():    acc trg words/s: 5505
2017-11-30 00:53:36,757:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:54:06,053:train.py:188 -         run_log_save(): Batch 1640, epoch 17/20:
2017-11-30 00:54:06,053:train.py:189 -         run_log_save():    avg word perp:   7.07
2017-11-30 00:54:06,054:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-30 00:54:06,054:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:54:35,589:train.py:188 -         run_log_save(): Batch 1740, epoch 17/20:
2017-11-30 00:54:35,589:train.py:189 -         run_log_save():    avg word perp:   7.31
2017-11-30 00:54:35,589:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-30 00:54:35,589:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:55:05,424:train.py:188 -         run_log_save(): Batch 1840, epoch 17/20:
2017-11-30 00:55:05,424:train.py:189 -         run_log_save():    avg word perp:   7.30
2017-11-30 00:55:05,424:train.py:190 -         run_log_save():    acc trg words/s: 5506
2017-11-30 00:55:05,424:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:55:35,465:train.py:188 -         run_log_save(): Batch 1940, epoch 17/20:
2017-11-30 00:55:35,465:train.py:189 -         run_log_save():    avg word perp:   7.31
2017-11-30 00:55:35,466:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-30 00:55:35,466:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:56:05,791:train.py:188 -         run_log_save(): Batch 2040, epoch 17/20:
2017-11-30 00:56:05,791:train.py:189 -         run_log_save():    avg word perp:   7.43
2017-11-30 00:56:05,791:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-30 00:56:05,791:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:56:35,360:train.py:188 -         run_log_save(): Batch 2140, epoch 17/20:
2017-11-30 00:56:35,361:train.py:189 -         run_log_save():    avg word perp:   7.37
2017-11-30 00:56:35,361:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-30 00:56:35,361:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:57:05,307:train.py:188 -         run_log_save(): Batch 2240, epoch 17/20:
2017-11-30 00:57:05,307:train.py:189 -         run_log_save():    avg word perp:   7.34
2017-11-30 00:57:05,308:train.py:190 -         run_log_save():    acc trg words/s: 5491
2017-11-30 00:57:05,308:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:57:34,727:train.py:188 -         run_log_save(): Batch 2340, epoch 17/20:
2017-11-30 00:57:34,728:train.py:189 -         run_log_save():    avg word perp:   7.29
2017-11-30 00:57:34,728:train.py:190 -         run_log_save():    acc trg words/s: 5492
2017-11-30 00:57:34,728:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:58:04,141:train.py:148 -         sample_input(): Sample input data:
2017-11-30 00:58:04,142:train.py:149 -         sample_input(): Src: . Land im Bürger normaler als nunmehr lebt und ast al@@ sp@@ g@@ Köni@@ den Shah a endr@@ yan@@ G@@ König ehemalige der verließ Juni im . ab Monarchie alte Jahre 39 2@@ die einstimmig beinahe Versammlung die schaffte lung shand@@ Amt@@ erste als _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 00:58:04,142:train.py:150 -         sample_input(): Src len: 44
2017-11-30 00:58:04,142:train.py:151 -         sample_input(): Trg: _BOS the Assembly &apos;s opening action had been to vote almost unanimously to abolish the 2@@ 39 @-@ year @-@ old monarchy , and in June former King G@@ yan@@ endr@@ a Shah depar@@ ted from the palace , remaining in the country as an ordinary citizen . _PAD _PAD
2017-11-30 00:58:04,142:train.py:152 -         sample_input(): Tar: the Assembly &apos;s opening action had been to vote almost unanimously to abolish the 2@@ 39 @-@ year @-@ old monarchy , and in June former King G@@ yan@@ endr@@ a Shah depar@@ ted from the palace , remaining in the country as an ordinary citizen . _EOS _PAD _PAD
2017-11-30 00:58:04,142:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0
2017-11-30 00:58:04,142:train.py:188 -         run_log_save(): Batch 2440, epoch 17/20:
2017-11-30 00:58:04,142:train.py:189 -         run_log_save():    avg word perp:   7.40
2017-11-30 00:58:04,142:train.py:190 -         run_log_save():    acc trg words/s: 5494
2017-11-30 00:58:04,142:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:58:31,921:train.py:116 -         report_epoch(): Finish epoch 17
2017-11-30 00:58:31,921:train.py:117 -         report_epoch():     It takes 0:12:22.573526
2017-11-30 00:58:31,921:train.py:118 -         report_epoch():     Avergage # words/second    5495.40194517
2017-11-30 00:58:31,921:train.py:119 -         report_epoch():     Average seconds/batch    0.29292841268
2017-11-30 00:58:31,921:train.py:130 -         report_epoch():     train perplexity: 7.09158728978
2017-11-30 00:58:32,361:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.439023017883 seconds
2017-11-30 00:58:33,214:train.py:188 -         run_log_save(): Batch 5, epoch 18/20:
2017-11-30 00:58:33,215:train.py:189 -         run_log_save():    avg word perp:   7.21
2017-11-30 00:58:33,215:train.py:190 -         run_log_save():    acc trg words/s: 5506
2017-11-30 00:58:33,215:train.py:191 -         run_log_save():    acc sec/batch:   0.16
2017-11-30 00:59:02,667:train.py:188 -         run_log_save(): Batch 105, epoch 18/20:
2017-11-30 00:59:02,667:train.py:189 -         run_log_save():    avg word perp:   6.46
2017-11-30 00:59:02,667:train.py:190 -         run_log_save():    acc trg words/s: 5558
2017-11-30 00:59:02,668:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 00:59:32,140:train.py:188 -         run_log_save(): Batch 205, epoch 18/20:
2017-11-30 00:59:32,140:train.py:189 -         run_log_save():    avg word perp:   6.46
2017-11-30 00:59:32,140:train.py:190 -         run_log_save():    acc trg words/s: 5538
2017-11-30 00:59:32,140:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:00:02,049:train.py:188 -         run_log_save(): Batch 305, epoch 18/20:
2017-11-30 01:00:02,049:train.py:189 -         run_log_save():    avg word perp:   6.63
2017-11-30 01:00:02,049:train.py:190 -         run_log_save():    acc trg words/s: 5518
2017-11-30 01:00:02,049:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:00:31,771:train.py:188 -         run_log_save(): Batch 405, epoch 18/20:
2017-11-30 01:00:31,771:train.py:189 -         run_log_save():    avg word perp:   6.50
2017-11-30 01:00:31,772:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-30 01:00:31,772:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:01:01,545:train.py:188 -         run_log_save(): Batch 505, epoch 18/20:
2017-11-30 01:01:01,545:train.py:189 -         run_log_save():    avg word perp:   6.67
2017-11-30 01:01:01,545:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-30 01:01:01,545:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:01:31,092:train.py:188 -         run_log_save(): Batch 605, epoch 18/20:
2017-11-30 01:01:31,092:train.py:189 -         run_log_save():    avg word perp:   6.56
2017-11-30 01:01:31,093:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-30 01:01:31,093:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:02:00,679:train.py:188 -         run_log_save(): Batch 705, epoch 18/20:
2017-11-30 01:02:00,679:train.py:189 -         run_log_save():    avg word perp:   6.61
2017-11-30 01:02:00,679:train.py:190 -         run_log_save():    acc trg words/s: 5499
2017-11-30 01:02:00,679:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:02:30,435:train.py:188 -         run_log_save(): Batch 805, epoch 18/20:
2017-11-30 01:02:30,435:train.py:189 -         run_log_save():    avg word perp:   6.80
2017-11-30 01:02:30,435:train.py:190 -         run_log_save():    acc trg words/s: 5503
2017-11-30 01:02:30,435:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:02:59,482:train.py:148 -         sample_input(): Sample input data:
2017-11-30 01:02:59,482:train.py:149 -         sample_input(): Src: : vorschlagen Balkan den für Plan @-@ Punkte @-@ Drei einen sollte Union Europäische die _PAD _PAD
2017-11-30 01:02:59,482:train.py:150 -         sample_input(): Src len: 15
2017-11-30 01:02:59,482:train.py:151 -         sample_input(): Trg: _BOS the European Union should now propose a three @-@ point plan for the Balkans : _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 01:02:59,482:train.py:152 -         sample_input(): Tar: the European Union should now propose a three @-@ point plan for the Balkans : _EOS _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 01:02:59,482:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-30 01:02:59,483:train.py:188 -         run_log_save(): Batch 905, epoch 18/20:
2017-11-30 01:02:59,483:train.py:189 -         run_log_save():    avg word perp:   6.69
2017-11-30 01:02:59,483:train.py:190 -         run_log_save():    acc trg words/s: 5511
2017-11-30 01:02:59,483:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:03:01,735:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.252666
2017-11-30 01:03:31,322:train.py:188 -         run_log_save(): Batch 1005, epoch 18/20:
2017-11-30 01:03:31,322:train.py:189 -         run_log_save():    avg word perp:   6.73
2017-11-30 01:03:31,322:train.py:190 -         run_log_save():    acc trg words/s: 5510
2017-11-30 01:03:31,322:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:04:00,729:train.py:188 -         run_log_save(): Batch 1105, epoch 18/20:
2017-11-30 01:04:00,729:train.py:189 -         run_log_save():    avg word perp:   6.83
2017-11-30 01:04:00,729:train.py:190 -         run_log_save():    acc trg words/s: 5512
2017-11-30 01:04:00,729:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:04:30,162:train.py:188 -         run_log_save(): Batch 1205, epoch 18/20:
2017-11-30 01:04:30,162:train.py:189 -         run_log_save():    avg word perp:   6.85
2017-11-30 01:04:30,162:train.py:190 -         run_log_save():    acc trg words/s: 5510
2017-11-30 01:04:30,163:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:04:59,666:train.py:188 -         run_log_save(): Batch 1305, epoch 18/20:
2017-11-30 01:04:59,666:train.py:189 -         run_log_save():    avg word perp:   6.94
2017-11-30 01:04:59,666:train.py:190 -         run_log_save():    acc trg words/s: 5508
2017-11-30 01:04:59,666:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:05:29,184:train.py:188 -         run_log_save(): Batch 1405, epoch 18/20:
2017-11-30 01:05:29,184:train.py:189 -         run_log_save():    avg word perp:   6.91
2017-11-30 01:05:29,184:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-30 01:05:29,184:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:05:58,767:train.py:188 -         run_log_save(): Batch 1505, epoch 18/20:
2017-11-30 01:05:58,767:train.py:189 -         run_log_save():    avg word perp:   6.85
2017-11-30 01:05:58,767:train.py:190 -         run_log_save():    acc trg words/s: 5508
2017-11-30 01:05:58,767:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:06:28,401:train.py:188 -         run_log_save(): Batch 1605, epoch 18/20:
2017-11-30 01:06:28,402:train.py:189 -         run_log_save():    avg word perp:   7.03
2017-11-30 01:06:28,402:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-30 01:06:28,402:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:06:57,757:train.py:188 -         run_log_save(): Batch 1705, epoch 18/20:
2017-11-30 01:06:57,757:train.py:189 -         run_log_save():    avg word perp:   6.92
2017-11-30 01:06:57,757:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-30 01:06:57,757:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:07:26,969:train.py:188 -         run_log_save(): Batch 1805, epoch 18/20:
2017-11-30 01:07:26,969:train.py:189 -         run_log_save():    avg word perp:   7.01
2017-11-30 01:07:26,969:train.py:190 -         run_log_save():    acc trg words/s: 5509
2017-11-30 01:07:26,969:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:07:56,914:train.py:148 -         sample_input(): Sample input data:
2017-11-30 01:07:56,915:train.py:149 -         sample_input(): Src: . Union Europäischen der Ländern den und Russland zwischen Vertrauen gegenseitiges wenig herrschte Zeit letzter in _PAD
2017-11-30 01:07:56,915:train.py:150 -         sample_input(): Src len: 16
2017-11-30 01:07:56,915:train.py:151 -         sample_input(): Trg: _BOS there has been little mutual trust lately between the governments of Russia and the European Union . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 01:07:56,915:train.py:152 -         sample_input(): Tar: there has been little mutual trust lately between the governments of Russia and the European Union . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 01:07:56,915:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-30 01:07:56,915:train.py:188 -         run_log_save(): Batch 1905, epoch 18/20:
2017-11-30 01:07:56,915:train.py:189 -         run_log_save():    avg word perp:   7.12
2017-11-30 01:07:56,915:train.py:190 -         run_log_save():    acc trg words/s: 5506
2017-11-30 01:07:56,915:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:07:56,915:validator.py:225 -    validate_and_save(): Start validation
2017-11-30 01:07:56,915:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-30 01:08:37,152:validator.py:144 -             evaluate():   Translating line 100, average 0.401815021038 seconds/sent
2017-11-30 01:09:16,269:validator.py:144 -             evaluate():   Translating line 200, average 0.39649407506 seconds/sent
2017-11-30 01:09:49,328:validator.py:144 -             evaluate():   Translating line 300, average 0.374526697 seconds/sent
2017-11-30 01:10:26,403:validator.py:144 -             evaluate():   Translating line 400, average 0.373583262563 seconds/sent
2017-11-30 01:11:10,440:validator.py:144 -             evaluate():   Translating line 500, average 0.386939700127 seconds/sent
2017-11-30 01:11:42,519:validator.py:144 -             evaluate():   Translating line 600, average 0.375914788246 seconds/sent
2017-11-30 01:12:22,620:validator.py:144 -             evaluate():   Translating line 700, average 0.37950030429 seconds/sent
2017-11-30 01:12:55,800:validator.py:144 -             evaluate():   Translating line 800, average 0.373537658751 seconds/sent
2017-11-30 01:13:26,240:validator.py:144 -             evaluate():   Translating line 900, average 0.365854912334 seconds/sent
2017-11-30 01:13:59,324:validator.py:144 -             evaluate():   Translating line 1000, average 0.362353811026 seconds/sent
2017-11-30 01:14:31,510:validator.py:144 -             evaluate():   Translating line 1100, average 0.358672479066 seconds/sent
2017-11-30 01:15:07,677:validator.py:144 -             evaluate():   Translating line 1200, average 0.358922101657 seconds/sent
2017-11-30 01:15:53,473:validator.py:144 -             evaluate():   Translating line 1300, average 0.366540695337 seconds/sent
2017-11-30 01:16:35,029:validator.py:144 -             evaluate():   Translating line 1400, average 0.370042313508 seconds/sent
2017-11-30 01:17:18,322:validator.py:144 -             evaluate():   Translating line 1500, average 0.374234323343 seconds/sent
2017-11-30 01:17:58,826:validator.py:144 -             evaluate():   Translating line 1600, average 0.376159759313 seconds/sent
2017-11-30 01:18:41,649:validator.py:144 -             evaluate():   Translating line 1700, average 0.379222831726 seconds/sent
2017-11-30 01:19:28,014:validator.py:144 -             evaluate():   Translating line 1800, average 0.383913102282 seconds/sent
2017-11-30 01:20:13,814:validator.py:144 -             evaluate():   Translating line 1900, average 0.387812486824 seconds/sent
2017-11-30 01:20:36,896:validator.py:153 -             evaluate(): Done translating.
2017-11-30 01:20:36,896:validator.py:154 -             evaluate(): dev perplexity: 83.84
2017-11-30 01:20:37,398:validator.py:160 -             evaluate(): BLEU = 12.82, 41.9/17.8/8.8/4.5 (BP=0.981, ratio=0.981, hyp_len=44414, ref_len=45274)

2017-11-30 01:20:37,398:validator.py:161 -             evaluate(): Validation took: 12.6738065839 minutes
2017-11-30 01:20:37,401:validator.py:196 -           maybe_save(): Current best bleus: 12.39
2017-11-30 01:20:37,401:validator.py:197 -           maybe_save(): Delete 12.39 & use 12.82 instead
2017-11-30 01:20:37,402:validator.py:207 -           maybe_save(): Delete ./nmt/saved_models/de2en/de2en-12.39.cpkt.data-00000-of-00001 & ./nmt/saved_models/de2en/de2en-12.39.cpkt.meta & ./nmt/saved_models/de2en/de2en-12.39.cpkt.index
2017-11-30 01:20:37,416:validator.py:213 -           maybe_save(): Save 12.82 to list of best bleu scores
2017-11-30 01:20:37,886:validator.py:217 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en/de2en-12.82.cpkt
2017-11-30 01:20:37,886:validator.py:218 -           maybe_save(): Best bleu scores so far: 12.82
2017-11-30 01:21:07,353:train.py:188 -         run_log_save(): Batch 2005, epoch 18/20:
2017-11-30 01:21:07,353:train.py:189 -         run_log_save():    avg word perp:   6.97
2017-11-30 01:21:07,353:train.py:190 -         run_log_save():    acc trg words/s: 5506
2017-11-30 01:21:07,353:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:21:37,057:train.py:188 -         run_log_save(): Batch 2105, epoch 18/20:
2017-11-30 01:21:37,058:train.py:189 -         run_log_save():    avg word perp:   6.97
2017-11-30 01:21:37,058:train.py:190 -         run_log_save():    acc trg words/s: 5504
2017-11-30 01:21:37,058:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:22:06,907:train.py:188 -         run_log_save(): Batch 2205, epoch 18/20:
2017-11-30 01:22:06,907:train.py:189 -         run_log_save():    avg word perp:   7.18
2017-11-30 01:22:06,907:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-30 01:22:06,907:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:22:36,516:train.py:188 -         run_log_save(): Batch 2305, epoch 18/20:
2017-11-30 01:22:36,516:train.py:189 -         run_log_save():    avg word perp:   7.23
2017-11-30 01:22:36,516:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-30 01:22:36,516:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:23:05,994:train.py:188 -         run_log_save(): Batch 2405, epoch 18/20:
2017-11-30 01:23:05,994:train.py:189 -         run_log_save():    avg word perp:   7.20
2017-11-30 01:23:05,994:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-30 01:23:05,994:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:23:35,551:train.py:188 -         run_log_save(): Batch 2505, epoch 18/20:
2017-11-30 01:23:35,552:train.py:189 -         run_log_save():    avg word perp:   7.08
2017-11-30 01:23:35,552:train.py:190 -         run_log_save():    acc trg words/s: 5503
2017-11-30 01:23:35,552:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:23:44,840:train.py:116 -         report_epoch(): Finish epoch 18
2017-11-30 01:23:44,840:train.py:117 -         report_epoch():     It takes 0:12:21.327783
2017-11-30 01:23:44,841:train.py:118 -         report_epoch():     Avergage # words/second    5504.64462775
2017-11-30 01:23:44,841:train.py:119 -         report_epoch():     Average seconds/batch    0.292436995403
2017-11-30 01:23:44,841:train.py:130 -         report_epoch():     train perplexity: 6.84527031014
2017-11-30 01:23:45,285:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.444094896317 seconds
2017-11-30 01:24:04,680:train.py:188 -         run_log_save(): Batch 70, epoch 19/20:
2017-11-30 01:24:04,680:train.py:189 -         run_log_save():    avg word perp:   6.27
2017-11-30 01:24:04,680:train.py:190 -         run_log_save():    acc trg words/s: 5565
2017-11-30 01:24:04,680:train.py:191 -         run_log_save():    acc sec/batch:   0.27
2017-11-30 01:24:34,387:train.py:188 -         run_log_save(): Batch 170, epoch 19/20:
2017-11-30 01:24:34,387:train.py:189 -         run_log_save():    avg word perp:   6.17
2017-11-30 01:24:34,387:train.py:190 -         run_log_save():    acc trg words/s: 5520
2017-11-30 01:24:34,387:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:25:03,506:train.py:188 -         run_log_save(): Batch 270, epoch 19/20:
2017-11-30 01:25:03,506:train.py:189 -         run_log_save():    avg word perp:   6.24
2017-11-30 01:25:03,506:train.py:190 -         run_log_save():    acc trg words/s: 5535
2017-11-30 01:25:03,506:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:25:33,081:train.py:148 -         sample_input(): Sample input data:
2017-11-30 01:25:33,082:train.py:149 -         sample_input(): Src: . führen zu Demokratisierung und Befreiung der Krieg effektiven einen um , Verhältnisse komplizierten der Verständnis am es fehlte Irakkrieges des Befürwortern den _PAD
2017-11-30 01:25:33,082:train.py:150 -         sample_input(): Src len: 23
2017-11-30 01:25:33,082:train.py:151 -         sample_input(): Trg: _BOS advocates of the Iraq war lacked an understanding of the complexities on the ground to wage an effective war of liberation and democratization . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 01:25:33,082:train.py:152 -         sample_input(): Tar: advocates of the Iraq war lacked an understanding of the complexities on the ground to wage an effective war of liberation and democratization . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 01:25:33,082:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-30 01:25:33,082:train.py:188 -         run_log_save(): Batch 370, epoch 19/20:
2017-11-30 01:25:33,082:train.py:189 -         run_log_save():    avg word perp:   6.37
2017-11-30 01:25:33,082:train.py:190 -         run_log_save():    acc trg words/s: 5530
2017-11-30 01:25:33,082:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:25:35,275:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.192445
2017-11-30 01:26:04,835:train.py:188 -         run_log_save(): Batch 470, epoch 19/20:
2017-11-30 01:26:04,835:train.py:189 -         run_log_save():    avg word perp:   6.30
2017-11-30 01:26:04,835:train.py:190 -         run_log_save():    acc trg words/s: 5521
2017-11-30 01:26:04,835:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:26:34,348:train.py:188 -         run_log_save(): Batch 570, epoch 19/20:
2017-11-30 01:26:34,349:train.py:189 -         run_log_save():    avg word perp:   6.41
2017-11-30 01:26:34,349:train.py:190 -         run_log_save():    acc trg words/s: 5512
2017-11-30 01:26:34,349:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:27:04,041:train.py:188 -         run_log_save(): Batch 670, epoch 19/20:
2017-11-30 01:27:04,041:train.py:189 -         run_log_save():    avg word perp:   6.36
2017-11-30 01:27:04,041:train.py:190 -         run_log_save():    acc trg words/s: 5513
2017-11-30 01:27:04,041:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:27:33,824:train.py:188 -         run_log_save(): Batch 770, epoch 19/20:
2017-11-30 01:27:33,824:train.py:189 -         run_log_save():    avg word perp:   6.51
2017-11-30 01:27:33,824:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-30 01:27:33,824:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:28:03,667:train.py:188 -         run_log_save(): Batch 870, epoch 19/20:
2017-11-30 01:28:03,667:train.py:189 -         run_log_save():    avg word perp:   6.47
2017-11-30 01:28:03,667:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-30 01:28:03,667:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:28:33,047:train.py:188 -         run_log_save(): Batch 970, epoch 19/20:
2017-11-30 01:28:33,048:train.py:189 -         run_log_save():    avg word perp:   6.48
2017-11-30 01:28:33,048:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-30 01:28:33,048:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:29:02,615:train.py:188 -         run_log_save(): Batch 1070, epoch 19/20:
2017-11-30 01:29:02,615:train.py:189 -         run_log_save():    avg word perp:   6.52
2017-11-30 01:29:02,615:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-30 01:29:02,615:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:29:32,515:train.py:188 -         run_log_save(): Batch 1170, epoch 19/20:
2017-11-30 01:29:32,515:train.py:189 -         run_log_save():    avg word perp:   6.48
2017-11-30 01:29:32,515:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-30 01:29:32,515:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:30:01,981:train.py:188 -         run_log_save(): Batch 1270, epoch 19/20:
2017-11-30 01:30:01,981:train.py:189 -         run_log_save():    avg word perp:   6.74
2017-11-30 01:30:01,981:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-30 01:30:01,981:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:30:31,280:train.py:148 -         sample_input(): Sample input data:
2017-11-30 01:30:31,281:train.py:149 -         sample_input(): Src: . schützen zu - Serben die insbesondere - Minderheiten die um , schaffen zu mechanismen Sicherheits@@ starke , erforderlich zwingend daher ist es _PAD _PAD
2017-11-30 01:30:31,281:train.py:150 -         sample_input(): Src len: 23
2017-11-30 01:30:31,281:train.py:151 -         sample_input(): Trg: _BOS so it is imperative that strong safeguards are put in place to protect minorities , particularly the Serbs . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 01:30:31,281:train.py:152 -         sample_input(): Tar: so it is imperative that strong safeguards are put in place to protect minorities , particularly the Serbs . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 01:30:31,281:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-30 01:30:31,281:train.py:188 -         run_log_save(): Batch 1370, epoch 19/20:
2017-11-30 01:30:31,281:train.py:189 -         run_log_save():    avg word perp:   6.80
2017-11-30 01:30:31,281:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-30 01:30:31,281:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:31:00,748:train.py:188 -         run_log_save(): Batch 1470, epoch 19/20:
2017-11-30 01:31:00,748:train.py:189 -         run_log_save():    avg word perp:   6.76
2017-11-30 01:31:00,748:train.py:190 -         run_log_save():    acc trg words/s: 5505
2017-11-30 01:31:00,748:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:31:29,910:train.py:188 -         run_log_save(): Batch 1570, epoch 19/20:
2017-11-30 01:31:29,910:train.py:189 -         run_log_save():    avg word perp:   6.71
2017-11-30 01:31:29,910:train.py:190 -         run_log_save():    acc trg words/s: 5510
2017-11-30 01:31:29,911:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:31:59,684:train.py:188 -         run_log_save(): Batch 1670, epoch 19/20:
2017-11-30 01:31:59,685:train.py:189 -         run_log_save():    avg word perp:   6.86
2017-11-30 01:31:59,685:train.py:190 -         run_log_save():    acc trg words/s: 5509
2017-11-30 01:31:59,685:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:32:29,190:train.py:188 -         run_log_save(): Batch 1770, epoch 19/20:
2017-11-30 01:32:29,191:train.py:189 -         run_log_save():    avg word perp:   6.96
2017-11-30 01:32:29,191:train.py:190 -         run_log_save():    acc trg words/s: 5510
2017-11-30 01:32:29,191:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:32:58,709:train.py:188 -         run_log_save(): Batch 1870, epoch 19/20:
2017-11-30 01:32:58,709:train.py:189 -         run_log_save():    avg word perp:   6.82
2017-11-30 01:32:58,709:train.py:190 -         run_log_save():    acc trg words/s: 5510
2017-11-30 01:32:58,709:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:33:28,210:train.py:188 -         run_log_save(): Batch 1970, epoch 19/20:
2017-11-30 01:33:28,210:train.py:189 -         run_log_save():    avg word perp:   6.83
2017-11-30 01:33:28,210:train.py:190 -         run_log_save():    acc trg words/s: 5509
2017-11-30 01:33:28,210:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:33:57,886:train.py:188 -         run_log_save(): Batch 2070, epoch 19/20:
2017-11-30 01:33:57,886:train.py:189 -         run_log_save():    avg word perp:   6.89
2017-11-30 01:33:57,887:train.py:190 -         run_log_save():    acc trg words/s: 5509
2017-11-30 01:33:57,887:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:34:27,842:train.py:188 -         run_log_save(): Batch 2170, epoch 19/20:
2017-11-30 01:34:27,842:train.py:189 -         run_log_save():    avg word perp:   6.86
2017-11-30 01:34:27,842:train.py:190 -         run_log_save():    acc trg words/s: 5506
2017-11-30 01:34:27,842:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:34:57,405:train.py:188 -         run_log_save(): Batch 2270, epoch 19/20:
2017-11-30 01:34:57,405:train.py:189 -         run_log_save():    avg word perp:   7.00
2017-11-30 01:34:57,405:train.py:190 -         run_log_save():    acc trg words/s: 5506
2017-11-30 01:34:57,406:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:35:28,181:train.py:148 -         sample_input(): Sample input data:
2017-11-30 01:35:28,181:train.py:149 -         sample_input(): Src: . werden getrieben möglich wie hoch so Preise ihre dass , kaufen Mengen großen so in Staatsanleihen Zentralbanken die sollten darauf Antwort als _PAD
2017-11-30 01:35:28,181:train.py:150 -         sample_input(): Src len: 23
2017-11-30 01:35:28,181:train.py:151 -         sample_input(): Trg: _BOS in response , central banks should purchase government bonds for cash in as large a quantity as needed to push their prices up as high as possible . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 01:35:28,182:train.py:152 -         sample_input(): Tar: in response , central banks should purchase government bonds for cash in as large a quantity as needed to push their prices up as high as possible . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 01:35:28,182:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-30 01:35:28,182:train.py:188 -         run_log_save(): Batch 2370, epoch 19/20:
2017-11-30 01:35:28,182:train.py:189 -         run_log_save():    avg word perp:   6.98
2017-11-30 01:35:28,182:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-30 01:35:28,182:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:35:30,338:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.156542
2017-11-30 01:35:59,347:train.py:188 -         run_log_save(): Batch 2470, epoch 19/20:
2017-11-30 01:35:59,347:train.py:189 -         run_log_save():    avg word perp:   6.98
2017-11-30 01:35:59,347:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-30 01:35:59,347:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:36:19,149:train.py:116 -         report_epoch(): Finish epoch 19
2017-11-30 01:36:19,149:train.py:117 -         report_epoch():     It takes 0:12:21.507589
2017-11-30 01:36:19,149:train.py:118 -         report_epoch():     Avergage # words/second    5503.35702734
2017-11-30 01:36:19,149:train.py:119 -         report_epoch():     Average seconds/batch    0.292507924601
2017-11-30 01:36:19,149:train.py:130 -         report_epoch():     train perplexity: 6.62979508819
2017-11-30 01:36:19,593:data_manager.py:317 -            get_batch(): Shuffling ./nmt/data/de2en/train.ids takes 0.443826913834 seconds
2017-11-30 01:36:29,117:train.py:188 -         run_log_save(): Batch 35, epoch 20/20:
2017-11-30 01:36:29,117:train.py:189 -         run_log_save():    avg word perp:   6.48
2017-11-30 01:36:29,117:train.py:190 -         run_log_save():    acc trg words/s: 5519
2017-11-30 01:36:29,117:train.py:191 -         run_log_save():    acc sec/batch:   0.27
2017-11-30 01:36:59,128:train.py:188 -         run_log_save(): Batch 135, epoch 20/20:
2017-11-30 01:36:59,128:train.py:189 -         run_log_save():    avg word perp:   6.02
2017-11-30 01:36:59,128:train.py:190 -         run_log_save():    acc trg words/s: 5449
2017-11-30 01:36:59,128:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:37:28,899:train.py:188 -         run_log_save(): Batch 235, epoch 20/20:
2017-11-30 01:37:28,899:train.py:189 -         run_log_save():    avg word perp:   6.09
2017-11-30 01:37:28,899:train.py:190 -         run_log_save():    acc trg words/s: 5479
2017-11-30 01:37:28,899:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:37:58,548:train.py:188 -         run_log_save(): Batch 335, epoch 20/20:
2017-11-30 01:37:58,549:train.py:189 -         run_log_save():    avg word perp:   5.99
2017-11-30 01:37:58,549:train.py:190 -         run_log_save():    acc trg words/s: 5479
2017-11-30 01:37:58,549:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:38:27,956:train.py:188 -         run_log_save(): Batch 435, epoch 20/20:
2017-11-30 01:38:27,956:train.py:189 -         run_log_save():    avg word perp:   6.29
2017-11-30 01:38:27,957:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-30 01:38:27,957:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:38:57,648:train.py:188 -         run_log_save(): Batch 535, epoch 20/20:
2017-11-30 01:38:57,648:train.py:189 -         run_log_save():    avg word perp:   6.24
2017-11-30 01:38:57,648:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-30 01:38:57,648:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:39:27,522:train.py:188 -         run_log_save(): Batch 635, epoch 20/20:
2017-11-30 01:39:27,522:train.py:189 -         run_log_save():    avg word perp:   6.19
2017-11-30 01:39:27,522:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-30 01:39:27,522:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:39:56,581:train.py:188 -         run_log_save(): Batch 735, epoch 20/20:
2017-11-30 01:39:56,582:train.py:189 -         run_log_save():    avg word perp:   6.21
2017-11-30 01:39:56,582:train.py:190 -         run_log_save():    acc trg words/s: 5503
2017-11-30 01:39:56,582:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:40:26,357:train.py:148 -         sample_input(): Sample input data:
2017-11-30 01:40:26,357:train.py:149 -         sample_input(): Src: . Quo Status dem gegenüber Fall diesem in - trauen ß@@ Mi@@ bzw. Vertrauen mit digkeit än@@ sh@@ k@@ Lin@@ und - Rechts@@ von ation Assozi@@ kulturellen traditionellen der entsprach Unterscheidung diese _PAD _PAD
2017-11-30 01:40:26,357:train.py:150 -         sample_input(): Src len: 32
2017-11-30 01:40:26,357:train.py:151 -         sample_input(): Trg: _BOS the distinction capitalized on long @-@ standing cultural associations of right@@ - and left @-@ han@@ de@@ dness with , respectively , trust and suspicion - in this case , of the status quo . _PAD _PAD _PAD _PAD _PAD
2017-11-30 01:40:26,357:train.py:152 -         sample_input(): Tar: the distinction capitalized on long @-@ standing cultural associations of right@@ - and left @-@ han@@ de@@ dness with , respectively , trust and suspicion - in this case , of the status quo . _EOS _PAD _PAD _PAD _PAD _PAD
2017-11-30 01:40:26,357:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0
2017-11-30 01:40:26,357:train.py:188 -         run_log_save(): Batch 835, epoch 20/20:
2017-11-30 01:40:26,358:train.py:189 -         run_log_save():    avg word perp:   6.46
2017-11-30 01:40:26,358:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-30 01:40:26,358:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:40:55,644:train.py:188 -         run_log_save(): Batch 935, epoch 20/20:
2017-11-30 01:40:55,644:train.py:189 -         run_log_save():    avg word perp:   6.35
2017-11-30 01:40:55,645:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-30 01:40:55,645:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:41:24,971:train.py:188 -         run_log_save(): Batch 1035, epoch 20/20:
2017-11-30 01:41:24,971:train.py:189 -         run_log_save():    avg word perp:   6.37
2017-11-30 01:41:24,971:train.py:190 -         run_log_save():    acc trg words/s: 5504
2017-11-30 01:41:24,971:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:41:54,289:train.py:188 -         run_log_save(): Batch 1135, epoch 20/20:
2017-11-30 01:41:54,289:train.py:189 -         run_log_save():    avg word perp:   6.34
2017-11-30 01:41:54,289:train.py:190 -         run_log_save():    acc trg words/s: 5507
2017-11-30 01:41:54,289:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:42:23,959:train.py:188 -         run_log_save(): Batch 1235, epoch 20/20:
2017-11-30 01:42:23,959:train.py:189 -         run_log_save():    avg word perp:   6.38
2017-11-30 01:42:23,959:train.py:190 -         run_log_save():    acc trg words/s: 5506
2017-11-30 01:42:23,959:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:42:53,316:train.py:188 -         run_log_save(): Batch 1335, epoch 20/20:
2017-11-30 01:42:53,316:train.py:189 -         run_log_save():    avg word perp:   6.48
2017-11-30 01:42:53,316:train.py:190 -         run_log_save():    acc trg words/s: 5508
2017-11-30 01:42:53,316:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:43:23,174:train.py:188 -         run_log_save(): Batch 1435, epoch 20/20:
2017-11-30 01:43:23,175:train.py:189 -         run_log_save():    avg word perp:   6.44
2017-11-30 01:43:23,175:train.py:190 -         run_log_save():    acc trg words/s: 5505
2017-11-30 01:43:23,175:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:43:53,201:train.py:188 -         run_log_save(): Batch 1535, epoch 20/20:
2017-11-30 01:43:53,202:train.py:189 -         run_log_save():    avg word perp:   6.63
2017-11-30 01:43:53,202:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-30 01:43:53,202:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:44:22,787:train.py:188 -         run_log_save(): Batch 1635, epoch 20/20:
2017-11-30 01:44:22,787:train.py:189 -         run_log_save():    avg word perp:   6.57
2017-11-30 01:44:22,787:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-30 01:44:22,787:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:44:53,028:train.py:188 -         run_log_save(): Batch 1735, epoch 20/20:
2017-11-30 01:44:53,028:train.py:189 -         run_log_save():    avg word perp:   6.60
2017-11-30 01:44:53,028:train.py:190 -         run_log_save():    acc trg words/s: 5496
2017-11-30 01:44:53,028:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:45:22,423:train.py:148 -         sample_input(): Sample input data:
2017-11-30 01:45:22,423:train.py:149 -         sample_input(): Src: . verschlechtert möglichkeiten Beschäftigungs@@ und Sozialleistungen zu Zugang ihr und verringert Familien armer Kaufkraft die sich hat Wirtschaftskrise und Finanz- der sowie preisen Treibstoff@@ und Nahrungsmittel- steigenden aus Kombination der aufgrund _PAD _PAD
2017-11-30 01:45:22,423:train.py:150 -         sample_input(): Src len: 31
2017-11-30 01:45:22,423:train.py:151 -         sample_input(): Trg: _BOS the combination of rising food and fuel prices and the financial and economic crisis has reduced poor families &quot; purchasing power , access to social services , and employment opportunities . _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 01:45:22,423:train.py:152 -         sample_input(): Tar: the combination of rising food and fuel prices and the financial and economic crisis has reduced poor families &quot; purchasing power , access to social services , and employment opportunities . _EOS _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD _PAD
2017-11-30 01:45:22,423:train.py:153 -         sample_input(): W: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2017-11-30 01:45:22,423:train.py:188 -         run_log_save(): Batch 1835, epoch 20/20:
2017-11-30 01:45:22,423:train.py:189 -         run_log_save():    avg word perp:   6.59
2017-11-30 01:45:22,423:train.py:190 -         run_log_save():    acc trg words/s: 5498
2017-11-30 01:45:22,424:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:45:24,627:train.py:196 -         run_log_save(): Save model to ./nmt/saved_models/de2en/de2en.cpkt, takes 0:00:02.203200
2017-11-30 01:45:24,627:validator.py:225 -    validate_and_save(): Start validation
2017-11-30 01:45:24,627:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-30 01:46:04,701:validator.py:144 -             evaluate():   Translating line 100, average 0.400189189911 seconds/sent
2017-11-30 01:46:46,659:validator.py:144 -             evaluate():   Translating line 200, average 0.409887545109 seconds/sent
2017-11-30 01:47:20,420:validator.py:144 -             evaluate():   Translating line 300, average 0.385792723497 seconds/sent
2017-11-30 01:47:52,962:validator.py:144 -             evaluate():   Translating line 400, average 0.37070102036 seconds/sent
2017-11-30 01:48:35,243:validator.py:144 -             evaluate():   Translating line 500, average 0.381122596264 seconds/sent
2017-11-30 01:49:07,702:validator.py:144 -             evaluate():   Translating line 600, average 0.371700871785 seconds/sent
2017-11-30 01:49:42,957:validator.py:144 -             evaluate():   Translating line 700, average 0.368964304243 seconds/sent
2017-11-30 01:50:16,945:validator.py:144 -             evaluate():   Translating line 800, average 0.365328498781 seconds/sent
2017-11-30 01:50:44,474:validator.py:144 -             evaluate():   Translating line 900, average 0.355324303309 seconds/sent
2017-11-30 01:51:17,647:validator.py:144 -             evaluate():   Translating line 1000, average 0.352965200186 seconds/sent
2017-11-30 01:51:48,829:validator.py:144 -             evaluate():   Translating line 1100, average 0.349225031029 seconds/sent
2017-11-30 01:52:23,856:validator.py:144 -             evaluate():   Translating line 1200, average 0.34931221505 seconds/sent
2017-11-30 01:53:08,601:validator.py:144 -             evaluate():   Translating line 1300, average 0.356860620058 seconds/sent
2017-11-30 01:53:50,872:validator.py:144 -             evaluate():   Translating line 1400, average 0.361564756462 seconds/sent
2017-11-30 01:54:34,554:validator.py:144 -             evaluate():   Translating line 1500, average 0.366581554095 seconds/sent
2017-11-30 01:55:17,365:validator.py:144 -             evaluate():   Translating line 1600, average 0.370427146852 seconds/sent
2017-11-30 01:55:56,282:validator.py:144 -             evaluate():   Translating line 1700, average 0.371529317744 seconds/sent
2017-11-30 01:56:43,737:validator.py:144 -             evaluate():   Translating line 1800, average 0.377253003385 seconds/sent
2017-11-30 01:57:27,380:validator.py:144 -             evaluate():   Translating line 1900, average 0.380367309043 seconds/sent
2017-11-30 01:57:50,774:validator.py:153 -             evaluate(): Done translating.
2017-11-30 01:57:50,774:validator.py:154 -             evaluate(): dev perplexity: 84.665
2017-11-30 01:57:51,276:validator.py:160 -             evaluate(): BLEU = 13.01, 42.5/18.3/9.0/4.6 (BP=0.968, ratio=0.968, hyp_len=43847, ref_len=45274)

2017-11-30 01:57:51,276:validator.py:161 -             evaluate(): Validation took: 12.4432348172 minutes
2017-11-30 01:57:51,279:validator.py:196 -           maybe_save(): Current best bleus: 12.82
2017-11-30 01:57:51,279:validator.py:197 -           maybe_save(): Delete 12.82 & use 13.01 instead
2017-11-30 01:57:51,279:validator.py:207 -           maybe_save(): Delete ./nmt/saved_models/de2en/de2en-12.82.cpkt.data-00000-of-00001 & ./nmt/saved_models/de2en/de2en-12.82.cpkt.meta & ./nmt/saved_models/de2en/de2en-12.82.cpkt.index
2017-11-30 01:57:51,294:validator.py:213 -           maybe_save(): Save 13.01 to list of best bleu scores
2017-11-30 01:57:51,753:validator.py:217 -           maybe_save(): Save new best model to ./nmt/saved_models/de2en/de2en-13.01.cpkt
2017-11-30 01:57:51,753:validator.py:218 -           maybe_save(): Best bleu scores so far: 13.01
2017-11-30 01:58:21,644:train.py:188 -         run_log_save(): Batch 1935, epoch 20/20:
2017-11-30 01:58:21,645:train.py:189 -         run_log_save():    avg word perp:   6.68
2017-11-30 01:58:21,645:train.py:190 -         run_log_save():    acc trg words/s: 5497
2017-11-30 01:58:21,645:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:58:51,393:train.py:188 -         run_log_save(): Batch 2035, epoch 20/20:
2017-11-30 01:58:51,393:train.py:189 -         run_log_save():    avg word perp:   6.62
2017-11-30 01:58:51,393:train.py:190 -         run_log_save():    acc trg words/s: 5495
2017-11-30 01:58:51,393:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:59:19,951:train.py:188 -         run_log_save(): Batch 2135, epoch 20/20:
2017-11-30 01:59:19,951:train.py:189 -         run_log_save():    avg word perp:   6.44
2017-11-30 01:59:19,952:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-30 01:59:19,952:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 01:59:49,642:train.py:188 -         run_log_save(): Batch 2235, epoch 20/20:
2017-11-30 01:59:49,642:train.py:189 -         run_log_save():    avg word perp:   6.69
2017-11-30 01:59:49,642:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-30 01:59:49,642:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 02:00:19,314:train.py:188 -         run_log_save(): Batch 2335, epoch 20/20:
2017-11-30 02:00:19,315:train.py:189 -         run_log_save():    avg word perp:   6.67
2017-11-30 02:00:19,316:train.py:190 -         run_log_save():    acc trg words/s: 5500
2017-11-30 02:00:19,316:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 02:00:48,443:train.py:188 -         run_log_save(): Batch 2435, epoch 20/20:
2017-11-30 02:00:48,443:train.py:189 -         run_log_save():    avg word perp:   6.73
2017-11-30 02:00:48,443:train.py:190 -         run_log_save():    acc trg words/s: 5502
2017-11-30 02:00:48,443:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 02:01:18,732:train.py:188 -         run_log_save(): Batch 2535, epoch 20/20:
2017-11-30 02:01:18,732:train.py:189 -         run_log_save():    avg word perp:   6.83
2017-11-30 02:01:18,732:train.py:190 -         run_log_save():    acc trg words/s: 5501
2017-11-30 02:01:18,732:train.py:191 -         run_log_save():    acc sec/batch:   0.29
2017-11-30 02:01:18,732:train.py:116 -         report_epoch(): Finish epoch 20
2017-11-30 02:01:18,732:train.py:117 -         report_epoch():     It takes 0:12:21.781284
2017-11-30 02:01:18,733:train.py:118 -         report_epoch():     Avergage # words/second    5501.23612917
2017-11-30 02:01:18,733:train.py:119 -         report_epoch():     Average seconds/batch    0.292615891161
2017-11-30 02:01:18,733:train.py:130 -         report_epoch():     train perplexity: 6.41902964574
2017-11-30 02:01:18,733:train.py:98 -                train(): It is finally done, mate!
2017-11-30 02:01:18,733:train.py:99 -                train(): Train perplexities:
2017-11-30 02:01:18,733:train.py:100 -                train(): 386.143510061, 164.945083584, 65.3424870486, 30.9428937837, 21.152871559, 16.7779364006, 14.2138361463, 12.4943187942, 11.2578947206, 10.2964653484, 9.5591003961, 8.97546214473, 8.47672448785, 8.05315420167, 7.68943867424, 7.36619314171, 7.09158728978, 6.84527031014, 6.62979508819, 6.41902964574
2017-11-30 02:01:18,733:train.py:103 -                train(): Save final checkpoint
2017-11-30 02:01:20,978:train.py:108 -                train(): Evaluate on test
2017-11-30 02:01:20,978:train.py:111 -                train(): Restore best cpkt from ./nmt/saved_models/de2en/de2en-13.01.cpkt
2017-11-30 02:01:21,100:data_manager.py:158 -           init_vocab(): Initialize en vocab from ./nmt/data/de2en/vocab-23262.en
2017-11-30 02:02:02,236:validator.py:144 -             evaluate():   Translating line 100, average 0.410819032192 seconds/sent
2017-11-30 02:02:48,928:validator.py:144 -             evaluate():   Translating line 200, average 0.438871225119 seconds/sent
2017-11-30 02:03:29,757:validator.py:144 -             evaluate():   Translating line 300, average 0.428678190708 seconds/sent
2017-11-30 02:04:14,484:validator.py:144 -             evaluate():   Translating line 400, average 0.433324215412 seconds/sent
2017-11-30 02:04:57,983:validator.py:144 -             evaluate():   Translating line 500, average 0.43365790844 seconds/sent
2017-11-30 02:05:51,963:validator.py:144 -             evaluate():   Translating line 600, average 0.451348036925 seconds/sent
2017-11-30 02:06:28,148:validator.py:144 -             evaluate():   Translating line 700, average 0.43856320858 seconds/sent
2017-11-30 02:07:07,578:validator.py:144 -             evaluate():   Translating line 800, average 0.433030451536 seconds/sent
2017-11-30 02:07:57,456:validator.py:144 -             evaluate():   Translating line 900, average 0.440335870054 seconds/sent
2017-11-30 02:08:34,215:validator.py:144 -             evaluate():   Translating line 1000, average 0.43306063509 seconds/sent
2017-11-30 02:09:17,909:validator.py:144 -             evaluate():   Translating line 1100, average 0.433414096399 seconds/sent
2017-11-30 02:10:01,802:validator.py:144 -             evaluate():   Translating line 1200, average 0.433873193463 seconds/sent
2017-11-30 02:10:45,502:validator.py:144 -             evaluate():   Translating line 1300, average 0.434114021705 seconds/sent
2017-11-30 02:11:24,165:validator.py:144 -             evaluate():   Translating line 1400, average 0.430722463642 seconds/sent
2017-11-30 02:11:57,210:validator.py:144 -             evaluate():   Translating line 1500, average 0.424037532806 seconds/sent
2017-11-30 02:12:43,045:validator.py:144 -             evaluate():   Translating line 1600, average 0.426182106286 seconds/sent
2017-11-30 02:13:27,893:validator.py:144 -             evaluate():   Translating line 1700, average 0.427493416562 seconds/sent
2017-11-30 02:14:14,694:validator.py:144 -             evaluate():   Translating line 1800, average 0.42974424945 seconds/sent
2017-11-30 02:14:53,002:validator.py:144 -             evaluate():   Translating line 1900, average 0.427288522218 seconds/sent
2017-11-30 02:15:31,568:validator.py:144 -             evaluate():   Translating line 2000, average 0.425207098603 seconds/sent
2017-11-30 02:16:15,591:validator.py:144 -             evaluate():   Translating line 2100, average 0.425922447159 seconds/sent
2017-11-30 02:16:56,303:validator.py:144 -             evaluate():   Translating line 2200, average 0.425067958723 seconds/sent
2017-11-30 02:17:42,058:validator.py:144 -             evaluate():   Translating line 2300, average 0.426480091758 seconds/sent
2017-11-30 02:18:29,910:validator.py:144 -             evaluate():   Translating line 2400, average 0.428648555477 seconds/sent
2017-11-30 02:19:10,030:validator.py:144 -             evaluate():   Translating line 2500, average 0.427550285244 seconds/sent
2017-11-30 02:19:57,161:validator.py:144 -             evaluate():   Translating line 2600, average 0.429233614298 seconds/sent
2017-11-30 02:20:38,990:validator.py:144 -             evaluate():   Translating line 2700, average 0.428828144868 seconds/sent
2017-11-30 02:20:45,426:validator.py:153 -             evaluate(): Done translating.
2017-11-30 02:20:45,426:validator.py:154 -             evaluate(): dev perplexity: 185.822
2017-11-30 02:20:46,194:validator.py:160 -             evaluate(): BLEU = 10.78, 35.1/14.6/7.2/3.7 (BP=1.000, ratio=1.205, hyp_len=68514, ref_len=56852)

2017-11-30 02:20:46,196:validator.py:161 -             evaluate(): Validation took: 19.4173656861 minutes
